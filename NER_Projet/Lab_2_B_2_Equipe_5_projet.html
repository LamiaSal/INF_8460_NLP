<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>BERT_SOUMISSION</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script>
(function() {
  function addWidgetsRenderer() {
    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var scriptElement = document.createElement('script');
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        widgetRendererSrc = 'https://unpkg.com/jupyter-js-widgets@*/dist/embed.js';
      }
    } catch(e) {}

    scriptElement.src = widgetRendererSrc;
    document.body.appendChild(scriptElement);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<center> cole Polytechnique de Montral <br> Dpartement Gnie Informatique et Gnie Logiciel <br>  INF8460  Traitement automatique de la langue naturelle <br> </center>
<center> TP3 INF8460 <br>  Automne 2021 </center>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># PATH = &quot;drive/MyDrive/TPS/TP3&quot;</span>
<span class="n">PATH</span> <span class="o">=</span> <span class="s2">&quot;drive/MyDrive/POLY/INF8460/TPS/TP3&quot;</span>
<span class="c1"># PATH = &quot;drive/MyDrive/POLY/Traitement Auto de la Langue Naturelle/TPS/TP3&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="k">import</span> <span class="n">drive</span>

<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True).
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">FileNotFoundError</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-88-1dee07b8ed35&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> 
<span class="ansi-green-intense-fg ansi-bold">      4</span> drive<span class="ansi-blue-fg">.</span>mount<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;/content/drive&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 5</span><span class="ansi-red-fg"> </span>os<span class="ansi-blue-fg">.</span>chdir<span class="ansi-blue-fg">(</span>PATH<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;drive/MyDrive/POLY/INF8460/TP/TP3&#39;</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Importations-des-diff&#233;rentes-librairies">Importations des diff&#233;rentes librairies<a class="anchor-link" href="#Importations-des-diff&#233;rentes-librairies">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.tag.util</span> <span class="k">import</span> <span class="n">untag</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="k">import</span> <span class="n">word_tokenize</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk</span> <span class="k">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="k">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">import</span> <span class="n">to_categorical</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Input</span><span class="p">,</span><span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">InputLayer</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="k">import</span> <span class="n">Adam</span><span class="p">,</span> <span class="n">SGD</span><span class="p">,</span><span class="n">RMSprop</span><span class="p">,</span><span class="n">Adagrad</span><span class="p">,</span><span class="n">Adadelta</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">load_model</span>
<span class="c1">#from tensorflow.keras.models import create_model</span>


<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">plot_confusion_matrix</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="k">import</span> <span class="n">chain</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">make_scorer</span>


<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RandomizedSearchCV</span><span class="p">,</span><span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">f1_score</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="k">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">load_model</span><span class="p">,</span><span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Masking</span>

<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Masking</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">BatchNormalization</span>

<span class="c1">#defining the checkpoint</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">f1_score</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">InputLayer</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="k">import</span> <span class="n">Adam</span><span class="p">,</span> <span class="n">SGD</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">classification_report</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;punkt&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[90]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[nltk_data] Downloading collection &#39;all&#39;
[nltk_data]    | 
[nltk_data]    | Downloading package abc to /root/nltk_data...
[nltk_data]    |   Package abc is already up-to-date!
[nltk_data]    | Downloading package alpino to /root/nltk_data...
[nltk_data]    |   Package alpino is already up-to-date!
[nltk_data]    | Downloading package biocreative_ppi to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package biocreative_ppi is already up-to-date!
[nltk_data]    | Downloading package brown to /root/nltk_data...
[nltk_data]    |   Package brown is already up-to-date!
[nltk_data]    | Downloading package brown_tei to /root/nltk_data...
[nltk_data]    |   Package brown_tei is already up-to-date!
[nltk_data]    | Downloading package cess_cat to /root/nltk_data...
[nltk_data]    |   Package cess_cat is already up-to-date!
[nltk_data]    | Downloading package cess_esp to /root/nltk_data...
[nltk_data]    |   Package cess_esp is already up-to-date!
[nltk_data]    | Downloading package chat80 to /root/nltk_data...
[nltk_data]    |   Package chat80 is already up-to-date!
[nltk_data]    | Downloading package city_database to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package city_database is already up-to-date!
[nltk_data]    | Downloading package cmudict to /root/nltk_data...
[nltk_data]    |   Package cmudict is already up-to-date!
[nltk_data]    | Downloading package comparative_sentences to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package comparative_sentences is already up-to-
[nltk_data]    |       date!
[nltk_data]    | Downloading package comtrans to /root/nltk_data...
[nltk_data]    |   Package comtrans is already up-to-date!
[nltk_data]    | Downloading package conll2000 to /root/nltk_data...
[nltk_data]    |   Package conll2000 is already up-to-date!
[nltk_data]    | Downloading package conll2002 to /root/nltk_data...
[nltk_data]    |   Package conll2002 is already up-to-date!
[nltk_data]    | Downloading package conll2007 to /root/nltk_data...
[nltk_data]    |   Package conll2007 is already up-to-date!
[nltk_data]    | Downloading package crubadan to /root/nltk_data...
[nltk_data]    |   Package crubadan is already up-to-date!
[nltk_data]    | Downloading package dependency_treebank to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package dependency_treebank is already up-to-date!
[nltk_data]    | Downloading package dolch to /root/nltk_data...
[nltk_data]    |   Package dolch is already up-to-date!
[nltk_data]    | Downloading package europarl_raw to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package europarl_raw is already up-to-date!
[nltk_data]    | Downloading package floresta to /root/nltk_data...
[nltk_data]    |   Package floresta is already up-to-date!
[nltk_data]    | Downloading package framenet_v15 to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package framenet_v15 is already up-to-date!
[nltk_data]    | Downloading package framenet_v17 to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package framenet_v17 is already up-to-date!
[nltk_data]    | Downloading package gazetteers to /root/nltk_data...
[nltk_data]    |   Package gazetteers is already up-to-date!
[nltk_data]    | Downloading package genesis to /root/nltk_data...
[nltk_data]    |   Package genesis is already up-to-date!
[nltk_data]    | Downloading package gutenberg to /root/nltk_data...
[nltk_data]    |   Package gutenberg is already up-to-date!
[nltk_data]    | Downloading package ieer to /root/nltk_data...
[nltk_data]    |   Package ieer is already up-to-date!
[nltk_data]    | Downloading package inaugural to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/inaugural.zip.
[nltk_data]    | Downloading package indian to /root/nltk_data...
[nltk_data]    |   Package indian is already up-to-date!
[nltk_data]    | Downloading package jeita to /root/nltk_data...
[nltk_data]    |   Package jeita is already up-to-date!
[nltk_data]    | Downloading package kimmo to /root/nltk_data...
[nltk_data]    |   Package kimmo is already up-to-date!
[nltk_data]    | Downloading package knbc to /root/nltk_data...
[nltk_data]    |   Package knbc is already up-to-date!
[nltk_data]    | Downloading package lin_thesaurus to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package lin_thesaurus is already up-to-date!
[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...
[nltk_data]    |   Package mac_morpho is already up-to-date!
[nltk_data]    | Downloading package machado to /root/nltk_data...
[nltk_data]    |   Package machado is already up-to-date!
[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...
[nltk_data]    |   Package masc_tagged is already up-to-date!
[nltk_data]    | Downloading package moses_sample to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package moses_sample is already up-to-date!
[nltk_data]    | Downloading package movie_reviews to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package movie_reviews is already up-to-date!
[nltk_data]    | Downloading package names to /root/nltk_data...
[nltk_data]    |   Package names is already up-to-date!
[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...
[nltk_data]    |   Package nombank.1.0 is already up-to-date!
[nltk_data]    | Downloading package nps_chat to /root/nltk_data...
[nltk_data]    |   Package nps_chat is already up-to-date!
[nltk_data]    | Downloading package omw to /root/nltk_data...
[nltk_data]    |   Package omw is already up-to-date!
[nltk_data]    | Downloading package opinion_lexicon to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package opinion_lexicon is already up-to-date!
[nltk_data]    | Downloading package paradigms to /root/nltk_data...
[nltk_data]    |   Package paradigms is already up-to-date!
[nltk_data]    | Downloading package pil to /root/nltk_data...
[nltk_data]    |   Package pil is already up-to-date!
[nltk_data]    | Downloading package pl196x to /root/nltk_data...
[nltk_data]    |   Package pl196x is already up-to-date!
[nltk_data]    | Downloading package ppattach to /root/nltk_data...
[nltk_data]    |   Package ppattach is already up-to-date!
[nltk_data]    | Downloading package problem_reports to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package problem_reports is already up-to-date!
[nltk_data]    | Downloading package propbank to /root/nltk_data...
[nltk_data]    |   Package propbank is already up-to-date!
[nltk_data]    | Downloading package ptb to /root/nltk_data...
[nltk_data]    |   Package ptb is already up-to-date!
[nltk_data]    | Downloading package product_reviews_1 to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package product_reviews_1 is already up-to-date!
[nltk_data]    | Downloading package product_reviews_2 to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package product_reviews_2 is already up-to-date!
[nltk_data]    | Downloading package pros_cons to /root/nltk_data...
[nltk_data]    |   Package pros_cons is already up-to-date!
[nltk_data]    | Downloading package qc to /root/nltk_data...
[nltk_data]    |   Package qc is already up-to-date!
[nltk_data]    | Downloading package reuters to /root/nltk_data...
[nltk_data]    |   Package reuters is already up-to-date!
[nltk_data]    | Downloading package rte to /root/nltk_data...
[nltk_data]    |   Package rte is already up-to-date!
[nltk_data]    | Downloading package semcor to /root/nltk_data...
[nltk_data]    |   Package semcor is already up-to-date!
[nltk_data]    | Downloading package senseval to /root/nltk_data...
[nltk_data]    |   Package senseval is already up-to-date!
[nltk_data]    | Downloading package sentiwordnet to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package sentiwordnet is already up-to-date!
[nltk_data]    | Downloading package sentence_polarity to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package sentence_polarity is already up-to-date!
[nltk_data]    | Downloading package shakespeare to /root/nltk_data...
[nltk_data]    |   Package shakespeare is already up-to-date!
[nltk_data]    | Downloading package sinica_treebank to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package sinica_treebank is already up-to-date!
[nltk_data]    | Downloading package smultron to /root/nltk_data...
[nltk_data]    |   Package smultron is already up-to-date!
[nltk_data]    | Downloading package state_union to /root/nltk_data...
[nltk_data]    |   Package state_union is already up-to-date!
[nltk_data]    | Downloading package stopwords to /root/nltk_data...
[nltk_data]    |   Package stopwords is already up-to-date!
[nltk_data]    | Downloading package subjectivity to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package subjectivity is already up-to-date!
[nltk_data]    | Downloading package swadesh to /root/nltk_data...
[nltk_data]    |   Package swadesh is already up-to-date!
[nltk_data]    | Downloading package switchboard to /root/nltk_data...
[nltk_data]    |   Package switchboard is already up-to-date!
[nltk_data]    | Downloading package timit to /root/nltk_data...
[nltk_data]    |   Package timit is already up-to-date!
[nltk_data]    | Downloading package toolbox to /root/nltk_data...
[nltk_data]    |   Package toolbox is already up-to-date!
[nltk_data]    | Downloading package treebank to /root/nltk_data...
[nltk_data]    |   Package treebank is already up-to-date!
[nltk_data]    | Downloading package twitter_samples to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package twitter_samples is already up-to-date!
[nltk_data]    | Downloading package udhr to /root/nltk_data...
[nltk_data]    |   Package udhr is already up-to-date!
[nltk_data]    | Downloading package udhr2 to /root/nltk_data...
[nltk_data]    |   Package udhr2 is already up-to-date!
[nltk_data]    | Downloading package unicode_samples to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package unicode_samples is already up-to-date!
[nltk_data]    | Downloading package universal_treebanks_v20 to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package universal_treebanks_v20 is already up-to-
[nltk_data]    |       date!
[nltk_data]    | Downloading package verbnet to /root/nltk_data...
[nltk_data]    |   Package verbnet is already up-to-date!
[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...
[nltk_data]    |   Package verbnet3 is already up-to-date!
[nltk_data]    | Downloading package webtext to /root/nltk_data...
[nltk_data]    |   Package webtext is already up-to-date!
[nltk_data]    | Downloading package wordnet to /root/nltk_data...
[nltk_data]    |   Package wordnet is already up-to-date!
[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/wordnet31.zip.
[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...
[nltk_data]    |   Package wordnet_ic is already up-to-date!
[nltk_data]    | Downloading package words to /root/nltk_data...
[nltk_data]    |   Package words is already up-to-date!
[nltk_data]    | Downloading package ycoe to /root/nltk_data...
[nltk_data]    |   Package ycoe is already up-to-date!
[nltk_data]    | Downloading package rslp to /root/nltk_data...
[nltk_data]    |   Package rslp is already up-to-date!
[nltk_data]    | Downloading package maxent_treebank_pos_tagger to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-
[nltk_data]    |       to-date!
[nltk_data]    | Downloading package universal_tagset to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package universal_tagset is already up-to-date!
[nltk_data]    | Downloading package maxent_ne_chunker to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!
[nltk_data]    | Downloading package punkt to /root/nltk_data...
[nltk_data]    |   Package punkt is already up-to-date!
[nltk_data]    | Downloading package book_grammars to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package book_grammars is already up-to-date!
[nltk_data]    | Downloading package sample_grammars to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package sample_grammars is already up-to-date!
[nltk_data]    | Downloading package spanish_grammars to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package spanish_grammars is already up-to-date!
[nltk_data]    | Downloading package basque_grammars to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package basque_grammars is already up-to-date!
[nltk_data]    | Downloading package large_grammars to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package large_grammars is already up-to-date!
[nltk_data]    | Downloading package tagsets to /root/nltk_data...
[nltk_data]    |   Package tagsets is already up-to-date!
[nltk_data]    | Downloading package snowball_data to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package snowball_data is already up-to-date!
[nltk_data]    | Downloading package bllip_wsj_no_aux to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!
[nltk_data]    | Downloading package word2vec_sample to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package word2vec_sample is already up-to-date!
[nltk_data]    | Downloading package panlex_swadesh to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package panlex_swadesh is already up-to-date!
[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...
[nltk_data]    |   Package mte_teip5 is already up-to-date!
[nltk_data]    | Downloading package averaged_perceptron_tagger to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package averaged_perceptron_tagger is already up-
[nltk_data]    |       to-date!
[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package averaged_perceptron_tagger_ru is already
[nltk_data]    |       up-to-date!
[nltk_data]    | Downloading package perluniprops to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package perluniprops is already up-to-date!
[nltk_data]    | Downloading package nonbreaking_prefixes to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!
[nltk_data]    | Downloading package vader_lexicon to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Package vader_lexicon is already up-to-date!
[nltk_data]    | Downloading package porter_test to /root/nltk_data...
[nltk_data]    |   Package porter_test is already up-to-date!
[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...
[nltk_data]    |   Package wmt15_eval is already up-to-date!
[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...
[nltk_data]    |   Package mwa_ppdb is already up-to-date!
[nltk_data]    | 
[nltk_data]  Done downloading collection all
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[91]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> <span class="c1">#download crf library for crf layer usage</span>
 <span class="o">!</span>pip install tf2crf
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: tf2crf in /usr/local/lib/python3.7/dist-packages (0.1.33)
Requirement already satisfied: tensorflow-addons&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from tf2crf) (0.15.0)
Requirement already satisfied: tensorflow&gt;=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tf2crf) (2.7.0)
Requirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (1.42.0)
Requirement already satisfied: keras-preprocessing&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (1.1.2)
Requirement already satisfied: tensorflow-io-gcs-filesystem&gt;=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (0.22.0)
Requirement already satisfied: protobuf&gt;=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (3.17.3)
Requirement already satisfied: google-pasta&gt;=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (0.2.0)
Requirement already satisfied: h5py&gt;=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (3.1.0)
Requirement already satisfied: absl-py&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (0.12.0)
Requirement already satisfied: gast&lt;0.5.0,&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (0.4.0)
Requirement already satisfied: numpy&gt;=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (1.19.5)
Requirement already satisfied: astunparse&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (1.6.3)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (3.3.0)
Requirement already satisfied: keras&lt;2.8,&gt;=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (2.7.0)
Requirement already satisfied: six&gt;=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (1.15.0)
Requirement already satisfied: flatbuffers&lt;3.0,&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (2.0)
Requirement already satisfied: wheel&lt;1.0,&gt;=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (0.37.0)
Requirement already satisfied: tensorflow-estimator&lt;2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (2.7.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (1.1.0)
Requirement already satisfied: typing-extensions&gt;=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (3.10.0.2)
Requirement already satisfied: libclang&gt;=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (12.0.0)
Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (2.7.0)
Requirement already satisfied: wrapt&gt;=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow&gt;=2.1.0-&gt;tf2crf) (1.13.3)
Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py&gt;=2.9.0-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (1.5.2)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (2.23.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (1.8.0)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (1.0.1)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (3.3.6)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (0.4.6)
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (57.4.0)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (0.6.1)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (1.35.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (4.8)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (4.2.4)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (0.2.8)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (1.3.0)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (4.8.2)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (3.6.0)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (0.4.8)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (2021.10.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (3.0.4)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (1.24.3)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard~=2.6-&gt;tensorflow&gt;=2.1.0-&gt;tf2crf) (3.1.1)
Requirement already satisfied: typeguard&gt;=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons&gt;=0.8.2-&gt;tf2crf) (2.7.1)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tf2crf</span> <span class="k">import</span> <span class="n">CRF</span><span class="p">,</span> <span class="n">ModelWithCRFLoss</span><span class="p">,</span><span class="n">ModelWithCRFLossDSCLoss</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#download sklearn-crfsuite for crf implementation</span>
<span class="o">!</span>pip install sklearn-crfsuite
<span class="o">!</span>pip install -U <span class="s1">&#39;scikit-learn&lt;0.24&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)
Requirement already satisfied: python-crfsuite&gt;=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.9.7)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)
Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)
Requirement already satisfied: tqdm&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.62.3)
Requirement already satisfied: scikit-learn&lt;0.24 in /usr/local/lib/python3.7/dist-packages (0.23.2)
Requirement already satisfied: scipy&gt;=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.24) (1.4.1)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.24) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.24) (3.0.0)
Requirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.24) (1.19.5)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn_crfsuite</span>
<span class="kn">from</span> <span class="nn">sklearn_crfsuite</span> <span class="k">import</span> <span class="n">scorers</span>
<span class="kn">from</span> <span class="nn">sklearn_crfsuite</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn_crfsuite</span> <span class="k">import</span> <span class="n">CRF</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Importation-de-Glove">Importation de Glove<a class="anchor-link" href="#Importation-de-Glove">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">zipfile</span><span class="o">,</span> <span class="nn">io</span>
<span class="n">zip_file_url</span> <span class="o">=</span> <span class="s2">&quot;http://nlp.stanford.edu/data/glove.840B.300d.zip&quot;</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">zip_file_url</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
<span class="n">z</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">codecs</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loading word embeddings...&#39;</span><span class="p">)</span>


<span class="n">embeddings_index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;glove.840B.300d.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">embeddings_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;found </span><span class="si">%s</span><span class="s1"> word vectors&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">embeddings_index</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Fonctions-utiles">Fonctions utiles<a class="anchor-link" href="#Fonctions-utiles">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_distrib</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">):</span>
  <span class="n">max_len</span><span class="p">,</span> <span class="n">mean_len</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
  <span class="n">tok_count</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">nb_tags</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">all_tokens</span><span class="p">:</span>
    <span class="n">nb_tags</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">tok_count</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tok_count</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">tok_count</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">tok_freq</span> <span class="o">=</span> <span class="p">{</span><span class="n">tag</span><span class="p">:</span> <span class="n">value</span> <span class="o">/</span> <span class="n">nb_tags</span> <span class="k">for</span> <span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tok_count</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">tok_freq</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">tok_freq</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution des tag&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tags&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frquence&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we get data in the form of a list of tokens and tags given the their dataframe</span>

<span class="k">def</span> <span class="nf">vectorize_tagged_sentence</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">folder</span><span class="p">):</span>
  <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">ids</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">tags</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">[</span><span class="n">folder</span><span class="p">]):</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">doc_id</span><span class="p">]</span>
    <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>
    <span class="n">tags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;Tag&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">sentences</span><span class="p">,</span><span class="n">tags</span><span class="p">,</span> <span class="n">ids</span>

<span class="k">def</span> <span class="nf">vectorize_test_sentence</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
  <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">ids</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]):</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">doc_id</span><span class="p">]</span>
    <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">ids</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">check_training_preproccessing</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;Cette fonction sert  vrifier que les donnes d&#39;entrainements possdent les proprits attendues.</span>
<span class="sd">  Notemment on vrifie la proportion de chaque tag ce qui permet d&#39;avoir un estimation de si on en a ouli.</span>
<span class="sd">  Ensuite on applique &quot;&quot;&quot;</span>
  <span class="n">max_len</span><span class="p">,</span> <span class="n">mean_len</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
  <span class="n">tok_count</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">train_sentences</span><span class="p">:</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span>
    <span class="n">mean_len</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
  <span class="n">nb_tags</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">train_tags</span><span class="p">:</span>
    <span class="n">nb_tags</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">tok_count</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tok_count</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">tok_count</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">tok_freq</span> <span class="o">=</span> <span class="p">{</span><span class="n">tag</span><span class="p">:</span> <span class="n">value</span> <span class="o">/</span> <span class="n">nb_tags</span> <span class="k">for</span> <span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tok_count</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;max_len=</span><span class="si">{max_len}</span><span class="s2">, mean_len={mean_len / len(train_sentences):.1f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;tok_freq=</span><span class="si">{tok_freq}</span><span class="s2">&quot;</span><span class="p">)</span>

  <span class="n">bad</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">tags</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_tags</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tags</span><span class="p">)):</span>
      <span class="k">if</span> <span class="s2">&quot;B&quot;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="s1">&#39;L&#39;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">or</span> <span class="s1">&#39;U&#39;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">or</span> <span class="s1">&#39;O&#39;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">bad</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># print(tags)</span>
      <span class="k">if</span> <span class="s2">&quot;L&quot;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_tags</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="ow">or</span> <span class="s1">&#39;B&#39;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="ow">or</span> <span class="s1">&#39;U&#39;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="ow">or</span> <span class="s1">&#39;O&#39;</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">bad</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># print(tags)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;nb of badly formed taggings:&quot;</span><span class="p">,</span><span class="n">bad</span><span class="p">)</span>

  <span class="n">nb_entity</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;data/train&quot;</span><span class="p">):</span>
    <span class="k">if</span> <span class="s2">&quot;.ann&quot;</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;data/train/</span><span class="si">{doc}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Type&quot;</span><span class="p">,</span> <span class="s2">&quot;Annotation&quot;</span><span class="p">,</span> <span class="s2">&quot;Tokens&quot;</span><span class="p">])</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">ANN</span><span class="p">[</span><span class="n">ANN</span><span class="p">[</span><span class="s1">&#39;Type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="s2">&quot;T&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
      <span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Tokens begining&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Annotation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">ANN</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])]</span>
      <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ANN</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">])[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">p</span><span class="p">,</span><span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">]):</span>
          <span class="k">continue</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">i</span>
        <span class="n">nb_entity</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="n">nb_found</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">train_tags</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
      <span class="k">if</span> <span class="s2">&quot;B&quot;</span> <span class="ow">in</span> <span class="n">tag</span> <span class="ow">or</span> <span class="s2">&quot;U&quot;</span> <span class="ow">in</span> <span class="n">tag</span><span class="p">:</span>
        <span class="n">nb_found</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nb of labeled entity:&quot;</span><span class="p">,</span> <span class="n">nb_entity</span><span class="p">,</span> <span class="s2">&quot;\ nb of found entity:&quot;</span><span class="p">,</span> <span class="n">nb_found</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Prop of possibly missing tags: {(nb_entity-nb_found)/nb_entity:.4f}%&quot;</span><span class="p">)</span>
<span class="c1"># check_training_preproccessing()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">weighted_categorical_crossentropy</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A weighted version of keras.objectives.categorical_crossentropy</span>
<span class="sd">    </span>
<span class="sd">    Variables:</span>
<span class="sd">        weights: numpy array of shape (C,) where C is the number of classes</span>
<span class="sd">    </span>
<span class="sd">    Usage:</span>
<span class="sd">        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.</span>
<span class="sd">        loss = weighted_categorical_crossentropy(weights)</span>
<span class="sd">        model.compile(loss=loss,optimizer=&#39;adam&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">weights</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
        <span class="c1"># scale predictions so that the class probas of each sample sum to 1</span>
        <span class="n">y_pred</span> <span class="o">/=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># clip to prevent NaN&#39;s and Inf&#39;s</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">(),</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
        <span class="c1"># calc</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">*</span> <span class="n">K</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="o">*</span> <span class="n">weights</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
    
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_seq</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">get_f1_micro</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span> 
  <span class="k">return</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">get_seq</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">get_seq</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span> 
<span class="k">def</span> <span class="nf">get_f1_macro</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">get_seq</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">get_seq</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># printing results of the benchmark done for bilstm model task A</span>
<span class="k">def</span> <span class="nf">print_training</span><span class="p">(</span><span class="n">histories</span><span class="p">,</span> <span class="n">metric_names</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">)):</span>
  <span class="n">nb_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
  <span class="n">nb_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric_names</span><span class="p">)</span>
  <span class="n">f</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nb_models</span><span class="p">,</span> <span class="n">nb_params</span><span class="p">)</span>
  <span class="n">f</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">history</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">histories</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metric_names</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>

      <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="n">metric_name</span><span class="p">])</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_&quot;</span><span class="o">+</span><span class="n">metric_name</span><span class="p">])</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">metric_name</span><span class="p">)</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train set&#39;</span><span class="p">,</span> <span class="s1">&#39;validation set&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
  <span class="n">f</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mf">3.0</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="importations-du-dataset-et-visualisation">importations du dataset et visualisation<a class="anchor-link" href="#importations-du-dataset-et-visualisation">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># On charge les fichier .csv dans lesquels se trouve la liste des jetons  annoter. </span>
<span class="c1"># On utilise `keep_default_na=False` pour viter de transformer le mot &#39;null&#39; en la valeur &#39;na&#39;</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/train.csv&quot;</span><span class="p">,</span> <span class="n">keep_default_na</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">val_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/val.csv&quot;</span><span class="p">,</span> <span class="n">keep_default_na</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/test.csv&quot;</span><span class="p">,</span> <span class="n">keep_default_na</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DocID</th>
      <th>TokenID</th>
      <th>Token</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-0</td>
      <td>The</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-1</td>
      <td>vapour</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-2</td>
      <td>phase</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-3</td>
      <td>consists</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-4</td>
      <td>of</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">val_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DocID</th>
      <th>TokenID</th>
      <th>Token</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0301010415300355</td>
      <td>S0301010415300355-0</td>
      <td>Alternatively</td>
      <td></td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0301010415300355</td>
      <td>S0301010415300355-1</td>
      <td>to</td>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0301010415300355</td>
      <td>S0301010415300355-2</td>
      <td>H-atom</td>
      <td></td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0301010415300355</td>
      <td>S0301010415300355-3</td>
      <td>photodetachment</td>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0301010415300355</td>
      <td>S0301010415300355-4</td>
      <td>from</td>
      <td></td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># On sauvegarde les documents dans une variable afin de pouvoir retrouver la provenance du document si on voit des problme pendant le prtraitement</span>

<span class="n">doc_ids</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)),</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">val_df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)),</span> <span class="s1">&#39;test&#39;</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))}</span>
<span class="n">N_doc</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1.-Etat-de-l&#8217;art-(10%)">1. Etat de l&#8217;art (10%)<a class="anchor-link" href="#1.-Etat-de-l&#8217;art-(10%)">&#182;</a></h1><p>Dcrivez en deux paragraphes, dans une cellule du notebook, ltat de lart pour la reconnaissance de mots cl et leur annotation. Utilisez le service Google Scholar. Voici quelques mots-cl (non exhaustifs) : Named Entity recognition, NER, entity typing.</p>
<p>Quelles sont les meilleures techniques de ltat de lart ?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ltat de lart pour la reconnaissance de mots-cls et leur annotation sest appuye sur des rseaux de neurones et notamment des LSTM jusquen 2017 environ avant dtre dpass par les modles  base de transformers, et notamment grce au modle BERT.</p>
<p>Parmi les meilleurs modles pour la reconnaissance dentits nommes (en les valuant sur le corpus CoNLL 2003) on trouve :</p>
<ul>
<li>Automated Concatenation of Embeddings for Structured Prediction [1] (Wang et al., 2021) qui consiste en la reprsentation de mots par une concatnation de diffrents types dembeddings, en utilisant de lapprentissage par renforcement pour dterminer quel concatnation choisir.</li>
<li>LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention [2] (Yamada et al., 2020) qui se base sur des reprsentations pr-entraines de mots bases sur des transformers bidirectionnels et sur le modle de BERT. La mthode propose aussi un mcanisme dattention propre qui soit  entity-aware .</li>
<li>Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning [3] (Wang et al., 2021) qui considre pour les mots dune phrase des contextes extrieurs  la phrase elle-mme, en recherchant un ensemble de textes smantiquement proches de la phrase dorigine dans un moteur de recherche.</li>
</ul>
<p>[1] <a href="https://arxiv.org/abs/2010.05006">https://arxiv.org/abs/2010.05006</a></p>
<p>[2] <a href="https://arxiv.org/abs/2010.01057">https://arxiv.org/abs/2010.01057</a></p>
<p>[3] <a href="https://arxiv.org/abs/2105.03654">https://arxiv.org/abs/2105.03654</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-Sous-t&#226;che-A-:-Identification-des-mots-cl&#233;s-(65%)">2. Sous-t&#226;che A : Identification des mots-cl&#233;s (65%)<a class="anchor-link" href="#2.-Sous-t&#226;che-A-:-Identification-des-mots-cl&#233;s-(65%)">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="a.-Pr&#233;traitement-des-donn&#233;es">a. Pr&#233;traitement des donn&#233;es<a class="anchor-link" href="#a.-Pr&#233;traitement-des-donn&#233;es">&#182;</a></h2><p>Premires tapes de prtraitement communes  tous les modles. Nous rcuprons les informations des fichiers .ann pour associ les tags aux jetons.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_id</span> <span class="o">=</span> <span class="mi">18</span>
<span class="k">def</span> <span class="nf">set_tag_A</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">sub_data</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Fonction pour annoter les jetons prsents dans les fichiers .csv</span>
<span class="sd">  On parcours toutes les lignes du fichier et paralllement on avance dans les fichiers .ann pour rcuprer les tags associs.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Tag&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
  <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
  <span class="n">doc_id</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))):</span>
    <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">doc_id</span><span class="p">:</span>
      <span class="n">i0</span> <span class="o">=</span> <span class="n">i</span>
      <span class="n">doc_id</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;data/</span><span class="si">{sub_data}</span><span class="s2">/</span><span class="si">{doc_id}</span><span class="s2">.ann&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Type&quot;</span><span class="p">,</span> <span class="s2">&quot;Annotation&quot;</span><span class="p">,</span> <span class="s2">&quot;Tokens&quot;</span><span class="p">])</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">ANN</span><span class="p">[</span><span class="n">ANN</span><span class="p">[</span><span class="s1">&#39;Type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="s2">&quot;T&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
      <span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Tokens begining&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Annotation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">ANN</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])]</span>
      <span class="n">tokens_id</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">match_id</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">tokens_id</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ANN</span><span class="p">):</span> 
      <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;O&quot;</span>
      <span class="k">continue</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">token</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Token&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">tokens</span><span class="p">[</span><span class="n">match_id</span><span class="p">]</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">match_id</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;U&quot;</span>
        <span class="n">previous_tokens_id</span> <span class="o">=</span> <span class="n">tokens_id</span>
        <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">tokens_id</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">ANN</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">previous_tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">]):</span>
          <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">elif</span> <span class="n">match_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">match_id</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="n">match_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">entity_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;B&quot;</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">entity_ids</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
          <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;I&quot;</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;L&quot;</span>
        <span class="n">match_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">previous_tokens_id</span> <span class="o">=</span> <span class="n">tokens_id</span>
        <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">tokens_id</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">ANN</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">previous_tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">]):</span>
          <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">entity_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">match_id</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;O&quot;</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">entity_ids</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;O&quot;</span>
      <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">match_id</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">return</span> <span class="n">df</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Comme la fonction `set_tag` met un certain temps  tre excute, on sauvegarde le rsultat pour pouvoir le rutiliser plus tard</span>

<span class="k">if</span> <span class="ow">not</span> <span class="s2">&quot;train_A_bilou.csv&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">():</span>
  <span class="n">train_A_df</span> <span class="o">=</span> <span class="n">set_tag_A</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
  <span class="n">train_A_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;train_A_bilou.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">train_A_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;train_A_bilou.csv&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="s2">&quot;val_A_bilou.csv&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">():</span>
  <span class="n">val_A_df</span> <span class="o">=</span> <span class="n">set_tag_A</span><span class="p">(</span><span class="n">val_df</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)</span>
  <span class="n">val_A_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;val_A_bilou.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">val_A_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;val_A_bilou.csv&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_A_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DocID</th>
      <th>TokenID</th>
      <th>Token</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-0</td>
      <td>The</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-1</td>
      <td>vapour</td>
      <td>B</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-2</td>
      <td>phase</td>
      <td>L</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-3</td>
      <td>consists</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-4</td>
      <td>of</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># TODO : </span>
<span class="n">train_sentences</span><span class="p">,</span> <span class="n">train_tags</span><span class="p">,</span> <span class="n">train_ids</span> <span class="o">=</span> <span class="n">vectorize_tagged_sentence</span><span class="p">(</span><span class="n">train_A_df</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">val_sentences</span><span class="p">,</span> <span class="n">val_tags</span><span class="p">,</span> <span class="n">val_ids</span> <span class="o">=</span> <span class="n">vectorize_tagged_sentence</span><span class="p">(</span><span class="n">val_A_df</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">)</span>
<span class="n">test_sentences</span><span class="p">,</span> <span class="n">test_ids</span> <span class="o">=</span> <span class="n">vectorize_test_sentence</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 350/350 [00:01&lt;00:00, 239.68it/s]
100%|| 50/50 [00:00&lt;00:00, 729.22it/s]
100%|| 100/100 [00:00&lt;00:00, 600.45it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">[</span><span class="n">show_id</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_tags</span><span class="p">[</span><span class="n">show_id</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;The&#39; &#39;final&#39; &#39;contribution&#39; &#39;to&#39; &#39;the&#39; &#39;force&#39; &#39;is&#39; &#39;the&#39; &#39;van&#39; &#39;der&#39;
 &#39;Waals&#39; &#39;interaction&#39; &#39;.&#39; &#39;It&#39; &#39;includes&#39; &#39;the&#39; &#39;following&#39;
 &#39;contributions&#39; &#39;:&#39; &#39;(&#39; &#39;i&#39; &#39;)&#39; &#39;between&#39; &#39;the&#39; &#39;macroscopic&#39; &#39;Si&#39; &#39;tip&#39;
 &#39;of&#39; &#39;conical&#39; &#39;shape&#39; &#39;with&#39; &#39;the&#39; &#39;sphere&#39; &#39;of&#39; &#39;radius&#39; &#39;R&#39; &#39;at&#39; &#39;the&#39;
 &#39;end&#39; &#39;[&#39; &#39;27&#39; &#39;]&#39; &#39;and&#39; &#39;semi-infinite&#39; &#39;substrate&#39; &#39;;&#39; &#39;(&#39; &#39;ii&#39; &#39;)&#39;
 &#39;the&#39; &#39;dispersion&#39; &#39;forces&#39; &#39;between&#39; &#39;the&#39; &#39;atoms&#39; &#39;in&#39; &#39;the&#39; &#39;sample&#39;
 &#39;treated&#39; &#39;atomistically&#39; &#39;;&#39; &#39;and&#39; &#39;(&#39; &#39;iii&#39; &#39;)&#39; &#39;the&#39; &#39;interaction&#39;
 &#39;between&#39; &#39;the&#39; &#39;macroscopic&#39; &#39;part&#39; &#39;of&#39; &#39;the&#39; &#39;tip&#39; &#39;and&#39; &#39;the&#39;
 &#39;sample&#39; &#39;atoms&#39; &#39;.&#39; &#39;The&#39; &#39;first&#39; &#39;contribution&#39; &#39;is&#39; &#39;calculated&#39;
 &#39;analytically&#39; &#39;[&#39; &#39;27&#39; &#39;]&#39; &#39;.&#39; &#39;In&#39; &#39;fact&#39; &#39;,&#39; &#39;the&#39; &#39;macroscopic&#39;
 &#39;contribution&#39; &#39;to&#39; &#39;the&#39; &#39;van&#39; &#39;der&#39; &#39;Waals&#39; &#39;force&#39; &#39;is&#39; &#39;the&#39; &#39;same&#39;
 &#39;in&#39; &#39;each&#39; &#39;of&#39; &#39;the&#39; &#39;three&#39; &#39;systems&#39; &#39;described&#39; &#39;below&#39; &#39;,&#39; &#39;as&#39;
 &#39;it&#39; &#39;depends&#39; &#39;only&#39; &#39;on&#39; &#39;the&#39; &#39;tipsurface&#39; &#39;separation&#39; &#39;,&#39;
 &#39;macroscopic&#39; &#39;sphere&#39; &#39;radius&#39; &#39;,&#39; &#39;cone-angle&#39; &#39;and&#39; &#39;Hamaker&#39;
 &#39;constant&#39; &#39;of&#39; &#39;the&#39; &#39;system&#39; &#39;[&#39; &#39;27&#39; &#39;]&#39; &#39;.&#39; &#39;All&#39; &#39;these&#39;
 &#39;quantities&#39; &#39;are&#39; &#39;identical&#39; &#39;in&#39; &#39;each&#39; &#39;system&#39; &#39;we&#39; &#39;look&#39; &#39;at&#39; &#39;,&#39;
 &#39;so&#39; &#39;that&#39; &#39;the&#39; &#39;van&#39; &#39;der&#39; &#39;Waals&#39; &#39;force&#39; &#39;acts&#39; &#39;as&#39; &#39;a&#39;
 &#39;background&#39; &#39;attractive&#39; &#39;force&#39; &#39;independent&#39; &#39;of&#39; &#39;the&#39; &#39;microscopic&#39;
 &#39;properties&#39; &#39;of&#39; &#39;the&#39; &#39;system&#39; &#39;[&#39; &#39;8&#39; &#39;]&#39; &#39;.&#39; &#39;The&#39; &#39;Hamaker&#39;
 &#39;constant&#39; &#39;needed&#39; &#39;for&#39; &#39;the&#39; &#39;calculation&#39; &#39;of&#39; &#39;the&#39; &#39;macroscopic&#39;
 &#39;van&#39; &#39;der&#39; &#39;Waals&#39; &#39;force&#39; &#39;is&#39; &#39;estimated&#39; &#39;to&#39; &#39;be&#39; &#39;0.5eV&#39; &#39;[&#39; &#39;32&#39;
 &#39;]&#39; &#39;.&#39;]
[&#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;I&#39; &#39;I&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;I&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39;
 &#39;U&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;I&#39; &#39;I&#39;
 &#39;I&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;I&#39; &#39;I&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;I&#39; &#39;I&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;
 &#39;U&#39; &#39;O&#39; &#39;O&#39; &#39;B&#39; &#39;I&#39; &#39;I&#39; &#39;I&#39; &#39;L&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39; &#39;O&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_distrib</span><span class="p">(</span><span class="n">train_tags</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>REMARQUE</em></strong>
on remarque que le jeu de donnes est trs dsquilibr.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="b.&amp;c.-Models-et-Evaluations">b.&amp;c. Models et Evaluations<a class="anchor-link" href="#b.&amp;c.-Models-et-Evaluations">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CRF-simple">CRF simple<a class="anchor-link" href="#CRF-simple">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On utilise le modle propos par le tutoriel en ligne CRF avec l'algorithme L-BFGS et Elastic Net avec les rgulariseur (L1 + L2).</p>
<p><a href="https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#training">https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#training</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Pr&#233;traitement">Pr&#233;traitement<a class="anchor-link" href="#Pr&#233;traitement">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we define the input of our CRF by addind the POS tag for each sentence, </span>
<span class="c1"># we need them for the features of our CRF</span>
<span class="n">X_crf_train</span><span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag_sents</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">)</span>
<span class="n">X_crf_val</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag_sents</span><span class="p">(</span><span class="n">val_sentences</span><span class="p">)</span>
<span class="n">X_crf_test</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag_sents</span><span class="p">(</span><span class="n">test_sentences</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Definition-du-Model">Definition du Model<a class="anchor-link" href="#Definition-du-Model">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Features have been chosen based on what has been done on other models found on the internet and logical sense</span>
<span class="k">def</span> <span class="nf">features</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; sentence: [w1, w2, ...], index: the index of the word &quot;&quot;&quot;</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">postag</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">features</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;bias&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">,</span>
        <span class="s1">&#39;is_first&#39;</span><span class="p">:</span> <span class="n">index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s1">&#39;is_last&#39;</span><span class="p">:</span> <span class="n">index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;word.lower()&#39;</span><span class="p">:</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span>
        <span class="s1">&#39;word[-3:]&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:],</span>
        <span class="s1">&#39;word[-2:]&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:],</span>
        <span class="s1">&#39;prev_word&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span> <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
        <span class="s1">&#39;next_word&#39;</span><span class="p">:</span> <span class="s1">&#39;&#39;</span> <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
        <span class="s1">&#39;word.isupper()&#39;</span><span class="p">:</span> <span class="n">word</span><span class="o">.</span><span class="n">isupper</span><span class="p">(),</span>
        <span class="s1">&#39;word.istitle()&#39;</span><span class="p">:</span> <span class="n">word</span><span class="o">.</span><span class="n">istitle</span><span class="p">(),</span>
        <span class="s1">&#39;word.isdigit()&#39;</span><span class="p">:</span> <span class="n">word</span><span class="o">.</span><span class="n">isdigit</span><span class="p">(),</span>
        <span class="s1">&#39;postag&#39;</span><span class="p">:</span> <span class="n">postag</span><span class="p">,</span>
        <span class="s1">&#39;postag[:2]&#39;</span><span class="p">:</span> <span class="n">postag</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
        <span class="s1">&#39;postag[:-2]&#39;</span><span class="p">:</span> <span class="n">postag</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">index</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">word1</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">postag1</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">features</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
            <span class="s1">&#39;-1:word.lower()&#39;</span><span class="p">:</span> <span class="n">word1</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span>
            <span class="s1">&#39;-1:word.istitle()&#39;</span><span class="p">:</span> <span class="n">word1</span><span class="o">.</span><span class="n">istitle</span><span class="p">(),</span>
            <span class="s1">&#39;-1:word.isupper()&#39;</span><span class="p">:</span> <span class="n">word1</span><span class="o">.</span><span class="n">isupper</span><span class="p">(),</span>
            <span class="s1">&#39;-1:postag&#39;</span><span class="p">:</span> <span class="n">postag1</span><span class="p">,</span>
            <span class="s1">&#39;-1:postag[:2]&#39;</span><span class="p">:</span> <span class="n">postag1</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">})</span>

    <span class="k">if</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">word1</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">postag1</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">features</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
            <span class="s1">&#39;+1:word.lower()&#39;</span><span class="p">:</span> <span class="n">word1</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span>
            <span class="s1">&#39;+1:word.istitle()&#39;</span><span class="p">:</span> <span class="n">word1</span><span class="o">.</span><span class="n">istitle</span><span class="p">(),</span>
            <span class="s1">&#39;+1:word.isupper()&#39;</span><span class="p">:</span> <span class="n">word1</span><span class="o">.</span><span class="n">isupper</span><span class="p">(),</span>
            <span class="s1">&#39;+1:postag&#39;</span><span class="p">:</span> <span class="n">postag1</span><span class="p">,</span>
            <span class="s1">&#39;+1:postag[:2]&#39;</span><span class="p">:</span> <span class="n">postag1</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">})</span>
    <span class="k">return</span> <span class="n">features</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">transform_to_dataset</span><span class="p">(</span><span class="n">tagged_sentences</span><span class="p">):</span>
    <span class="n">X</span><span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">tagged</span> <span class="ow">in</span> <span class="n">tagged_sentences</span><span class="p">:</span>
      <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">features</span><span class="p">(</span><span class="n">tagged</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tagged</span><span class="p">))])</span>
 
    <span class="k">return</span> <span class="n">X</span>
<span class="n">CRF_train_sentences</span> <span class="o">=</span> <span class="n">transform_to_dataset</span><span class="p">(</span><span class="n">X_crf_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Entrainement-d'un-model">Entrainement d'un model<a class="anchor-link" href="#Entrainement-d'un-model">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> <span class="n">model_CRF_tacheA_</span> <span class="o">=</span> <span class="n">CRF</span><span class="p">(</span>
    <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span>
    <span class="n">c1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">c2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">max_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">all_possible_transitions</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

<span class="n">model_CRF_tacheA_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">CRF_train_sentences</span><span class="p">,</span> <span class="n">train_tags</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.
  FutureWarning)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>CRF(algorithm=&#39;lbfgs&#39;, all_possible_transitions=True, c1=0.1, c2=0.1,
    keep_tempfiles=None, max_iterations=100)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_CRF_tacheA</span> <span class="o">=</span> <span class="n">model_CRF_tacheA_</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Grid-search">Grid search<a class="anchor-link" href="#Grid-search">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">model_CRF_tacheA = CRF(</span>
<span class="sd">    algorithm=&#39;lbfgs&#39;,</span>
<span class="sd">    max_iterations=100,</span>
<span class="sd">    all_possible_transitions=True</span>
<span class="sd">    )</span>

<span class="sd">params_space = {</span>
<span class="sd">    &#39;c1&#39;: scipy.stats.expon(scale=0.5),</span>
<span class="sd">    &#39;c2&#39;: scipy.stats.expon(scale=0.05),</span>
<span class="sd">}</span>

<span class="sd">labels = list(model_CRF_tacheA_.classes_)</span>
<span class="sd">labels.remove(&#39;O&#39;)</span>

<span class="sd"># use the same metric for evaluation</span>
<span class="sd">f1_scorer = make_scorer(metrics.flat_f1_score,</span>
<span class="sd">                        average=&#39;weighted&#39;, labels=labels)</span>

<span class="sd"># search</span>
<span class="sd">rs = RandomizedSearchCV(model_CRF_tacheA, params_space,</span>
<span class="sd">                        cv=3,</span>
<span class="sd">                        verbose=1,</span>
<span class="sd">                        n_jobs=-1,</span>
<span class="sd">                        n_iter=50,</span>
<span class="sd">                        scoring=f1_scorer)</span>
<span class="sd">rs.fit(CRF_train_sentences, train_tags)</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;\nmodel_CRF_tacheA = CRF(\n    algorithm=&#39;lbfgs&#39;,\n    max_iterations=100,\n    all_possible_transitions=True\n    )\n\nparams_space = {\n    &#39;c1&#39;: scipy.stats.expon(scale=0.5),\n    &#39;c2&#39;: scipy.stats.expon(scale=0.05),\n}\n\nlabels = list(model_CRF_tacheA_.classes_)\nlabels.remove(&#39;O&#39;)\n\n# use the same metric for evaluation\nf1_scorer = make_scorer(metrics.flat_f1_score,\n                        average=&#39;weighted&#39;, labels=labels)\n\n# search\nrs = RandomizedSearchCV(model_CRF_tacheA, params_space,\n                        cv=3,\n                        verbose=1,\n                        n_jobs=-1,\n                        n_iter=50,\n                        scoring=f1_scorer)\nrs.fit(CRF_train_sentences, train_tags)\n&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">print(&#39;best params:&#39;, rs.best_params_)</span>
<span class="sd">print(&#39;best CV score:&#39;, rs.best_score_)</span>
<span class="sd">print(&#39;model size: {:0.2f}M&#39;.format(rs.best_estimator_.size_ / 1000000))</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;\nprint(&#39;best params:&#39;, rs.best_params_)\nprint(&#39;best CV score:&#39;, rs.best_score_)\nprint(&#39;model size: {:0.2f}M&#39;.format(rs.best_estimator_.size_ / 1000000))\n&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#model_CRF_tacheA = rs.best_estimator_</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="prediction">prediction<a class="anchor-link" href="#prediction">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tag_prediction</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
  <span class="n">X</span><span class="o">=</span> <span class="p">[]</span>
  <span class="n">Y</span><span class="o">=</span> <span class="p">[]</span>
  
  <span class="k">for</span> <span class="n">tagged</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="n">sentence_features</span><span class="o">=</span><span class="p">[</span><span class="n">features</span><span class="p">(</span><span class="n">tagged</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tagged</span><span class="p">))]</span>
    <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence_features</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">sentence_features</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
 
<span class="n">CRF_train_sentences</span><span class="p">,</span> <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">tag_prediction</span><span class="p">(</span><span class="n">X_crf_train</span><span class="p">,</span><span class="n">model_CRF_tacheA</span><span class="p">)</span>
<span class="n">CRF_val_sentences</span><span class="p">,</span> <span class="n">y_val_pred</span> <span class="o">=</span> <span class="n">tag_prediction</span><span class="p">(</span><span class="n">X_crf_val</span><span class="p">,</span><span class="n">model_CRF_tacheA</span><span class="p">)</span>
<span class="n">CRF_test_sentences</span><span class="p">,</span> <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">tag_prediction</span><span class="p">(</span><span class="n">X_crf_test</span><span class="p">,</span><span class="n">model_CRF_tacheA</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Evaluation-on-train-and-val-set">Evaluation on train and val set<a class="anchor-link" href="#Evaluation-on-train-and-val-set">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">CRF_show_confusion</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;f1 micro:{f1_score(y_true, y_pred, average=&#39;micro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;f1 micro:{f1_score(y_true, y_pred, average=&#39;macro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;recall macro:{recall_score(y_true, y_pred, average=&#39;macro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_CRF_tacheA</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">labels</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;O&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">flat_f1_score</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">val_tags</span><span class="p">)),</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_val_pred</span><span class="p">)),</span>
      <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.47435081824155995
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">flat_accuracy_score</span><span class="p">(</span><span class="n">val_tags</span><span class="p">,</span> <span class="n">y_val_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.7748409640713197
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">CRF_show_confusion</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">val_tags</span><span class="p">)),</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_val_pred</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>f1 micro:0.775
f1 micro:0.559
recall macro:0.539
Confusion Matrix:
[[ 324  109    1  248   12]
 [  71  462   43  482   14]
 [   0   54  407  224    9]
 [ 241  544  193 7335   27]
 [  37   29   29  146  120]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># labels results</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">model_CRF_tacheA</span><span class="o">.</span><span class="n">classes_</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">flat_classification_report</span><span class="p">(</span>
    <span class="n">y_val_pred</span><span class="p">,</span> <span class="n">val_tags</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">3</span>
<span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;O&#39;, &#39;B&#39;, &#39;L&#39;, &#39;U&#39;, &#39;I&#39;]
              precision    recall  f1-score   support

           O      0.879     0.870     0.875      8435
           B      0.467     0.481     0.474       673
           L      0.586     0.605     0.595       673
           U      0.332     0.659     0.442       182
           I      0.431     0.386     0.407      1198

    accuracy                          0.775     11161
   macro avg      0.539     0.600     0.559     11161
weighted avg      0.780     0.775     0.776     11161

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[&#39;O&#39;, &#39;B&#39;, &#39;L&#39;, &#39;U&#39;, &#39;I&#39;] as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Remarque</em></strong></p>
<p>Le CRF simple nous donne des rsultats assez mdiocres, on ne s'attendait pas  ce qu'il dpasse les state of the art mais nous l'avons implment pour valuer le modle et le tester tout simplement. On remarque que le dsquilibre du jeu de donnes se ressent dans les rsultats avec plus de 'O' prdis. Par contre le CRF propose des rsultats qui restent correctes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Submission-file-for-CRF">Submission file for CRF<a class="anchor-link" href="#Submission-file-for-CRF">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[102]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_val_csv</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_val_pred</span><span class="p">))</span>

<span class="n">CRF_val_df_soumission</span><span class="o">=</span><span class="n">val_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DocID&#39;</span><span class="p">,</span> <span class="s1">&#39;Token&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">CRF_val_df_soumission</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">y_val_csv</span>
<span class="n">CRF_val_df_soumission</span>

<span class="n">CRF_val_df_soumission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;CRF_submission_val_A.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_test_csv</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_test_pred</span><span class="p">))</span>

<span class="n">CRF_test_df_soumission</span><span class="o">=</span><span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DocID&#39;</span><span class="p">,</span> <span class="s1">&#39;Token&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">CRF_test_df_soumission</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">y_test_csv</span>
<span class="n">CRF_test_df_soumission</span>

<span class="n">CRF_test_df_soumission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;CRF_submission_test_A.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="BI-LSTM-et-Glove-Bilstm-CRF">BI LSTM et Glove-Bilstm-CRF<a class="anchor-link" href="#BI-LSTM-et-Glove-Bilstm-CRF">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Pr&#233;traitement">Pr&#233;traitement<a class="anchor-link" href="#Pr&#233;traitement">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we define the words through numbers/index to save space</span>
<span class="n">words</span><span class="p">,</span> <span class="n">tags</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(),</span> <span class="nb">set</span><span class="p">()</span>
 
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">train_sentences</span><span class="p">:</span>
  <span class="n">words</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
 
<span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">train_tags</span><span class="p">:</span>
  <span class="n">tags</span> <span class="o">=</span> <span class="n">tags</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ts</span><span class="p">))</span>
 
<span class="n">word2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">words</span><span class="p">))}</span>
<span class="n">word2index</span><span class="p">[</span><span class="s1">&#39;-PAD-&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># The special value used for padding</span>
<span class="n">word2index</span><span class="p">[</span><span class="s1">&#39;-OOV-&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># The special value used for OOVs</span>
 
<span class="c1"># defining tag to index mapping</span>
<span class="n">tag2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">t</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">tags</span><span class="p">))}</span>
<span class="n">tag2index</span><span class="p">[</span><span class="s1">&#39;-PAD-&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># The special value used to padding</span>
<span class="n">index2tag</span><span class="o">=</span><span class="p">{</span><span class="n">value</span><span class="p">:</span> <span class="n">key</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tag2index</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tag2index</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">index2tag</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_sentence_X</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
  <span class="n">sentences_X</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="n">s_int</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">s_int</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="n">w</span><span class="p">])</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">s_int</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word2index</span><span class="p">[</span><span class="s1">&#39;-OOV-&#39;</span><span class="p">])</span>
 
    <span class="n">sentences_X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s_int</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">sentences_X</span>
  
<span class="n">train_sentences_X_no_pad</span> <span class="o">=</span> <span class="n">get_sentence_X</span><span class="p">(</span><span class="n">train_sentences</span><span class="p">)</span>
<span class="n">val_sentences_X_no_pad</span>   <span class="o">=</span> <span class="n">get_sentence_X</span><span class="p">(</span><span class="n">val_sentences</span><span class="p">)</span>
<span class="n">test_sentences_X_no_pad</span>  <span class="o">=</span> <span class="n">get_sentence_X</span><span class="p">(</span><span class="n">test_sentences</span><span class="p">)</span>

<span class="n">train_tags_y_no_pad</span> <span class="o">=</span> <span class="p">[[</span><span class="n">tag2index</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">train_tags</span><span class="p">]</span>
<span class="n">val_tags_y_no_pad</span>   <span class="o">=</span> <span class="p">[[</span><span class="n">tag2index</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">val_tags</span><span class="p">]</span>
 
<span class="nb">print</span><span class="p">(</span><span class="n">train_sentences_X_no_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">val_sentences_X_no_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_tags_y_no_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">val_tags_y_no_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[5612, 1238, 1447, 8464, 4901, 5266, 3634, 3814, 6457, 4901, 5266, 7145, 5148, 6393, 7371, 8672, 849, 6328, 5282, 5222, 4902, 4903, 2228, 2304, 8268, 6421, 1447, 3318, 8989, 1291, 8672, 2408, 7447, 7931, 7625, 2614, 4901, 454, 2637, 7931, 806, 2614, 4267, 8528, 6941, 2304, 8268, 6421, 1447, 3886, 5148, 8189, 8984, 6602, 6941, 8989, 1291, 8672, 3718, 1087, 4563, 7931, 4831, 2614, 4901, 5675, 8953, 7081, 7931, 4611, 2614, 4267, 8672, 746, 4657, 6838, 1238, 5489, 4903, 6941, 2304, 5664, 4903, 2902, 1733, 8984, 6602, 6941, 2721, 9001, 5466, 2228, 4901, 8984, 3415, 1896, 8672, 3494, 4656, 4901, 4678, 4052, 8127, 8856, 4360, 4901, 192, 8044, 3830, 7082, 8672, 4393, 1292, 949, 140, 6941, 2304, 8268, 6602, 6941, 1923, 3886, 5148, 6602, 4077, 4985, 192, 2073, 4901, 1291, 8672, 6754, 5148, 3453, 4901, 5148, 8268, 3546, 408, 5282, 5222, 153, 8888, 8672, 2843, 6941, 192, 7275, 5148, 5282, 9001, 4550, 4286, 5148, 1195, 8672, 1538, 2304, 8285, 1089, 9034, 3419, 8942, 8463, 3569, 1956, 8989, 8528, 4589, 4267, 7413, 8528, 7289, 408, 8674, 1630, 7931, 4611, 2614, 8672, 4690, 4901, 6328, 7214, 259, 5222, 2385, 8127, 2435, 5148, 1470, 8127, 2601, 5266, 1616, 1500, 7931, 3522, 2614, 8528, 361, 755, 7931, 2057, 2614, 8672]
[440, 8127, 1, 1, 2169, 6602, 4872, 1, 4901, 6602, 4457, 5282, 5445, 4903, 4475, 8711, 8672, 1, 1448, 1089, 2580, 5266, 3802, 6235, 3353, 6602, 1, 8011, 8989, 1, 4267, 192, 8044, 1, 109, 4475, 3816, 2016, 259, 1533, 6765, 5259, 8127, 5526, 4901, 1, 7110, 8528, 4569, 3419, 8229, 1, 7931, 1, 2614, 4901, 3605, 6602, 8723, 2391, 6328, 919, 1447, 6673, 606, 3023, 7931, 1, 2614, 8672, 2843, 1018, 810, 4594, 1, 2391, 6602, 1, 4901, 1, 5148, 1, 1, 1447, 7928, 1, 4901, 1, 5148, 1, 4901, 8140, 8989, 2105, 2302, 8672, 3071, 4267, 4901, 5033, 6602, 810, 4594, 7572, 2391, 6602, 1, 8011, 192, 4189, 88, 4901, 7928, 1, 7931, 575, 2614, 8672, 1, 192, 6814, 5190, 4651, 1, 1, 1491, 1, 5148, 1639, 1, 8672, 3146, 192, 7026, 5154, 5077, 3353, 6602, 4457, 7900, 5222, 4986, 8127, 6765, 4118, 7295, 5266, 1, 919, 8672]
[1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 2, 5, 5, 5, 1, 2, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 2, 5, 5, 5, 5, 1, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 2, 5, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 3, 5, 5, 1, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
[5, 5, 1, 2, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 5, 3, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 3, 5, 3, 5, 1, 2, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 2, 5]

 [1, 6859, 6521, 1, 8989, 1, 4267, 2794, 2169, 1, 1, 1, 6246, 5113, 8984, 3415, 3546, 8579, 8516, 8127, 1, 5266, 2659, 1, 8672, 2843, 1, 5185, 2391, 1, 5266, 5190, 1, 1, 6246, 1959, 4819, 3621, 5190, 4429, 5642, 2391, 6602, 3282, 2446, 8638, 8672, 888, 5185, 6246, 1838, 8127, 7790, 1, 2650, 8989, 1, 4267, 1616, 5185, 4903, 8044, 1362, 2391, 8393, 1, 3344, 3569, 4429, 8891, 5148, 5697, 3253, 8989, 1, 750, 5393, 4901, 950, 4901, 1, 4901, 7889, 4901, 3460, 4267, 8672, 1279, 7357, 3703, 6287, 4673, 34, 841, 2169, 6602, 1, 1616, 8672, 1, 5148, 7477, 1762, 4903, 1525, 2203, 8672, 2843, 1, 1, 34, 8400, 6271, 8127, 5190, 4429, 1, 8989, 1, 1, 6199, 1, 1, 4901, 1, 1, 4901, 1, 4901, 3460, 4267, 8672, 2843, 2644, 2391, 6602, 5430, 6230, 34, 1, 4901, 5148, 6602, 4429, 1, 2446, 5642, 34, 7436, 3569, 1865, 3813, 8989, 1, 4267, 8672, 8993, 1, 5266, 3453, 4819, 5190, 6632, 8793, 4901, 6602, 1616, 2391, 6602, 4429, 1, 5642, 34, 1, 3622, 8816, 3888, 1, 8672]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># defininf the length of the longest sentence in the whole dataset</span>
<span class="n">MAX_LENGTH_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">train_sentences_X_no_pad</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">))</span>
<span class="n">MAX_LENGTH_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">val_sentences_X_no_pad</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">))</span>
<span class="n">MAX_LENGTH_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">))</span>
<span class="n">MAX_LENGTH</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">MAX_LENGTH_train</span> <span class="p">,</span> <span class="n">MAX_LENGTH_val</span><span class="p">,</span><span class="n">MAX_LENGTH_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>350
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Pad the sentences for bilstm entry</span>
 
<span class="n">train_sentences_X</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">train_sentences_X_no_pad</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>
<span class="n">val_sentences_X</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">val_sentences_X_no_pad</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>
<span class="n">test_sentences_X</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>

<span class="n">train_tags_y</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">train_tags_y_no_pad</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>
<span class="n">val_tags_y</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">val_tags_y_no_pad</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>

<span class="n">train_tags_y</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_tags_y</span><span class="p">)</span>
<span class="n">val_tags_y</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">val_tags_y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_sentences_X</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_tags_y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[5612 1238 1447 8464 4901 5266 3634 3814 6457 4901 5266 7145 5148 6393
 7371 8672  849 6328 5282 5222 4902 4903 2228 2304 8268 6421 1447 3318
 8989 1291 8672 2408 7447 7931 7625 2614 4901  454 2637 7931  806 2614
 4267 8528 6941 2304 8268 6421 1447 3886 5148 8189 8984 6602 6941 8989
 1291 8672 3718 1087 4563 7931 4831 2614 4901 5675 8953 7081 7931 4611
 2614 4267 8672  746 4657 6838 1238 5489 4903 6941 2304 5664 4903 2902
 1733 8984 6602 6941 2721 9001 5466 2228 4901 8984 3415 1896 8672 3494
 4656 4901 4678 4052 8127 8856 4360 4901  192 8044 3830 7082 8672 4393
 1292  949  140 6941 2304 8268 6602 6941 1923 3886 5148 6602 4077 4985
  192 2073 4901 1291 8672 6754 5148 3453 4901 5148 8268 3546  408 5282
 5222  153 8888 8672 2843 6941  192 7275 5148 5282 9001 4550 4286 5148
 1195 8672 1538 2304 8285 1089 9034 3419 8942 8463 3569 1956 8989 8528
 4589 4267 7413 8528 7289  408 8674 1630 7931 4611 2614 8672 4690 4901
 6328 7214  259 5222 2385 8127 2435 5148 1470 8127 2601 5266 1616 1500
 7931 3522 2614 8528  361  755 7931 2057 2614 8672    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0]
[[0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1.]
 ...
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Simple-Bilstm">Simple Bilstm<a class="anchor-link" href="#Simple-Bilstm">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="architecture-du-model">architecture du model<a class="anchor-link" href="#architecture-du-model">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="p">)))</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word2index</span><span class="p">),</span> <span class="mi">128</span><span class="p">))</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tag2index</span><span class="p">))))</span>
  <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
  
  <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">weighted_categorical_crossentropy</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">get_f1_micro</span><span class="p">,</span> <span class="n">get_f1_macro</span><span class="p">],</span>
                <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="benchmark/grid-search">benchmark/grid search<a class="anchor-link" href="#benchmark/grid-search">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">tag2weights_list = [</span>
<span class="sd">                    {&quot;-PAD-&quot;:1, &#39;O&#39;:1, &#39;U&#39;:1, &#39;I&#39;:1, &#39;B&#39;:1, &#39;L&#39;:1},</span>
<span class="sd">                    {&quot;-PAD-&quot;:1, &#39;O&#39;:1, &#39;U&#39;:2, &#39;I&#39;:2, &#39;B&#39;:2, &#39;L&#39;:2},</span>
<span class="sd">                    {&quot;-PAD-&quot;:1, &#39;O&#39;:1, &#39;U&#39;:10, &#39;I&#39;:10, &#39;B&#39;:10, &#39;L&#39;:10}</span>
<span class="sd">]</span>
<span class="sd">all_weights = [np.array([tag2weights[index2tag[i]] for i in range(len(tag2index))]) for tag2weights in tag2weights_list]</span>
<span class="sd">optimizers = [Adam(), SGD()]</span>
<span class="sd">models = [create_model(weights, optimizer) for weights in all_weights for optimizer in optimizers]</span>
<span class="sd">histories = []</span>
<span class="sd">for model in tqdm(models):</span>
<span class="sd">  histories.append(model.fit(train_sentences_X, train_tags_y, batch_size=32, epochs=15, validation_data=(val_sentences_X,val_tags_y), verbose=0))</span>
<span class="sd">metric_names = [&#39;loss&#39;, &#39;accuracy&#39;]</span>
<span class="sd">params = [([tag2weights[index2tag[i]] for i in range(len(tag2index))], optimizer) for tag2weights in tag2weights_list for optimizer in [&quot;adam&quot;, &#39;sgd&#39;]]</span>
<span class="sd">print_training(histories, metric_names, params)</span>
<span class="sd">#predictions_test = mymodel.predict(test_sentences_X)</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Bilstm-CRF-avec-glove-embedding">Bilstm-CRF avec glove embedding<a class="anchor-link" href="#Bilstm-CRF-avec-glove-embedding">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># fex parameters</span>
<span class="n">MAX_LEN</span> <span class="o">=</span> <span class="n">MAX_LENGTH</span>  <span class="c1"># Max length of words</span>
<span class="n">WORD_EMBEDDING_OUT_DIM</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">tags_A</span> <span class="o">=</span> <span class="n">tag2index</span>
<span class="n">n_tags_A</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tags_A</span><span class="p">)</span>
<span class="n">words_voc_A</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
<span class="n">n_words_A</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">words_voc_A</span><span class="p">)</span> <span class="o">+</span><span class="mi">2</span>
<span class="n">max_word_len_A</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">words_voc_A</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Definition-de-la-matrice-d'embedding-Glove">Definition de la matrice d'embedding Glove<a class="anchor-link" href="#Definition-de-la-matrice-d'embedding-Glove">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># definition of the embedding matrix</span>
<span class="n">words_not_found</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_words_A</span><span class="p">,</span> <span class="n">WORD_EMBEDDING_OUT_DIM</span><span class="p">))</span>

<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word2index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">n_words_A</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">embeddings_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">embedding_vector</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># words not found in embedding index will be all-zeros.</span>
        <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">words_not_found</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;number of null word embeddings: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>number of null word embeddings: 1302
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="D&#233;finition-du-mod&#233;le-Bilstm+Crf">D&#233;finition du mod&#233;le Bilstm+Crf<a class="anchor-link" href="#D&#233;finition-du-mod&#233;le-Bilstm+Crf">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On utilise la librairie tf2crf de pypi, qui est est un module permettant d'implmenter un layer crf sur tensorflow 2. Ici on utilise la fonction  ModelWithCRFLossDSCLoss qui permet d'uitiliser la fonction de cout DSC (Dice similarity coefficient) qui est trs pratique dans le cadre des donnes qui sont dsquilibre. On utilise galement de l'early stopping et un checkpoint conservant le meilleur modle en terme d'accuracy sur le validation set. Finalement, un embedding glove est utilis pour augementer nos performances. On compare galement le GRU et le LSTM comme layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_model_Bilstm_crf_A</span><span class="p">(</span> <span class="n">optimizer</span><span class="p">,</span><span class="n">embedding_name</span><span class="p">,</span><span class="n">layer</span><span class="p">,</span><span class="n">dropout</span><span class="p">,</span> <span class="n">unit</span><span class="p">):</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="p">))</span>
  <span class="k">if</span> <span class="n">embedding_name</span> <span class="o">==</span> <span class="s1">&#39;Glove&#39;</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">n_words_A</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">WORD_EMBEDDING_OUT_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">])(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">n_words_A</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">WORD_EMBEDDING_OUT_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="s1">&#39;GRU&#39;</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">unit</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">unit</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">crf</span> <span class="o">=</span> <span class="n">CRF</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">n_tags_A</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">crf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">base_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
  <span class="n">model_crf</span> <span class="o">=</span> <span class="n">ModelWithCRFLossDSCLoss</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span><span class="n">sparse_target</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">model_crf</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">model_crf</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Grid-search-sur-plusieurs-donn&#233;es">Grid search sur plusieurs donn&#233;es<a class="anchor-link" href="#Grid-search-sur-plusieurs-donn&#233;es">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ici on lance un grid search avec plusieurs paramtres diffrents</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;adam&#39;</span><span class="p">]</span> <span class="c1">#[&#39;adam&#39;,&#39;rmsprop&#39;,&#39;SGD&#39;]#[&#39;rmsprop&#39;,&#39;adam&#39;,&#39;SGD&#39;,&#39;adadelta&#39;]#[&#39;Adam()&#39;, &#39;SGD()&#39;, &#39;RMSprop()&#39;,&#39;Adagrad()&#39;,&#39;Adadelta()&#39;]</span>
<span class="n">all_dropouts</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">]</span>
<span class="n">units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">64</span><span class="p">]</span> <span class="c1">#[10, 64, 150, 250]</span>
<span class="n">embeddin_meth</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Glove&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="c1">#[&#39;Glove&#39;, None] </span>
<span class="n">models_bilstm_crf_param_A</span> <span class="o">=</span> <span class="p">[[</span><span class="n">optimizer</span><span class="p">,</span><span class="n">embedding_name</span><span class="p">,</span><span class="n">layer</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">unit</span><span class="p">]</span> <span class="k">for</span> <span class="n">unit</span> <span class="ow">in</span> <span class="n">units</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;GRU&#39;</span><span class="p">,</span> <span class="s1">&#39;LSTM&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">dropout</span> <span class="ow">in</span> <span class="n">all_dropouts</span> <span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span> <span class="k">for</span> <span class="n">embedding_name</span> <span class="ow">in</span>  <span class="n">embeddin_meth</span> <span class="p">]</span>
<span class="n">models_bilstm_crf_A</span><span class="o">=</span> <span class="p">[</span><span class="n">create_model_Bilstm_crf_A</span><span class="p">(</span> <span class="n">optimizer</span><span class="p">,</span><span class="n">embedding_name</span><span class="p">,</span><span class="n">layer</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">unit</span><span class="p">)</span> <span class="k">for</span> <span class="n">unit</span> <span class="ow">in</span> <span class="n">units</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;GRU&#39;</span><span class="p">,</span> <span class="s1">&#39;LSTM&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">dropout</span> <span class="ow">in</span> <span class="n">all_dropouts</span> <span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span> <span class="k">for</span> <span class="n">embedding_name</span> <span class="ow">in</span>  <span class="n">embeddin_meth</span> <span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">callback2_A</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss_val&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">histories_A_Bilstm_crf</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">model</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">models_bilstm_crf_A</span><span class="p">)):</span>
  <span class="n">checkpoint2_A</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;./models/Bilstm_crf/best_model_bilstm_A&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;.hdf5&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_val_accuracy&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">histories_A_Bilstm_crf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_sentences_X</span><span class="p">,</span> <span class="n">train_tags_y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">,</span><span class="n">val_tags_y</span><span class="p">),</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint2_A</span><span class="p">,</span><span class="n">callback2_A</span><span class="p">],</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>0it [00:00, ?it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 408.1556 - accuracy: 0.8245
Epoch 00001: val_val_accuracy improved from -inf to 0.85314, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 27s 872ms/step - loss: 408.1556 - accuracy: 0.8245 - val_loss_val: 319.8029 - val_val_accuracy: 0.8531
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 270.2895 - accuracy: 0.8632
Epoch 00002: val_val_accuracy improved from 0.85314 to 0.85428, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 717ms/step - loss: 270.2895 - accuracy: 0.8632 - val_loss_val: 220.0158 - val_val_accuracy: 0.8543
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 185.2820 - accuracy: 0.8650
Epoch 00003: val_val_accuracy improved from 0.85428 to 0.85495, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 715ms/step - loss: 185.2820 - accuracy: 0.8650 - val_loss_val: 173.3734 - val_val_accuracy: 0.8549
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 149.2076 - accuracy: 0.8662
Epoch 00004: val_val_accuracy improved from 0.85495 to 0.85655, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 709ms/step - loss: 149.2076 - accuracy: 0.8662 - val_loss_val: 157.4285 - val_val_accuracy: 0.8565
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 134.7961 - accuracy: 0.8685
Epoch 00005: val_val_accuracy improved from 0.85655 to 0.85768, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 714ms/step - loss: 134.7961 - accuracy: 0.8685 - val_loss_val: 147.2958 - val_val_accuracy: 0.8577
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 125.6658 - accuracy: 0.8711
Epoch 00006: val_val_accuracy improved from 0.85768 to 0.85933, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 708ms/step - loss: 125.6658 - accuracy: 0.8711 - val_loss_val: 140.4553 - val_val_accuracy: 0.8593
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 119.0472 - accuracy: 0.8732
Epoch 00007: val_val_accuracy improved from 0.85933 to 0.86067, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 705ms/step - loss: 119.0472 - accuracy: 0.8732 - val_loss_val: 135.0703 - val_val_accuracy: 0.8607
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 112.8316 - accuracy: 0.8778
Epoch 00008: val_val_accuracy did not improve from 0.86067
11/11 [==============================] - 7s 678ms/step - loss: 112.8316 - accuracy: 0.8778 - val_loss_val: 131.3474 - val_val_accuracy: 0.8599
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 107.3018 - accuracy: 0.8819
Epoch 00009: val_val_accuracy improved from 0.86067 to 0.86361, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 709ms/step - loss: 107.3018 - accuracy: 0.8819 - val_loss_val: 127.4926 - val_val_accuracy: 0.8636
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 102.4262 - accuracy: 0.8852
Epoch 00010: val_val_accuracy improved from 0.86361 to 0.86515, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 11s 1s/step - loss: 102.4262 - accuracy: 0.8852 - val_loss_val: 123.3809 - val_val_accuracy: 0.8652
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 97.5829 - accuracy: 0.8904
Epoch 00011: val_val_accuracy improved from 0.86515 to 0.86691, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 712ms/step - loss: 97.5829 - accuracy: 0.8904 - val_loss_val: 121.0134 - val_val_accuracy: 0.8669
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 93.2918 - accuracy: 0.8953
Epoch 00012: val_val_accuracy improved from 0.86691 to 0.86753, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 711ms/step - loss: 93.2918 - accuracy: 0.8953 - val_loss_val: 118.9325 - val_val_accuracy: 0.8675
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 88.7594 - accuracy: 0.9018
Epoch 00013: val_val_accuracy improved from 0.86753 to 0.86840, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 719ms/step - loss: 88.7594 - accuracy: 0.9018 - val_loss_val: 116.6680 - val_val_accuracy: 0.8684
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 84.7835 - accuracy: 0.9064
Epoch 00014: val_val_accuracy improved from 0.86840 to 0.87299, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 708ms/step - loss: 84.7835 - accuracy: 0.9064 - val_loss_val: 114.5204 - val_val_accuracy: 0.8730
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 81.2092 - accuracy: 0.9106
Epoch 00015: val_val_accuracy did not improve from 0.87299
11/11 [==============================] - 8s 689ms/step - loss: 81.2092 - accuracy: 0.9106 - val_loss_val: 112.0115 - val_val_accuracy: 0.8713
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 77.1020 - accuracy: 0.9165
Epoch 00016: val_val_accuracy did not improve from 0.87299
11/11 [==============================] - 7s 680ms/step - loss: 77.1020 - accuracy: 0.9165 - val_loss_val: 111.9755 - val_val_accuracy: 0.8712
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 73.2263 - accuracy: 0.9214
Epoch 00017: val_val_accuracy did not improve from 0.87299
11/11 [==============================] - 7s 676ms/step - loss: 73.2263 - accuracy: 0.9214 - val_loss_val: 110.0395 - val_val_accuracy: 0.8729
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 70.1145 - accuracy: 0.9259
Epoch 00018: val_val_accuracy did not improve from 0.87299
11/11 [==============================] - 7s 676ms/step - loss: 70.1145 - accuracy: 0.9259 - val_loss_val: 108.2439 - val_val_accuracy: 0.8726
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 67.0302 - accuracy: 0.9302
Epoch 00019: val_val_accuracy improved from 0.87299 to 0.87376, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 9s 814ms/step - loss: 67.0302 - accuracy: 0.9302 - val_loss_val: 107.6265 - val_val_accuracy: 0.8738
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 64.1392 - accuracy: 0.9339
Epoch 00020: val_val_accuracy improved from 0.87376 to 0.87428, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 709ms/step - loss: 64.1392 - accuracy: 0.9339 - val_loss_val: 106.4183 - val_val_accuracy: 0.8743
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 61.3323 - accuracy: 0.9365
Epoch 00021: val_val_accuracy did not improve from 0.87428
11/11 [==============================] - 8s 685ms/step - loss: 61.3323 - accuracy: 0.9365 - val_loss_val: 105.2593 - val_val_accuracy: 0.8731
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 58.5908 - accuracy: 0.9409
Epoch 00022: val_val_accuracy did not improve from 0.87428
11/11 [==============================] - 7s 676ms/step - loss: 58.5908 - accuracy: 0.9409 - val_loss_val: 105.1700 - val_val_accuracy: 0.8741
Epoch 23/50
11/11 [==============================] - ETA: 0s - loss: 55.9540 - accuracy: 0.9433
Epoch 00023: val_val_accuracy did not improve from 0.87428
11/11 [==============================] - 7s 679ms/step - loss: 55.9540 - accuracy: 0.9433 - val_loss_val: 105.2442 - val_val_accuracy: 0.8742
Epoch 24/50
11/11 [==============================] - ETA: 0s - loss: 53.9516 - accuracy: 0.9466
Epoch 00024: val_val_accuracy improved from 0.87428 to 0.87479, saving model to ./models/Bilstm_crf/best_model_bilstm_A0.hdf5
11/11 [==============================] - 8s 716ms/step - loss: 53.9516 - accuracy: 0.9466 - val_loss_val: 105.0789 - val_val_accuracy: 0.8748
Epoch 25/50
11/11 [==============================] - ETA: 0s - loss: 51.4262 - accuracy: 0.9487
Epoch 00025: val_val_accuracy did not improve from 0.87479
11/11 [==============================] - 8s 686ms/step - loss: 51.4262 - accuracy: 0.9487 - val_loss_val: 105.1767 - val_val_accuracy: 0.8711
Epoch 26/50
11/11 [==============================] - ETA: 0s - loss: 49.4750 - accuracy: 0.9525
Epoch 00026: val_val_accuracy did not improve from 0.87479
11/11 [==============================] - 7s 673ms/step - loss: 49.4750 - accuracy: 0.9525 - val_loss_val: 105.2492 - val_val_accuracy: 0.8686
Epoch 27/50
11/11 [==============================] - ETA: 0s - loss: 47.8141 - accuracy: 0.9531
Epoch 00027: val_val_accuracy did not improve from 0.87479
11/11 [==============================] - 7s 680ms/step - loss: 47.8141 - accuracy: 0.9531 - val_loss_val: 104.1259 - val_val_accuracy: 0.8716
Epoch 28/50
11/11 [==============================] - ETA: 0s - loss: 45.5654 - accuracy: 0.9564
Epoch 00028: val_val_accuracy did not improve from 0.87479
11/11 [==============================] - 7s 676ms/step - loss: 45.5654 - accuracy: 0.9564 - val_loss_val: 105.2187 - val_val_accuracy: 0.8710
Epoch 29/50
11/11 [==============================] - ETA: 0s - loss: 43.6988 - accuracy: 0.9582
Epoch 00029: val_val_accuracy did not improve from 0.87479
11/11 [==============================] - 7s 675ms/step - loss: 43.6988 - accuracy: 0.9582 - val_loss_val: 105.1298 - val_val_accuracy: 0.8694
Epoch 30/50
11/11 [==============================] - ETA: 0s - loss: 42.5566 - accuracy: 0.9589
Epoch 00030: val_val_accuracy did not improve from 0.87479
11/11 [==============================] - 7s 678ms/step - loss: 42.5566 - accuracy: 0.9589 - val_loss_val: 106.9442 - val_val_accuracy: 0.8698
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>1it [04:12, 252.82s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 503.0184 - accuracy: 0.4878
Epoch 00001: val_val_accuracy improved from -inf to 0.42469, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 17s 872ms/step - loss: 503.0184 - accuracy: 0.4878 - val_loss_val: 478.4823 - val_val_accuracy: 0.4247
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 375.8264 - accuracy: 0.5276
Epoch 00002: val_val_accuracy improved from 0.42469 to 0.42572, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 691ms/step - loss: 375.8264 - accuracy: 0.5276 - val_loss_val: 379.1693 - val_val_accuracy: 0.4257
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 288.1357 - accuracy: 0.5999
Epoch 00003: val_val_accuracy improved from 0.42572 to 0.76902, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 716ms/step - loss: 288.1357 - accuracy: 0.5999 - val_loss_val: 296.6234 - val_val_accuracy: 0.7690
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 218.9512 - accuracy: 0.8637
Epoch 00004: val_val_accuracy improved from 0.76902 to 0.85082, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 713ms/step - loss: 218.9512 - accuracy: 0.8637 - val_loss_val: 222.0821 - val_val_accuracy: 0.8508
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 169.0762 - accuracy: 0.8656
Epoch 00005: val_val_accuracy improved from 0.85082 to 0.85428, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 716ms/step - loss: 169.0762 - accuracy: 0.8656 - val_loss_val: 179.5650 - val_val_accuracy: 0.8543
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 145.7827 - accuracy: 0.8653
Epoch 00006: val_val_accuracy improved from 0.85428 to 0.85464, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 714ms/step - loss: 145.7827 - accuracy: 0.8653 - val_loss_val: 163.2454 - val_val_accuracy: 0.8546
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 132.0676 - accuracy: 0.8684
Epoch 00007: val_val_accuracy improved from 0.85464 to 0.85716, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 718ms/step - loss: 132.0676 - accuracy: 0.8684 - val_loss_val: 154.8576 - val_val_accuracy: 0.8572
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 121.2176 - accuracy: 0.8807
Epoch 00008: val_val_accuracy improved from 0.85716 to 0.85923, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 719ms/step - loss: 121.2176 - accuracy: 0.8807 - val_loss_val: 149.8229 - val_val_accuracy: 0.8592
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 112.6191 - accuracy: 0.8923
Epoch 00009: val_val_accuracy improved from 0.85923 to 0.86186, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 715ms/step - loss: 112.6191 - accuracy: 0.8923 - val_loss_val: 144.9431 - val_val_accuracy: 0.8619
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 105.0566 - accuracy: 0.9000
Epoch 00010: val_val_accuracy improved from 0.86186 to 0.86418, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 712ms/step - loss: 105.0566 - accuracy: 0.9000 - val_loss_val: 141.0876 - val_val_accuracy: 0.8642
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 98.2960 - accuracy: 0.9067
Epoch 00011: val_val_accuracy improved from 0.86418 to 0.86567, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 717ms/step - loss: 98.2960 - accuracy: 0.9067 - val_loss_val: 137.9512 - val_val_accuracy: 0.8657
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 91.8609 - accuracy: 0.9144
Epoch 00012: val_val_accuracy improved from 0.86567 to 0.86742, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 712ms/step - loss: 91.8609 - accuracy: 0.9144 - val_loss_val: 135.9150 - val_val_accuracy: 0.8674
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 86.0059 - accuracy: 0.9237
Epoch 00013: val_val_accuracy improved from 0.86742 to 0.86876, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 713ms/step - loss: 86.0059 - accuracy: 0.9237 - val_loss_val: 133.9197 - val_val_accuracy: 0.8688
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 80.5370 - accuracy: 0.9306
Epoch 00014: val_val_accuracy improved from 0.86876 to 0.86964, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 713ms/step - loss: 80.5370 - accuracy: 0.9306 - val_loss_val: 132.2146 - val_val_accuracy: 0.8696
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 75.3754 - accuracy: 0.9349
Epoch 00015: val_val_accuracy improved from 0.86964 to 0.87021, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 719ms/step - loss: 75.3754 - accuracy: 0.9349 - val_loss_val: 130.8894 - val_val_accuracy: 0.8702
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 70.7845 - accuracy: 0.9399
Epoch 00016: val_val_accuracy did not improve from 0.87021
11/11 [==============================] - 8s 689ms/step - loss: 70.7845 - accuracy: 0.9399 - val_loss_val: 130.0584 - val_val_accuracy: 0.8688
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 66.4935 - accuracy: 0.9439
Epoch 00017: val_val_accuracy improved from 0.87021 to 0.87041, saving model to ./models/Bilstm_crf/best_model_bilstm_A1.hdf5
11/11 [==============================] - 8s 723ms/step - loss: 66.4935 - accuracy: 0.9439 - val_loss_val: 129.1717 - val_val_accuracy: 0.8704
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 62.5794 - accuracy: 0.9467
Epoch 00018: val_val_accuracy did not improve from 0.87041
11/11 [==============================] - 8s 687ms/step - loss: 62.5794 - accuracy: 0.9467 - val_loss_val: 128.8878 - val_val_accuracy: 0.8691
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 59.1227 - accuracy: 0.9503
Epoch 00019: val_val_accuracy did not improve from 0.87041
11/11 [==============================] - 7s 681ms/step - loss: 59.1227 - accuracy: 0.9503 - val_loss_val: 128.1987 - val_val_accuracy: 0.8682
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 56.0452 - accuracy: 0.9531
Epoch 00020: val_val_accuracy did not improve from 0.87041
11/11 [==============================] - 7s 681ms/step - loss: 56.0452 - accuracy: 0.9531 - val_loss_val: 128.3723 - val_val_accuracy: 0.8678
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 53.0496 - accuracy: 0.9553
Epoch 00021: val_val_accuracy did not improve from 0.87041
11/11 [==============================] - 7s 678ms/step - loss: 53.0496 - accuracy: 0.9553 - val_loss_val: 128.2354 - val_val_accuracy: 0.8681
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 50.4047 - accuracy: 0.9583
Epoch 00022: val_val_accuracy did not improve from 0.87041
11/11 [==============================] - 7s 679ms/step - loss: 50.4047 - accuracy: 0.9583 - val_loss_val: 128.3351 - val_val_accuracy: 0.8681
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>2it [07:38, 225.00s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 742.4615 - accuracy: 0.1056
Epoch 00001: val_val_accuracy improved from -inf to 0.41778, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 17s 863ms/step - loss: 742.4615 - accuracy: 0.1056 - val_loss_val: 617.0889 - val_val_accuracy: 0.4178
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 615.9537 - accuracy: 0.3342
Epoch 00002: val_val_accuracy improved from 0.41778 to 0.43000, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 7s 674ms/step - loss: 615.9537 - accuracy: 0.3342 - val_loss_val: 503.7560 - val_val_accuracy: 0.4300
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 482.8935 - accuracy: 0.4193
Epoch 00003: val_val_accuracy improved from 0.43000 to 0.83572, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 7s 674ms/step - loss: 482.8935 - accuracy: 0.4193 - val_loss_val: 378.2153 - val_val_accuracy: 0.8357
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 339.3403 - accuracy: 0.8564
Epoch 00004: val_val_accuracy improved from 0.83572 to 0.85201, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 697ms/step - loss: 339.3403 - accuracy: 0.8564 - val_loss_val: 277.2865 - val_val_accuracy: 0.8520
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 243.4981 - accuracy: 0.8629
Epoch 00005: val_val_accuracy improved from 0.85201 to 0.85356, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 698ms/step - loss: 243.4981 - accuracy: 0.8629 - val_loss_val: 221.0386 - val_val_accuracy: 0.8536
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 193.4892 - accuracy: 0.8646
Epoch 00006: val_val_accuracy improved from 0.85356 to 0.85464, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 701ms/step - loss: 193.4892 - accuracy: 0.8646 - val_loss_val: 192.9861 - val_val_accuracy: 0.8546
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 168.1801 - accuracy: 0.8657
Epoch 00007: val_val_accuracy improved from 0.85464 to 0.85510, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 698ms/step - loss: 168.1801 - accuracy: 0.8657 - val_loss_val: 177.8651 - val_val_accuracy: 0.8551
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 153.9174 - accuracy: 0.8673
Epoch 00008: val_val_accuracy improved from 0.85510 to 0.85526, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 695ms/step - loss: 153.9174 - accuracy: 0.8673 - val_loss_val: 167.9852 - val_val_accuracy: 0.8553
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 144.0385 - accuracy: 0.8692
Epoch 00009: val_val_accuracy improved from 0.85526 to 0.85680, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 697ms/step - loss: 144.0385 - accuracy: 0.8692 - val_loss_val: 161.0492 - val_val_accuracy: 0.8568
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 136.6276 - accuracy: 0.8721
Epoch 00010: val_val_accuracy improved from 0.85680 to 0.85856, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 694ms/step - loss: 136.6276 - accuracy: 0.8721 - val_loss_val: 155.1065 - val_val_accuracy: 0.8586
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 130.4489 - accuracy: 0.8751
Epoch 00011: val_val_accuracy improved from 0.85856 to 0.86005, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 707ms/step - loss: 130.4489 - accuracy: 0.8751 - val_loss_val: 150.6991 - val_val_accuracy: 0.8601
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 124.9412 - accuracy: 0.8791
Epoch 00012: val_val_accuracy improved from 0.86005 to 0.86201, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 700ms/step - loss: 124.9412 - accuracy: 0.8791 - val_loss_val: 146.8780 - val_val_accuracy: 0.8620
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 120.5122 - accuracy: 0.8815
Epoch 00013: val_val_accuracy did not improve from 0.86201
11/11 [==============================] - 7s 671ms/step - loss: 120.5122 - accuracy: 0.8815 - val_loss_val: 143.6225 - val_val_accuracy: 0.8614
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 115.8515 - accuracy: 0.8863
Epoch 00014: val_val_accuracy improved from 0.86201 to 0.86459, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 700ms/step - loss: 115.8515 - accuracy: 0.8863 - val_loss_val: 140.9211 - val_val_accuracy: 0.8646
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 111.7748 - accuracy: 0.8897
Epoch 00015: val_val_accuracy improved from 0.86459 to 0.86716, saving model to ./models/Bilstm_crf/best_model_bilstm_A2.hdf5
11/11 [==============================] - 8s 704ms/step - loss: 111.7748 - accuracy: 0.8897 - val_loss_val: 137.8863 - val_val_accuracy: 0.8672
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 107.9929 - accuracy: 0.8934
Epoch 00016: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 669ms/step - loss: 107.9929 - accuracy: 0.8934 - val_loss_val: 136.5431 - val_val_accuracy: 0.8655
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 104.3382 - accuracy: 0.8977
Epoch 00017: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 670ms/step - loss: 104.3382 - accuracy: 0.8977 - val_loss_val: 134.5343 - val_val_accuracy: 0.8658
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 100.9835 - accuracy: 0.9002
Epoch 00018: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 666ms/step - loss: 100.9835 - accuracy: 0.9002 - val_loss_val: 132.5215 - val_val_accuracy: 0.8645
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 97.6702 - accuracy: 0.9069
Epoch 00019: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 664ms/step - loss: 97.6702 - accuracy: 0.9069 - val_loss_val: 132.1455 - val_val_accuracy: 0.8648
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 94.5155 - accuracy: 0.9079
Epoch 00020: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 670ms/step - loss: 94.5155 - accuracy: 0.9079 - val_loss_val: 130.4512 - val_val_accuracy: 0.8645
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 91.2579 - accuracy: 0.9135
Epoch 00021: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 666ms/step - loss: 91.2579 - accuracy: 0.9135 - val_loss_val: 129.1151 - val_val_accuracy: 0.8662
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 88.1726 - accuracy: 0.9172
Epoch 00022: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 667ms/step - loss: 88.1726 - accuracy: 0.9172 - val_loss_val: 128.4799 - val_val_accuracy: 0.8654
Epoch 23/50
11/11 [==============================] - ETA: 0s - loss: 85.3496 - accuracy: 0.9204
Epoch 00023: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 677ms/step - loss: 85.3496 - accuracy: 0.9204 - val_loss_val: 127.5776 - val_val_accuracy: 0.8638
Epoch 24/50
11/11 [==============================] - ETA: 0s - loss: 82.7516 - accuracy: 0.9238
Epoch 00024: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 677ms/step - loss: 82.7516 - accuracy: 0.9238 - val_loss_val: 126.9635 - val_val_accuracy: 0.8665
Epoch 25/50
11/11 [==============================] - ETA: 0s - loss: 79.8203 - accuracy: 0.9270
Epoch 00025: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 664ms/step - loss: 79.8203 - accuracy: 0.9270 - val_loss_val: 126.7819 - val_val_accuracy: 0.8634
Epoch 26/50
11/11 [==============================] - ETA: 0s - loss: 77.4260 - accuracy: 0.9298
Epoch 00026: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 662ms/step - loss: 77.4260 - accuracy: 0.9298 - val_loss_val: 127.7902 - val_val_accuracy: 0.8617
Epoch 27/50
11/11 [==============================] - ETA: 0s - loss: 74.6847 - accuracy: 0.9331
Epoch 00027: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 665ms/step - loss: 74.6847 - accuracy: 0.9331 - val_loss_val: 126.3179 - val_val_accuracy: 0.8632
Epoch 28/50
11/11 [==============================] - ETA: 0s - loss: 72.5325 - accuracy: 0.9350
Epoch 00028: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 663ms/step - loss: 72.5325 - accuracy: 0.9350 - val_loss_val: 127.2918 - val_val_accuracy: 0.8631
Epoch 29/50
11/11 [==============================] - ETA: 0s - loss: 70.2593 - accuracy: 0.9371
Epoch 00029: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 665ms/step - loss: 70.2593 - accuracy: 0.9371 - val_loss_val: 125.4094 - val_val_accuracy: 0.8652
Epoch 30/50
11/11 [==============================] - ETA: 0s - loss: 68.0090 - accuracy: 0.9401
Epoch 00030: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 669ms/step - loss: 68.0090 - accuracy: 0.9401 - val_loss_val: 126.7594 - val_val_accuracy: 0.8634
Epoch 31/50
11/11 [==============================] - ETA: 0s - loss: 65.9041 - accuracy: 0.9422
Epoch 00031: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 658ms/step - loss: 65.9041 - accuracy: 0.9422 - val_loss_val: 127.8074 - val_val_accuracy: 0.8632
Epoch 32/50
11/11 [==============================] - ETA: 0s - loss: 63.7840 - accuracy: 0.9445
Epoch 00032: val_val_accuracy did not improve from 0.86716
11/11 [==============================] - 7s 664ms/step - loss: 63.7840 - accuracy: 0.9445 - val_loss_val: 127.1277 - val_val_accuracy: 0.8616
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>3it [12:16, 249.10s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 813.2711 - accuracy: 0.2275
Epoch 00001: val_val_accuracy improved from -inf to 0.26753, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 17s 856ms/step - loss: 813.2711 - accuracy: 0.2275 - val_loss_val: 723.2390 - val_val_accuracy: 0.2675
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 590.4734 - accuracy: 0.4268
Epoch 00002: val_val_accuracy improved from 0.26753 to 0.47923, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 9s 811ms/step - loss: 590.4734 - accuracy: 0.4268 - val_loss_val: 533.1318 - val_val_accuracy: 0.4792
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 412.7198 - accuracy: 0.6604
Epoch 00003: val_val_accuracy improved from 0.47923 to 0.66510, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 10s 715ms/step - loss: 412.7198 - accuracy: 0.6604 - val_loss_val: 391.2334 - val_val_accuracy: 0.6651
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 302.7714 - accuracy: 0.7334
Epoch 00004: val_val_accuracy improved from 0.66510 to 0.76067, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 696ms/step - loss: 302.7714 - accuracy: 0.7334 - val_loss_val: 298.5576 - val_val_accuracy: 0.7607
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 238.1145 - accuracy: 0.8461
Epoch 00005: val_val_accuracy improved from 0.76067 to 0.84809, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 7s 687ms/step - loss: 238.1145 - accuracy: 0.8461 - val_loss_val: 240.5229 - val_val_accuracy: 0.8481
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 201.9463 - accuracy: 0.8604
Epoch 00006: val_val_accuracy improved from 0.84809 to 0.85098, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 691ms/step - loss: 201.9463 - accuracy: 0.8604 - val_loss_val: 211.4399 - val_val_accuracy: 0.8510
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 182.7852 - accuracy: 0.8621
Epoch 00007: val_val_accuracy improved from 0.85098 to 0.85206, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 693ms/step - loss: 182.7852 - accuracy: 0.8621 - val_loss_val: 196.4420 - val_val_accuracy: 0.8521
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 169.6782 - accuracy: 0.8633
Epoch 00008: val_val_accuracy improved from 0.85206 to 0.85263, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 694ms/step - loss: 169.6782 - accuracy: 0.8633 - val_loss_val: 186.5994 - val_val_accuracy: 0.8526
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 158.8791 - accuracy: 0.8649
Epoch 00009: val_val_accuracy improved from 0.85263 to 0.85284, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 700ms/step - loss: 158.8791 - accuracy: 0.8649 - val_loss_val: 179.2210 - val_val_accuracy: 0.8528
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 150.0727 - accuracy: 0.8677
Epoch 00010: val_val_accuracy improved from 0.85284 to 0.85356, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 691ms/step - loss: 150.0727 - accuracy: 0.8677 - val_loss_val: 172.8640 - val_val_accuracy: 0.8536
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 142.3945 - accuracy: 0.8707
Epoch 00011: val_val_accuracy improved from 0.85356 to 0.85505, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 696ms/step - loss: 142.3945 - accuracy: 0.8707 - val_loss_val: 166.6411 - val_val_accuracy: 0.8551
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 135.6338 - accuracy: 0.8742
Epoch 00012: val_val_accuracy improved from 0.85505 to 0.85582, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 697ms/step - loss: 135.6338 - accuracy: 0.8742 - val_loss_val: 162.0122 - val_val_accuracy: 0.8558
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 129.5919 - accuracy: 0.8792
Epoch 00013: val_val_accuracy improved from 0.85582 to 0.85794, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 692ms/step - loss: 129.5919 - accuracy: 0.8792 - val_loss_val: 158.0872 - val_val_accuracy: 0.8579
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 124.1356 - accuracy: 0.8842
Epoch 00014: val_val_accuracy improved from 0.85794 to 0.85964, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 9s 850ms/step - loss: 124.1356 - accuracy: 0.8842 - val_loss_val: 154.6490 - val_val_accuracy: 0.8596
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 119.2670 - accuracy: 0.8895
Epoch 00015: val_val_accuracy improved from 0.85964 to 0.85990, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 694ms/step - loss: 119.2670 - accuracy: 0.8895 - val_loss_val: 152.0501 - val_val_accuracy: 0.8599
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 114.5187 - accuracy: 0.8954
Epoch 00016: val_val_accuracy improved from 0.85990 to 0.86124, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 699ms/step - loss: 114.5187 - accuracy: 0.8954 - val_loss_val: 149.5993 - val_val_accuracy: 0.8612
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 110.1428 - accuracy: 0.9004
Epoch 00017: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 666ms/step - loss: 110.1428 - accuracy: 0.9004 - val_loss_val: 147.4149 - val_val_accuracy: 0.8606
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 105.8828 - accuracy: 0.9055
Epoch 00018: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 667ms/step - loss: 105.8828 - accuracy: 0.9055 - val_loss_val: 145.4979 - val_val_accuracy: 0.8610
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 101.9472 - accuracy: 0.9092
Epoch 00019: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 666ms/step - loss: 101.9472 - accuracy: 0.9092 - val_loss_val: 143.7287 - val_val_accuracy: 0.8610
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 98.1668 - accuracy: 0.9130
Epoch 00020: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 664ms/step - loss: 98.1668 - accuracy: 0.9130 - val_loss_val: 142.4571 - val_val_accuracy: 0.8589
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 94.4084 - accuracy: 0.9173
Epoch 00021: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 674ms/step - loss: 94.4084 - accuracy: 0.9173 - val_loss_val: 141.1472 - val_val_accuracy: 0.8599
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 90.8987 - accuracy: 0.9208
Epoch 00022: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 659ms/step - loss: 90.8987 - accuracy: 0.9208 - val_loss_val: 139.9941 - val_val_accuracy: 0.8584
Epoch 23/50
11/11 [==============================] - ETA: 0s - loss: 87.5356 - accuracy: 0.9236
Epoch 00023: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 663ms/step - loss: 87.5356 - accuracy: 0.9236 - val_loss_val: 139.7140 - val_val_accuracy: 0.8578
Epoch 24/50
11/11 [==============================] - ETA: 0s - loss: 84.3048 - accuracy: 0.9266
Epoch 00024: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 661ms/step - loss: 84.3048 - accuracy: 0.9266 - val_loss_val: 138.6302 - val_val_accuracy: 0.8598
Epoch 25/50
11/11 [==============================] - ETA: 0s - loss: 81.2186 - accuracy: 0.9296
Epoch 00025: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 662ms/step - loss: 81.2186 - accuracy: 0.9296 - val_loss_val: 138.1147 - val_val_accuracy: 0.8598
Epoch 26/50
11/11 [==============================] - ETA: 0s - loss: 78.1885 - accuracy: 0.9318
Epoch 00026: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 660ms/step - loss: 78.1885 - accuracy: 0.9318 - val_loss_val: 137.4277 - val_val_accuracy: 0.8593
Epoch 27/50
11/11 [==============================] - ETA: 0s - loss: 75.3621 - accuracy: 0.9352
Epoch 00027: val_val_accuracy did not improve from 0.86124
11/11 [==============================] - 7s 662ms/step - loss: 75.3621 - accuracy: 0.9352 - val_loss_val: 136.9212 - val_val_accuracy: 0.8601
Epoch 28/50
11/11 [==============================] - ETA: 0s - loss: 72.5772 - accuracy: 0.9380
Epoch 00028: val_val_accuracy improved from 0.86124 to 0.86314, saving model to ./models/Bilstm_crf/best_model_bilstm_A3.hdf5
11/11 [==============================] - 8s 692ms/step - loss: 72.5772 - accuracy: 0.9380 - val_loss_val: 137.0233 - val_val_accuracy: 0.8631
Epoch 29/50
11/11 [==============================] - ETA: 0s - loss: 69.9634 - accuracy: 0.9415
Epoch 00029: val_val_accuracy did not improve from 0.86314
11/11 [==============================] - 7s 669ms/step - loss: 69.9634 - accuracy: 0.9415 - val_loss_val: 136.3283 - val_val_accuracy: 0.8627
Epoch 30/50
11/11 [==============================] - ETA: 0s - loss: 67.4495 - accuracy: 0.9452
Epoch 00030: val_val_accuracy did not improve from 0.86314
11/11 [==============================] - 7s 660ms/step - loss: 67.4495 - accuracy: 0.9452 - val_loss_val: 136.2452 - val_val_accuracy: 0.8613
Epoch 31/50
11/11 [==============================] - ETA: 0s - loss: 65.0133 - accuracy: 0.9477
Epoch 00031: val_val_accuracy did not improve from 0.86314
11/11 [==============================] - 7s 664ms/step - loss: 65.0133 - accuracy: 0.9477 - val_loss_val: 136.2579 - val_val_accuracy: 0.8605
Epoch 32/50
11/11 [==============================] - ETA: 0s - loss: 62.6481 - accuracy: 0.9511
Epoch 00032: val_val_accuracy did not improve from 0.86314
11/11 [==============================] - 7s 668ms/step - loss: 62.6481 - accuracy: 0.9511 - val_loss_val: 136.5500 - val_val_accuracy: 0.8606
Epoch 33/50
11/11 [==============================] - ETA: 0s - loss: 60.3572 - accuracy: 0.9538
Epoch 00033: val_val_accuracy did not improve from 0.86314
11/11 [==============================] - 7s 662ms/step - loss: 60.3572 - accuracy: 0.9538 - val_loss_val: 136.6698 - val_val_accuracy: 0.8594
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>4it [16:57, 261.79s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 576.6807 - accuracy: 0.3084
Epoch 00001: val_val_accuracy improved from -inf to 0.57799, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 21s 1s/step - loss: 576.6807 - accuracy: 0.3084 - val_loss_val: 424.4284 - val_val_accuracy: 0.5780
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 325.2778 - accuracy: 0.7910
Epoch 00002: val_val_accuracy improved from 0.57799 to 0.85485, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 325.2778 - accuracy: 0.7910 - val_loss_val: 177.6390 - val_val_accuracy: 0.8548
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 136.8391 - accuracy: 0.8692
Epoch 00003: val_val_accuracy improved from 0.85485 to 0.85629, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 136.8391 - accuracy: 0.8692 - val_loss_val: 143.7660 - val_val_accuracy: 0.8563
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 121.9745 - accuracy: 0.8720
Epoch 00004: val_val_accuracy improved from 0.85629 to 0.86041, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 121.9745 - accuracy: 0.8720 - val_loss_val: 135.9795 - val_val_accuracy: 0.8604
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 112.9335 - accuracy: 0.8778
Epoch 00005: val_val_accuracy improved from 0.86041 to 0.86356, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 112.9335 - accuracy: 0.8778 - val_loss_val: 127.5509 - val_val_accuracy: 0.8636
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 105.1034 - accuracy: 0.8852
Epoch 00006: val_val_accuracy improved from 0.86356 to 0.86510, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 105.1034 - accuracy: 0.8852 - val_loss_val: 121.3885 - val_val_accuracy: 0.8651
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 98.1868 - accuracy: 0.8923
Epoch 00007: val_val_accuracy improved from 0.86510 to 0.87077, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 98.1868 - accuracy: 0.8923 - val_loss_val: 114.9686 - val_val_accuracy: 0.8708
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 91.1774 - accuracy: 0.8976
Epoch 00008: val_val_accuracy improved from 0.87077 to 0.87160, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 91.1774 - accuracy: 0.8976 - val_loss_val: 110.8770 - val_val_accuracy: 0.8716
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 84.5473 - accuracy: 0.9058
Epoch 00009: val_val_accuracy improved from 0.87160 to 0.87479, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 84.5473 - accuracy: 0.9058 - val_loss_val: 105.7032 - val_val_accuracy: 0.8748
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 78.3752 - accuracy: 0.9117
Epoch 00010: val_val_accuracy improved from 0.87479 to 0.87943, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 12s 1s/step - loss: 78.3752 - accuracy: 0.9117 - val_loss_val: 101.6577 - val_val_accuracy: 0.8794
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 73.0855 - accuracy: 0.9183
Epoch 00011: val_val_accuracy improved from 0.87943 to 0.87954, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 73.0855 - accuracy: 0.9183 - val_loss_val: 99.9656 - val_val_accuracy: 0.8795
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 67.7933 - accuracy: 0.9249
Epoch 00012: val_val_accuracy improved from 0.87954 to 0.88077, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 67.7933 - accuracy: 0.9249 - val_loss_val: 97.5033 - val_val_accuracy: 0.8808
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 63.2665 - accuracy: 0.9314
Epoch 00013: val_val_accuracy improved from 0.88077 to 0.88108, saving model to ./models/Bilstm_crf/best_model_bilstm_A4.hdf5
11/11 [==============================] - 11s 1s/step - loss: 63.2665 - accuracy: 0.9314 - val_loss_val: 96.0012 - val_val_accuracy: 0.8811
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 58.6265 - accuracy: 0.9365
Epoch 00014: val_val_accuracy did not improve from 0.88108
11/11 [==============================] - 11s 983ms/step - loss: 58.6265 - accuracy: 0.9365 - val_loss_val: 95.5850 - val_val_accuracy: 0.8798
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 54.4825 - accuracy: 0.9409
Epoch 00015: val_val_accuracy did not improve from 0.88108
11/11 [==============================] - 11s 979ms/step - loss: 54.4825 - accuracy: 0.9409 - val_loss_val: 96.4534 - val_val_accuracy: 0.8803
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 50.3339 - accuracy: 0.9464
Epoch 00016: val_val_accuracy did not improve from 0.88108
11/11 [==============================] - 11s 980ms/step - loss: 50.3339 - accuracy: 0.9464 - val_loss_val: 98.5796 - val_val_accuracy: 0.8778
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 47.2959 - accuracy: 0.9499
Epoch 00017: val_val_accuracy did not improve from 0.88108
11/11 [==============================] - 11s 978ms/step - loss: 47.2959 - accuracy: 0.9499 - val_loss_val: 99.5261 - val_val_accuracy: 0.8766
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>5it [20:15, 238.66s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 430.8212 - accuracy: 0.6677
Epoch 00001: val_val_accuracy improved from -inf to 0.84036, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 20s 1s/step - loss: 430.8212 - accuracy: 0.6677 - val_loss_val: 335.6440 - val_val_accuracy: 0.8404
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 242.3040 - accuracy: 0.8585
Epoch 00002: val_val_accuracy improved from 0.84036 to 0.85041, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 988ms/step - loss: 242.3040 - accuracy: 0.8585 - val_loss_val: 223.6375 - val_val_accuracy: 0.8504
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 172.8817 - accuracy: 0.8631
Epoch 00003: val_val_accuracy improved from 0.85041 to 0.85454, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 172.8817 - accuracy: 0.8631 - val_loss_val: 179.3337 - val_val_accuracy: 0.8545
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 151.8311 - accuracy: 0.8647
Epoch 00004: val_val_accuracy improved from 0.85454 to 0.85459, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 151.8311 - accuracy: 0.8647 - val_loss_val: 170.9669 - val_val_accuracy: 0.8546
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 136.0702 - accuracy: 0.8648
Epoch 00005: val_val_accuracy improved from 0.85459 to 0.85479, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 136.0702 - accuracy: 0.8648 - val_loss_val: 153.0976 - val_val_accuracy: 0.8548
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 121.1565 - accuracy: 0.8704
Epoch 00006: val_val_accuracy improved from 0.85479 to 0.86005, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 121.1565 - accuracy: 0.8704 - val_loss_val: 144.7955 - val_val_accuracy: 0.8601
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 107.6114 - accuracy: 0.8940
Epoch 00007: val_val_accuracy improved from 0.86005 to 0.86943, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 107.6114 - accuracy: 0.8940 - val_loss_val: 137.5357 - val_val_accuracy: 0.8694
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 95.2571 - accuracy: 0.9123
Epoch 00008: val_val_accuracy improved from 0.86943 to 0.87155, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 95.2571 - accuracy: 0.9123 - val_loss_val: 131.7091 - val_val_accuracy: 0.8715
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 82.7479 - accuracy: 0.9246
Epoch 00009: val_val_accuracy improved from 0.87155 to 0.87289, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 82.7479 - accuracy: 0.9246 - val_loss_val: 128.0436 - val_val_accuracy: 0.8729
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 71.3704 - accuracy: 0.9332
Epoch 00010: val_val_accuracy did not improve from 0.87289
11/11 [==============================] - 11s 985ms/step - loss: 71.3704 - accuracy: 0.9332 - val_loss_val: 125.8844 - val_val_accuracy: 0.8727
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 60.4052 - accuracy: 0.9453
Epoch 00011: val_val_accuracy improved from 0.87289 to 0.87428, saving model to ./models/Bilstm_crf/best_model_bilstm_A5.hdf5
11/11 [==============================] - 11s 1s/step - loss: 60.4052 - accuracy: 0.9453 - val_loss_val: 127.2878 - val_val_accuracy: 0.8743
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 51.1571 - accuracy: 0.9550
Epoch 00012: val_val_accuracy did not improve from 0.87428
11/11 [==============================] - 11s 985ms/step - loss: 51.1571 - accuracy: 0.9550 - val_loss_val: 132.0555 - val_val_accuracy: 0.8706
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 43.4949 - accuracy: 0.9632
Epoch 00013: val_val_accuracy did not improve from 0.87428
11/11 [==============================] - 11s 980ms/step - loss: 43.4949 - accuracy: 0.9632 - val_loss_val: 137.9423 - val_val_accuracy: 0.8668
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>6it [22:47, 209.34s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 564.8522 - accuracy: 0.4661
Epoch 00001: val_val_accuracy improved from -inf to 0.83459, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 22s 1s/step - loss: 564.8522 - accuracy: 0.4661 - val_loss_val: 406.6782 - val_val_accuracy: 0.8346
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 277.0113 - accuracy: 0.8587
Epoch 00002: val_val_accuracy improved from 0.83459 to 0.84608, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 277.0113 - accuracy: 0.8587 - val_loss_val: 213.7614 - val_val_accuracy: 0.8461
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 183.2888 - accuracy: 0.8564
Epoch 00003: val_val_accuracy improved from 0.84608 to 0.85062, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 183.2888 - accuracy: 0.8564 - val_loss_val: 194.1914 - val_val_accuracy: 0.8506
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 169.2045 - accuracy: 0.8655
Epoch 00004: val_val_accuracy improved from 0.85062 to 0.85335, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 169.2045 - accuracy: 0.8655 - val_loss_val: 183.0802 - val_val_accuracy: 0.8534
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 158.9474 - accuracy: 0.8672
Epoch 00005: val_val_accuracy improved from 0.85335 to 0.85500, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 158.9474 - accuracy: 0.8672 - val_loss_val: 174.5592 - val_val_accuracy: 0.8550
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 150.0113 - accuracy: 0.8724
Epoch 00006: val_val_accuracy improved from 0.85500 to 0.85593, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 150.0113 - accuracy: 0.8724 - val_loss_val: 168.2451 - val_val_accuracy: 0.8559
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 141.9887 - accuracy: 0.8765
Epoch 00007: val_val_accuracy improved from 0.85593 to 0.86211, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 141.9887 - accuracy: 0.8765 - val_loss_val: 161.2108 - val_val_accuracy: 0.8621
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 133.9024 - accuracy: 0.8838
Epoch 00008: val_val_accuracy did not improve from 0.86211
11/11 [==============================] - 13s 1s/step - loss: 133.9024 - accuracy: 0.8838 - val_loss_val: 156.1208 - val_val_accuracy: 0.8615
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 125.4644 - accuracy: 0.8898
Epoch 00009: val_val_accuracy improved from 0.86211 to 0.86500, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 125.4644 - accuracy: 0.8898 - val_loss_val: 151.1609 - val_val_accuracy: 0.8650
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 118.0387 - accuracy: 0.8961
Epoch 00010: val_val_accuracy did not improve from 0.86500
11/11 [==============================] - 13s 1s/step - loss: 118.0387 - accuracy: 0.8961 - val_loss_val: 147.6973 - val_val_accuracy: 0.8650
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 110.7316 - accuracy: 0.9011
Epoch 00011: val_val_accuracy improved from 0.86500 to 0.86804, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 110.7316 - accuracy: 0.9011 - val_loss_val: 143.3531 - val_val_accuracy: 0.8680
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 103.5902 - accuracy: 0.9063
Epoch 00012: val_val_accuracy improved from 0.86804 to 0.86964, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 103.5902 - accuracy: 0.9063 - val_loss_val: 141.6227 - val_val_accuracy: 0.8696
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 96.4050 - accuracy: 0.9127
Epoch 00013: val_val_accuracy did not improve from 0.86964
11/11 [==============================] - 13s 1s/step - loss: 96.4050 - accuracy: 0.9127 - val_loss_val: 139.5004 - val_val_accuracy: 0.8654
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 89.1097 - accuracy: 0.9198
Epoch 00014: val_val_accuracy improved from 0.86964 to 0.87191, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 89.1097 - accuracy: 0.9198 - val_loss_val: 137.8902 - val_val_accuracy: 0.8719
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 83.6419 - accuracy: 0.9238
Epoch 00015: val_val_accuracy did not improve from 0.87191
11/11 [==============================] - 13s 1s/step - loss: 83.6419 - accuracy: 0.9238 - val_loss_val: 138.9414 - val_val_accuracy: 0.8690
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 77.5784 - accuracy: 0.9295
Epoch 00016: val_val_accuracy did not improve from 0.87191
11/11 [==============================] - 13s 1s/step - loss: 77.5784 - accuracy: 0.9295 - val_loss_val: 141.4497 - val_val_accuracy: 0.8645
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 71.6371 - accuracy: 0.9344
Epoch 00017: val_val_accuracy improved from 0.87191 to 0.87232, saving model to ./models/Bilstm_crf/best_model_bilstm_A6.hdf5
11/11 [==============================] - 13s 1s/step - loss: 71.6371 - accuracy: 0.9344 - val_loss_val: 139.2100 - val_val_accuracy: 0.8723
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>7it [27:32, 234.02s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 553.8858 - accuracy: 0.4223
Epoch 00001: val_val_accuracy improved from -inf to 0.47031, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 23s 1s/step - loss: 553.8858 - accuracy: 0.4223 - val_loss_val: 422.5653 - val_val_accuracy: 0.4703
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 302.7005 - accuracy: 0.6211
Epoch 00002: val_val_accuracy improved from 0.47031 to 0.84443, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 302.7005 - accuracy: 0.6211 - val_loss_val: 256.1518 - val_val_accuracy: 0.8444
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 201.6654 - accuracy: 0.8563
Epoch 00003: val_val_accuracy improved from 0.84443 to 0.85206, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 201.6654 - accuracy: 0.8563 - val_loss_val: 204.9319 - val_val_accuracy: 0.8521
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 179.9676 - accuracy: 0.8636
Epoch 00004: val_val_accuracy improved from 0.85206 to 0.85247, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 179.9676 - accuracy: 0.8636 - val_loss_val: 201.1865 - val_val_accuracy: 0.8525
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 171.0653 - accuracy: 0.8639
Epoch 00005: val_val_accuracy improved from 0.85247 to 0.85423, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 171.0653 - accuracy: 0.8639 - val_loss_val: 189.3566 - val_val_accuracy: 0.8542
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 162.4392 - accuracy: 0.8648
Epoch 00006: val_val_accuracy improved from 0.85423 to 0.85469, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 162.4392 - accuracy: 0.8648 - val_loss_val: 182.4481 - val_val_accuracy: 0.8547
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 153.1332 - accuracy: 0.8649
Epoch 00007: val_val_accuracy did not improve from 0.85469
11/11 [==============================] - 13s 1s/step - loss: 153.1332 - accuracy: 0.8649 - val_loss_val: 172.3825 - val_val_accuracy: 0.8547
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 142.1828 - accuracy: 0.8652
Epoch 00008: val_val_accuracy improved from 0.85469 to 0.85515, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 142.1828 - accuracy: 0.8652 - val_loss_val: 163.7299 - val_val_accuracy: 0.8552
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 130.7540 - accuracy: 0.8691
Epoch 00009: val_val_accuracy improved from 0.85515 to 0.85727, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 130.7540 - accuracy: 0.8691 - val_loss_val: 154.8849 - val_val_accuracy: 0.8573
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 120.0812 - accuracy: 0.8812
Epoch 00010: val_val_accuracy improved from 0.85727 to 0.86031, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 120.0812 - accuracy: 0.8812 - val_loss_val: 148.1951 - val_val_accuracy: 0.8603
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 110.2446 - accuracy: 0.8965
Epoch 00011: val_val_accuracy improved from 0.86031 to 0.86222, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 110.2446 - accuracy: 0.8965 - val_loss_val: 142.8625 - val_val_accuracy: 0.8622
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 101.1224 - accuracy: 0.9058
Epoch 00012: val_val_accuracy improved from 0.86222 to 0.86474, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 101.1224 - accuracy: 0.9058 - val_loss_val: 139.7124 - val_val_accuracy: 0.8647
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 92.0615 - accuracy: 0.9134
Epoch 00013: val_val_accuracy did not improve from 0.86474
11/11 [==============================] - 13s 1s/step - loss: 92.0615 - accuracy: 0.9134 - val_loss_val: 141.2984 - val_val_accuracy: 0.8604
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 83.0295 - accuracy: 0.9229
Epoch 00014: val_val_accuracy improved from 0.86474 to 0.86923, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 83.0295 - accuracy: 0.9229 - val_loss_val: 134.7515 - val_val_accuracy: 0.8692
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 73.2969 - accuracy: 0.9326
Epoch 00015: val_val_accuracy did not improve from 0.86923
11/11 [==============================] - 14s 1s/step - loss: 73.2969 - accuracy: 0.9326 - val_loss_val: 135.6058 - val_val_accuracy: 0.8672
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 64.4518 - accuracy: 0.9416
Epoch 00016: val_val_accuracy improved from 0.86923 to 0.86979, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 64.4518 - accuracy: 0.9416 - val_loss_val: 134.6388 - val_val_accuracy: 0.8698
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 56.1510 - accuracy: 0.9509
Epoch 00017: val_val_accuracy improved from 0.86979 to 0.87175, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 56.1510 - accuracy: 0.9509 - val_loss_val: 135.4783 - val_val_accuracy: 0.8718
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 48.7872 - accuracy: 0.9601
Epoch 00018: val_val_accuracy improved from 0.87175 to 0.87469, saving model to ./models/Bilstm_crf/best_model_bilstm_A7.hdf5
11/11 [==============================] - 13s 1s/step - loss: 48.7872 - accuracy: 0.9601 - val_loss_val: 140.4779 - val_val_accuracy: 0.8747
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 43.0050 - accuracy: 0.9658
Epoch 00019: val_val_accuracy did not improve from 0.87469
11/11 [==============================] - 13s 1s/step - loss: 43.0050 - accuracy: 0.9658 - val_loss_val: 140.3924 - val_val_accuracy: 0.8719
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>8it [31:47, 238.47s/it]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="r&#233;sulats-du-grid-search">r&#233;sulats du grid search<a class="anchor-link" href="#r&#233;sulats-du-grid-search">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#on importe les meilleurs modles </span>
<span class="n">val_true</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">val_tags_y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">grid_search_results_A</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="s1">&#39;f1 score micro&#39;</span><span class="p">,</span><span class="s1">&#39;f1 score macro&#39;</span><span class="p">])</span>
<span class="n">grid_search_results_A</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">models_bilstm_crf_param_A</span>

<span class="n">f1_scores_micro</span><span class="o">=</span><span class="p">[]</span>
<span class="n">f1_scores_macro</span><span class="o">=</span><span class="p">[]</span>

<span class="n">f1_score_selected</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">models_bilstm_crf_A</span><span class="p">)):</span>
  <span class="c1"># Restore the weights</span>
  <span class="n">model_i</span> <span class="o">=</span> <span class="n">models_bilstm_crf_A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">model_i</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s2">&quot;./models/Bilstm_crf/best_model_bilstm_A&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;.hdf5&quot;</span><span class="p">)</span>
  <span class="n">val_pred_ner_i</span> <span class="o">=</span> <span class="n">model_i</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">)</span>
  
  
  <span class="n">f1_score_micro</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
  <span class="n">f1_score_macro</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
  <span class="n">f1_scores_micro</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score_micro</span><span class="p">)</span>
  <span class="n">f1_scores_macro</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score_macro</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">f1_score_macro</span> <span class="o">&gt;=</span> <span class="n">f1_score_selected</span><span class="p">:</span>
    <span class="n">model_selected</span> <span class="o">=</span> <span class="n">model_i</span>
    <span class="n">f1_score_selected</span> <span class="o">=</span> <span class="n">f1_score_macro</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search_results_A</span><span class="p">[</span><span class="s1">&#39;f1 score micro&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1_scores_micro</span>
<span class="n">grid_search_results_A</span><span class="p">[</span><span class="s1">&#39;f1 score macro&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1_scores_macro</span>
<span class="n">grid_search_results_A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>f1 score micro</th>
      <th>f1 score macro</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[adam, Glove, GRU, 0.3, 10]</td>
      <td>0.875309</td>
      <td>0.570776</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[adam, None, GRU, 0.3, 10]</td>
      <td>0.870000</td>
      <td>0.535713</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[adam, Glove, LSTM, 0.3, 10]</td>
      <td>0.866237</td>
      <td>0.428373</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[adam, None, LSTM, 0.3, 10]</td>
      <td>0.863093</td>
      <td>0.483890</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[adam, Glove, GRU, 0.3, 64]</td>
      <td>0.884124</td>
      <td>0.616138</td>
    </tr>
    <tr>
      <th>5</th>
      <td>[adam, None, GRU, 0.3, 64]</td>
      <td>0.873196</td>
      <td>0.572482</td>
    </tr>
    <tr>
      <th>6</th>
      <td>[adam, Glove, LSTM, 0.3, 64]</td>
      <td>0.874845</td>
      <td>0.575239</td>
    </tr>
    <tr>
      <th>7</th>
      <td>[adam, None, LSTM, 0.3, 64]</td>
      <td>0.875464</td>
      <td>0.547626</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>REMARQUE</em></strong>
on remarque que l'embedding Glove donne en gnral de meilleurs rsultats. De plus le GRU offre galement les meilleurs rsultats avec un meilleur score f1 score macro de 0.61 et micro de 0.88. Ce rsulat est associ  un plus grand nombreux d'units (64) et un embedding glove.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Mod&#232;le-s&#233;lectionn&#233;">Mod&#232;le s&#233;lectionn&#233;<a class="anchor-link" href="#Mod&#232;le-s&#233;lectionn&#233;">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_sected</span><span class="o">=</span><span class="n">models_bilstm_crf_A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">callback2_A</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss_val&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">checkpoint2_A</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;./models/Bilstm_crf/best_model_bilstm_A_select.hdf5&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_val_accuracy&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">model_sected</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_sentences_X</span><span class="p">,</span> <span class="n">train_tags_y</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">,</span><span class="n">val_tags_y</span><span class="p">),</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint2_A</span><span class="p">,</span><span class="n">callback2_A</span><span class="p">],</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Evaluation-du-mod&#232;le-(confusion-matrix-et-autre-metrics)">Evaluation du mod&#232;le (confusion matrix et autre metrics)<a class="anchor-link" href="#Evaluation-du-mod&#232;le-(confusion-matrix-et-autre-metrics)">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">val_pred_ner</span> <span class="o">=</span> <span class="n">model_selected</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">)</span>
<span class="n">labels_for_confusion_m</span><span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tags_A</span><span class="p">))</span>
<span class="n">show_confusion_bis</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">labels</span><span class="o">=</span><span class="n">labels_for_confusion_m</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>f1 micro:0.875
f1 macro:0.548
recall macro:0.523
Confusion Matrix:
[[8239    0    0    0    0    0]
 [   2 7852  203  146  124   13]
 [   0  346  284   53    6    5]
 [   0  617  123  255   72    5]
 [   2  322   14   25  324    7]
 [   2  225   67   10   27   30]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">target_names</span><span class="o">=</span><span class="n">tags_A</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           O       1.00      1.00      1.00      8239
           B       0.84      0.94      0.89      8340
           I       0.41      0.41      0.41       694
           L       0.52      0.24      0.33      1072
           U       0.59      0.47      0.52       694
       -PAD-       0.50      0.08      0.14       361

    accuracy                           0.88     19400
   macro avg       0.64      0.52      0.55     19400
weighted avg       0.86      0.88      0.86     19400

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Remarque</em></strong></p>
<p>On remarque que notre modle apprend bien les valeurs videntes comme les valeurs de padding qui sont  zros. En vu de notre jeu de donnes qui est trs dsquilibrs on s'attend donc  ce que notre modle prdit beacoup de 'O', ce qui nous donne certes une  bonne precision, recall et f1 score pour le O mais des rsultats moyens poour le 'I' par exemple et autre. Le 'B' est galement pltot bien prdit, nous pensons que la couche CRF permet en effet d'ajouter des lments de logiques permettant d'amliorer nos rsultats. En effet, on a test un modle Bilstm simple sans CRF et nous avionns de moins bon rsultats.</p>
<p>NB: pour les valeurs du padding qui sont  0 nous aurions pu utiliser l'argument masking=0 pour l'embedding mais cela nous donnait de moins bon rsultats tonnement.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="cr&#233;ation-des-fichiers-de-soumissions-pour-la-validation-et-le-test">cr&#233;ation des fichiers de soumissions pour la validation et le test<a class="anchor-link" href="#cr&#233;ation-des-fichiers-de-soumissions-pour-la-validation-et-le-test">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">suppress_pad</span><span class="p">(</span><span class="n">test_tags_y_predict</span><span class="p">,</span><span class="n">test_sentences_X_no_pad</span><span class="p">):</span>
  <span class="c1"># we supress the 0s correponding to the additional padding</span>
  <span class="c1">#test_tags_y_predict_no_pad = np.delete(test_tags_y_predict[0], np.where(test_tags_y_predict[0] == 0))</span>
  <span class="n">test_tags_y_predict_no_pad</span> <span class="o">=</span> <span class="n">test_tags_y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">test_tags_y_predict</span><span class="p">)):</span>
    <span class="n">A_i</span><span class="o">=</span><span class="n">test_tags_y_predict</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>
    <span class="n">test_tags_y_predict_no_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">test_tags_y_predict_no_pad</span> <span class="p">,</span><span class="n">A_i</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">!=</span><span class="nb">len</span><span class="p">(</span><span class="n">A_i</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A_i</span><span class="p">))</span>
      <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FALSE:&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">test_tags_y_predict_no_pad</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">val_pred_ner</span> <span class="o">=</span> <span class="n">model_selected</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">)</span>
<span class="n">val_pred_ner_no_pad</span> <span class="o">=</span> <span class="n">suppress_pad</span><span class="p">(</span><span class="n">val_pred_ner</span><span class="p">,</span><span class="n">val_sentences_X_no_pad</span><span class="p">)</span>
<span class="n">submission_val_bilstm_crf_A</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">])</span>
<span class="n">submission_val_bilstm_crf_A</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_df</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span>
<span class="c1">#submission_val_bilstm_crf_A[&#39;Tag&#39;] = val_pred_ner_no_pad</span>

<span class="n">val_ids_concat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">val_ids</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_df</span><span class="p">))):</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">val_df</span><span class="p">[</span><span class="n">val_df</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">val_ids_concat</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">submission_val_bilstm_crf_A</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_pred_ner_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>


<span class="n">submission_val_bilstm_crf_A</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission_val_bilstm_crf_A</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">index2tag</span><span class="p">)</span>
<span class="n">submission_val_bilstm_crf_A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 11161/11161 [00:14&lt;00:00, 775.02it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TokenID</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0301010415300355-0</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0301010415300355-1</td>
      <td>O</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0301010415300355-2</td>
      <td>O</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0301010415300355-3</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0301010415300355-4</td>
      <td>O</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>11156</th>
      <td>S1359028614000989-185</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11157</th>
      <td>S1359028614000989-186</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11158</th>
      <td>S1359028614000989-187</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11159</th>
      <td>S1359028614000989-188</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11160</th>
      <td>S1359028614000989-189</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
<p>11161 rows  2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_pred_ner</span> <span class="o">=</span> <span class="n">model_selected</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_sentences_X</span><span class="p">)</span>
<span class="n">test_pred_ner_no_pad</span> <span class="o">=</span> <span class="n">suppress_pad</span><span class="p">(</span><span class="n">test_pred_ner</span><span class="p">,</span><span class="n">test_sentences_X_no_pad</span><span class="p">)</span>
<span class="n">submission_test_bilstm_crf_A</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">])</span>
<span class="n">submission_test_bilstm_crf_A</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span>
<span class="c1">#submission_test_bilstm_crf_A[&#39;Tag&#39;] = test_pred_ner_no_pad</span>

<span class="n">test_ids_concat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_ids</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">))):</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_ids_concat</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">submission_test_bilstm_crf_A</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_pred_ner_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="n">submission_test_bilstm_crf_A</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission_test_bilstm_crf_A</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">index2tag</span><span class="p">)</span>
<span class="n">submission_test_bilstm_crf_A</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 21711/21711 [00:42&lt;00:00, 516.10it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TokenID</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0885230816301759-0</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0885230816301759-1</td>
      <td>O</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0885230816301759-2</td>
      <td>O</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0885230816301759-3</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0885230816301759-4</td>
      <td>B</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21706</th>
      <td>S1877750313001269-211</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21707</th>
      <td>S1877750313001269-212</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21708</th>
      <td>S1877750313001269-213</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21709</th>
      <td>S1877750313001269-214</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21710</th>
      <td>S1877750313001269-215</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
<p>21711 rows  2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">submission_test_bilstm_crf_A</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Test_submission_Glove_Bilstm_CRF_tache_A.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">submission_val_bilstm_crf_A</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Val_submission_Glove_Bilstm_CRF_tache_A.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="BERT">BERT<a class="anchor-link" href="#BERT">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Imports">Imports<a class="anchor-link" href="#Imports">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install transformers
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)
Requirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.1.0-&gt;transformers) (3.10.0.2)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;=20.0-&gt;transformers) (3.0.6)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers) (3.6.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2021.10.8)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (1.24.3)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (2.10)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers) (3.0.4)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers) (1.15.0)
Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers) (7.1.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers) (1.1.0)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">BertTokenizer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">BertForTokenClassification</span><span class="p">,</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">BertConfig</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">get_linear_schedule_with_warmup</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="k">import</span> <span class="n">pad_sequences</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span><span class="p">,</span> <span class="n">SequentialSampler</span>

<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="k">import</span> <span class="n">sent_tokenize</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">datetime</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># If there&#39;s a GPU available...</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>    

    <span class="c1"># Tell PyTorch to use the GPU.    </span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> GPU(s) available.&#39;</span> <span class="o">%</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">())</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;We will use the GPU:&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># If not...</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;No GPU available, using the CPU instead.&#39;</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>There are 1 GPU(s) available.
We will use the GPU: Tesla K80
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preprocessing-for-BERT">Preprocessing for BERT<a class="anchor-link" href="#Preprocessing-for-BERT">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since BERT is a massive architecture we can no longer use entire documents ans we need to use sentences instead. Indee the maximal length of the documents is around 350 whereas the maximal length of the sentences is around 200.<br>
Since we don't have clear sentence delimitation in the .csv documents, we use nltk sentence tokenizer on the .txt documents and then the nltk word tokenizer on the sentences. Finally we sequentially attribute the labels we got in the previous parts to the tokens we just optained. Unfortunatly, it seems that the .cvs files don't exactly used this technic to optain their tokens because some sentences are missing points or some token we optaned correspond to several tokens in the csv file.<br>
When the problem is just a missing point we add it. When tokens are not the same with the two tokenization strategy, since these examples are very rare, we just delete them from the dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># We retrieve the texts directly from the .txt files to apply the sentence tokeniezer</span>
<span class="k">def</span> <span class="nf">get_text_docs</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
  <span class="n">text_docs</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading docs...&quot;</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">[</span><span class="n">folder</span><span class="p">])):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;data/</span><span class="si">{folder}</span><span class="s2">/</span><span class="si">{doc_id}</span><span class="s2">.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">text_docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   DONE.&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">text_docs</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># We then construct the tokenized sentences and assign the labels</span>

<span class="k">def</span> <span class="nf">get_doc_sentences</span><span class="p">(</span><span class="n">text_docs</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">original_sentences</span><span class="p">,</span> <span class="n">doc_tags</span><span class="p">,</span> <span class="n">ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="c1"># We construct the list sentences (list of tokens) based on nltk sent_tokenize and nltk world_tokenizer</span>
  <span class="n">doc_sentences0</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Constructing sentences...&quot;</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">text_docs</span><span class="p">):</span>
    <span class="n">doc_sentences0</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)])</span>
  <span class="n">diff</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">invalid_indices</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="nb">print</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">doc_sentences0</span><span class="p">,</span> <span class="n">original_sentences</span><span class="p">)):</span>
    <span class="n">sentence_tokens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sentence_tokens</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
      <span class="n">doc_sentences0</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">doc_sentences0</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;.&quot;</span><span class="p">])])</span>
      <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">doc_sentences0</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
        <span class="c1"># When sent_tokenizer + word_tokenizer doesn&#39;t match the tokens form the .csv file</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot; Doc </span><span class="si">{doc_ids[folder][i]}</span><span class="s2"> invalid&quot;</span><span class="p">)</span>
        <span class="n">invalid_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">doc_sentences0</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
  
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   DONE.&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>
    
  <span class="c1"># Since we noticed there is only one sentence in the dataset that is wrongly tokenized, we simply delete it from dataset</span>
  <span class="n">doc_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc_sentences0</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_sentences0</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">invalid_indices</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">doc_tags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">tags_valid</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc_tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_tags</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">invalid_indices</span><span class="p">]</span>

  <span class="c1"># Setting tags to the new tokens</span>
  <span class="k">if</span> <span class="n">doc_tags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> 
    <span class="n">doc_tags_</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">tags</span><span class="p">,</span> <span class="n">sentences</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tags_valid</span><span class="p">,</span> <span class="n">doc_sentences</span><span class="p">):</span>
      <span class="n">doc_tags_</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
      <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
        <span class="n">doc_tags_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tags</span><span class="p">[</span><span class="n">n</span><span class="p">:</span><span class="n">n</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)]))</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
  
  <span class="c1"># We flatten the doc_sentences structure to have only one list of sentence independently of the documents</span>
  <span class="n">all_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span> <span class="k">for</span> <span class="n">sentences</span> <span class="ow">in</span> <span class="n">doc_sentences</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">doc_tags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> 
    <span class="n">all_tags</span> <span class="o">=</span> <span class="p">[</span><span class="n">tags</span> <span class="k">for</span> <span class="n">sentence_tags</span> <span class="ow">in</span> <span class="n">doc_tags_</span> <span class="k">for</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">sentence_tags</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Same number of sentences and tag sequences:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_sentences</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_tags</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_sentences</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_tags</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Size:&quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">all_sentences</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Looking at some sentences randomly:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_sentences</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">all_sentences</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">all_tags</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>

  <span class="k">else</span><span class="p">:</span> <span class="n">all_tags</span> <span class="o">=</span> <span class="kc">None</span>
  
  <span class="k">return</span> <span class="n">all_sentences</span><span class="p">,</span> <span class="n">all_tags</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Train dataset ====&quot;</span><span class="p">)</span>
<span class="n">all_sentences_train</span><span class="p">,</span> <span class="n">all_tags_train</span> <span class="o">=</span> <span class="n">get_doc_sentences</span><span class="p">(</span><span class="n">get_text_docs</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">train_sentences</span><span class="p">,</span> <span class="n">train_tags</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Validation dataset ====&quot;</span><span class="p">)</span>
<span class="n">all_sentences_val</span><span class="p">,</span> <span class="n">all_tags_val</span> <span class="o">=</span> <span class="n">get_doc_sentences</span><span class="p">(</span><span class="n">get_text_docs</span><span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">),</span> <span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">val_sentences</span><span class="p">,</span> <span class="n">val_tags</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>==== Train dataset ====
Loading docs...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 350/350 [00:58&lt;00:00,  5.94it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Constructing sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 350/350 [00:00&lt;00:00, 441.52it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
 Doc S0370269304009359 invalid
[&#39;Table&#39;, &#39;1&#39;, &#39;lists&#39;, &#39;8&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;B&#39;, &#39;decays&#39;, &#39;.&#39;, &#39;In&#39;, &#39;fact&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;more&#39;, &#39;decay&#39;, &#39;pairs&#39;, &#39;,&#39;, &#39;since&#39;, &#39;many&#39;, &#39;of&#39;, &#39;the&#39;, &#39;particles&#39;, &#39;in&#39;, &#39;the&#39;, &#39;final&#39;, &#39;states&#39;, &#39;can&#39;, &#39;be&#39;, &#39;observed&#39;, &#39;as&#39;, &#39;either&#39;, &#39;pseudoscalar&#39;, &#39;(&#39;, &#39;P&#39;, &#39;)&#39;, &#39;or&#39;, &#39;vector&#39;, &#39;(&#39;, &#39;V&#39;, &#39;)&#39;, &#39;mesons&#39;, &#39;.&#39;, &#39;Note&#39;, &#39;that&#39;, &#39;certain&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;written&#39;, &#39;in&#39;, &#39;terms&#39;, &#39;of&#39;, &#39;VV&#39;, &#39;final&#39;, &#39;states&#39;, &#39;,&#39;, &#39;while&#39;, &#39;others&#39;, &#39;are&#39;, &#39;have&#39;, &#39;PP&#39;, &#39;states&#39;, &#39;.&#39;, &#39;There&#39;, &#39;are&#39;, &#39;three&#39;, &#39;reasons&#39;, &#39;for&#39;, &#39;this&#39;, &#39;.&#39;, &#39;First&#39;, &#39;,&#39;, &#39;some&#39;, &#39;decays&#39;, &#39;involve&#39;, &#39;a&#39;, &#39;final-state&#39;, &#39;0&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;experimentally&#39;, &#39;it&#39;, &#39;will&#39;, &#39;be&#39;, &#39;necessary&#39;, &#39;to&#39;, &#39;find&#39;, &#39;the&#39;, &#39;decay&#39;, &#39;vertices&#39;, &#39;of&#39;, &#39;the&#39;, &#39;final&#39;, &#39;particles&#39;, &#39;.&#39;, &#39;This&#39;, &#39;is&#39;, &#39;virtually&#39;, &#39;impossible&#39;, &#39;for&#39;, &#39;a&#39;, &#39;0&#39;, &#39;,&#39;, &#39;and&#39;, &#39;so&#39;, &#39;we&#39;, &#39;always&#39;, &#39;use&#39;, &#39;a&#39;, &#39;0&#39;, &#39;.&#39;, &#39;Second&#39;, &#39;,&#39;, &#39;some&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;only&#39;, &#39;if&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;pair&#39;, &#39;is&#39;, &#39;used&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;no&#39;, &#39;P&#39;, &#34;&#39;s&#34;, &#39;which&#39;, &#39;are&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;.&#39;, &#39;The&#39;, &#39;mesons&#39;, &#39;&#39;, &#39;and&#39;, &#39;&#39;, &#39;have&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;component&#39;, &#39;,&#39;, &#39;but&#39;, &#39;they&#39;, &#39;also&#39;, &#39;have&#39;, &#39;significant&#39;, &#39;(&#39;, &#39;uu&#39;, &#39;)&#39;, &#39;and&#39;, &#39;(&#39;, &#39;dd&#39;, &#39;)&#39;, &#39;pieces&#39;, &#39;.&#39;, &#39;As&#39;, &#39;a&#39;, &#39;result&#39;, &#39;the&#39;, &#39;bs&#39;, &#39;and&#39;, &#39;bd&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;not&#39;, &#39;really&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;involves&#39;, &#39;an&#39;, &#39;&#39;, &#39;or&#39;, &#39;&#39;, &#39;.&#39;, &#39;We&#39;, &#39;therefore&#39;, &#39;consider&#39;, &#39;instead&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;&#39;, &#39;which&#39;, &#39;is&#39;, &#39;essentially&#39;, &#39;a&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;state&#39;, &#39;.&#39;, &#39;Finally&#39;, &#39;,&#39;, &#39;we&#39;, &#39;require&#39;, &#39;that&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;be&#39;, &#39;able&#39;, &#39;to&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;, &#39;This&#39;, &#39;can&#39;, &#39;not&#39;, &#39;happen&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;contains&#39;, &#39;a&#39;, &#39;single&#39;, &#39;K0&#39;, &#39;(&#39;, &#39;or&#39;, &#39;K0&#39;, &#39;)&#39;, &#39;meson&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;it&#39;, &#39;can&#39;, &#39;occur&#39;, &#39;if&#39;, &#39;this&#39;, &#39;final-state&#39;, &#39;particle&#39;, &#39;is&#39;, &#39;an&#39;, &#39;excited&#39;, &#39;neutral&#39;, &#39;kaon&#39;, &#39;.&#39;, &#39;In&#39;, &#39;this&#39;, &#39;case&#39;, &#39;one&#39;, &#39;decay&#39;, &#39;involves&#39;, &#39;K*0&#39;, &#39;,&#39;, &#39;while&#39;, &#39;the&#39;, &#39;other&#39;, &#39;has&#39;, &#39;K*0&#39;, &#39;.&#39;, &#39;Assuming&#39;, &#39;that&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;is&#39;, &#39;detected&#39;, &#39;via&#39;, &#39;its&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;Ks0&#39;, &#39;(&#39;, &#39;as&#39;, &#39;in&#39;, &#39;the&#39;, &#39;measurement&#39;, &#39;of&#39;, &#39;sin2&#39;, &#39;via&#39;, &#39;Bd0&#39;, &#39;(&#39;, &#39;t&#39;, &#39;)&#39;, &#39;J/K*&#39;, &#39;)&#39;, &#39;,&#39;, &#39;then&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;can&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;same&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;, &#39;.&#39;]
[&#39;Table&#39;, &#39;1&#39;, &#39;lists&#39;, &#39;8&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;B&#39;, &#39;decays&#39;, &#39;.&#39;, &#39;In&#39;, &#39;fact&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;more&#39;, &#39;decay&#39;, &#39;pairs&#39;, &#39;,&#39;, &#39;since&#39;, &#39;many&#39;, &#39;of&#39;, &#39;the&#39;, &#39;particles&#39;, &#39;in&#39;, &#39;the&#39;, &#39;final&#39;, &#39;states&#39;, &#39;can&#39;, &#39;be&#39;, &#39;observed&#39;, &#39;as&#39;, &#39;either&#39;, &#39;pseudoscalar&#39;, &#39;(&#39;, &#39;P&#39;, &#39;)&#39;, &#39;or&#39;, &#39;vector&#39;, &#39;(&#39;, &#39;V&#39;, &#39;)&#39;, &#39;mesons&#39;, &#39;.&#39;, &#39;Note&#39;, &#39;that&#39;, &#39;certain&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;written&#39;, &#39;in&#39;, &#39;terms&#39;, &#39;of&#39;, &#39;VV&#39;, &#39;final&#39;, &#39;states&#39;, &#39;,&#39;, &#39;while&#39;, &#39;others&#39;, &#39;are&#39;, &#39;have&#39;, &#39;PP&#39;, &#39;states&#39;, &#39;.&#39;, &#39;There&#39;, &#39;are&#39;, &#39;three&#39;, &#39;reasons&#39;, &#39;for&#39;, &#39;this&#39;, &#39;.&#39;, &#39;First&#39;, &#39;,&#39;, &#39;some&#39;, &#39;decays&#39;, &#39;involve&#39;, &#39;a&#39;, &#39;final-state&#39;, &#39;0&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;experimentally&#39;, &#39;it&#39;, &#39;will&#39;, &#39;be&#39;, &#39;necessary&#39;, &#39;to&#39;, &#39;find&#39;, &#39;the&#39;, &#39;decay&#39;, &#39;vertices&#39;, &#39;of&#39;, &#39;the&#39;, &#39;final&#39;, &#39;particles&#39;, &#39;.&#39;, &#39;This&#39;, &#39;is&#39;, &#39;virtually&#39;, &#39;impossible&#39;, &#39;for&#39;, &#39;a&#39;, &#39;0&#39;, &#39;,&#39;, &#39;and&#39;, &#39;so&#39;, &#39;we&#39;, &#39;always&#39;, &#39;use&#39;, &#39;a&#39;, &#39;0&#39;, &#39;.&#39;, &#39;Second&#39;, &#39;,&#39;, &#39;some&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;only&#39;, &#39;if&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;pair&#39;, &#39;is&#39;, &#39;used&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;no&#39;, &#39;P&#39;, &#34;&#39;s&#34;, &#39;which&#39;, &#39;are&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;.&#39;, &#39;The&#39;, &#39;mesons&#39;, &#39;&#39;, &#39;and&#39;, &#39;&#39;, &#39;have&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;component&#39;, &#39;,&#39;, &#39;but&#39;, &#39;they&#39;, &#39;also&#39;, &#39;have&#39;, &#39;significant&#39;, &#39;(&#39;, &#39;uu&#39;, &#39;)&#39;, &#39;and&#39;, &#39;(&#39;, &#39;dd&#39;, &#39;)&#39;, &#39;pieces&#39;, &#39;.&#39;, &#39;As&#39;, &#39;a&#39;, &#39;result&#39;, &#39;the&#39;, &#39;bs&#39;, &#39;and&#39;, &#39;bd&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;not&#39;, &#39;really&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;involves&#39;, &#39;an&#39;, &#39;&#39;, &#39;or&#39;, &#39;&#39;, &#39;.&#39;, &#39;We&#39;, &#39;therefore&#39;, &#39;consider&#39;, &#39;instead&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;&#39;, &#39;which&#39;, &#39;is&#39;, &#39;essentially&#39;, &#39;a&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;state&#39;, &#39;.&#39;, &#39;Finally&#39;, &#39;,&#39;, &#39;we&#39;, &#39;require&#39;, &#39;that&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;be&#39;, &#39;able&#39;, &#39;to&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;, &#39;This&#39;, &#39;can&#39;, &#39;not&#39;, &#39;happen&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;contains&#39;, &#39;a&#39;, &#39;single&#39;, &#39;K0&#39;, &#39;(&#39;, &#39;or&#39;, &#39;K0&#39;, &#39;)&#39;, &#39;meson&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;it&#39;, &#39;can&#39;, &#39;occur&#39;, &#39;if&#39;, &#39;this&#39;, &#39;final-state&#39;, &#39;particle&#39;, &#39;is&#39;, &#39;an&#39;, &#39;excited&#39;, &#39;neutral&#39;, &#39;kaon&#39;, &#39;.&#39;, &#39;In&#39;, &#39;this&#39;, &#39;case&#39;, &#39;one&#39;, &#39;decay&#39;, &#39;involves&#39;, &#39;K&#39;, &#39;*&#39;, &#39;0&#39;, &#39;,&#39;, &#39;while&#39;, &#39;the&#39;, &#39;other&#39;, &#39;has&#39;, &#39;K&#39;, &#39;*&#39;, &#39;0&#39;, &#39;.&#39;, &#39;Assuming&#39;, &#39;that&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;is&#39;, &#39;detected&#39;, &#39;via&#39;, &#39;its&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;Ks0&#39;, &#39;(&#39;, &#39;as&#39;, &#39;in&#39;, &#39;the&#39;, &#39;measurement&#39;, &#39;of&#39;, &#39;sin2&#39;, &#39;via&#39;, &#39;Bd0&#39;, &#39;(&#39;, &#39;t&#39;, &#39;)&#39;, &#39;J/K&#39;, &#39;*&#39;, &#39;)&#39;, &#39;,&#39;, &#39;then&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;can&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;same&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;]

   DONE.

Same number of sentences and tag sequences: True
Size: 2402
Looking at some sentences randomly:
[(&#39;In&#39;, &#39;O&#39;), (&#39;this&#39;, &#39;O&#39;), (&#39;case&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;experimental&#39;, &#39;B&#39;), (&#39;data&#39;, &#39;L&#39;), (&#39;become&#39;, &#39;O&#39;), (&#39;entirely&#39;, &#39;O&#39;), (&#39;integrated&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;calibration&#39;, &#39;B&#39;), (&#39;process&#39;, &#39;L&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;an&#39;, &#39;O&#39;), (&#39;optimization&#39;, &#39;B&#39;), (&#39;routine&#39;, &#39;L&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;used&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;quantify&#39;, &#39;B&#39;), (&#39;the&#39;, &#39;I&#39;), (&#39;best&#39;, &#39;I&#39;), (&#39;set&#39;, &#39;I&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;parameters&#39;, &#39;L&#39;), (&#39;which&#39;, &#39;O&#39;), (&#39;explain&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;observed&#39;, &#39;O&#39;), (&#39;pyrolysis&#39;, &#39;B&#39;), (&#39;behaviour&#39;, &#39;L&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;i.e&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;(&#39;, &#39;O&#39;), (&#39;4&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;also&#39;, &#39;O&#39;), (&#39;h=5.95&#39;, &#39;O&#39;), (&#39;obtained&#39;, &#39;O&#39;), (&#39;from&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;decay&#39;, &#39;O&#39;), (&#39;width&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;Some&#39;, &#39;O&#39;), (&#39;nonlinear&#39;, &#39;B&#39;), (&#39;wave&#39;, &#39;I&#39;), (&#39;equations&#39;, &#39;L&#39;), (&#39;are&#39;, &#39;O&#39;), (&#39;more&#39;, &#39;O&#39;), (&#39;difficult&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;investigate&#39;, &#39;B&#39;), (&#39;mathematically&#39;, &#39;L&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;as&#39;, &#39;O&#39;), (&#39;no&#39;, &#39;O&#39;), (&#39;general&#39;, &#39;O&#39;), (&#39;analytical&#39;, &#39;B&#39;), (&#39;method&#39;, &#39;L&#39;), (&#39;for&#39;, &#39;O&#39;), (&#39;their&#39;, &#39;O&#39;), (&#39;solutions&#39;, &#39;O&#39;), (&#39;exists&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;In&#39;, &#39;O&#39;), (&#39;addition&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;we&#39;, &#39;O&#39;), (&#39;propose&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;major&#39;, &#39;B&#39;), (&#39;types&#39;, &#39;I&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;learning&#39;, &#39;I&#39;), (&#39;scenarios&#39;, &#39;L&#39;), (&#39;for&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;use&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;designed&#39;, &#39;O&#39;), (&#39;systems&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;Thereupon&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;new&#39;, &#39;O&#39;), (&#39;emphases&#39;, &#39;O&#39;), (&#39;on&#39;, &#39;O&#39;), (&#39;sustainability&#39;, &#39;B&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;transportation&#39;, &#39;I&#39;), (&#39;system&#39;, &#39;L&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;megalopolis&#39;, &#39;O&#39;), (&#39;are&#39;, &#39;O&#39;), (&#39;creating&#39;, &#39;O&#39;), (&#39;new&#39;, &#39;O&#39;), (&#39;demands&#39;, &#39;O&#39;), (&#39;for&#39;, &#39;O&#39;), (&#39;adequate&#39;, &#39;O&#39;), (&#39;approach&#39;, &#39;B&#39;), (&#39;to&#39;, &#39;I&#39;), (&#39;measure&#39;, &#39;I&#39;), (&#39;its&#39;, &#39;I&#39;), (&#39;performance&#39;, &#39;I&#39;), (&#39;and&#39;, &#39;I&#39;), (&#39;diagnosis&#39;, &#39;I&#39;), (&#39;potential&#39;, &#39;I&#39;), (&#39;drawbacks&#39;, &#39;L&#39;), (&#39;.&#39;, &#39;O&#39;)]


==== Validation dataset ====
Loading docs...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 50/50 [00:07&lt;00:00,  6.32it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Constructing sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 50/50 [00:00&lt;00:00, 359.26it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
   DONE.

Same number of sentences and tag sequences: True
Size: 413
Looking at some sentences randomly:
[(&#39;Under&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;assumption&#39;, &#39;O&#39;), (&#39;that&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;noise&#39;, &#39;O&#39;), (&#39;present&#39;, &#39;O&#39;), (&#39;above&#39;, &#39;O&#39;), (&#39;1023Hz&#39;, &#39;O&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;negligible&#39;, &#39;O&#39;), (&#39;compared&#39;, &#39;O&#39;), (&#39;with&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;noise&#39;, &#39;O&#39;), (&#39;present&#39;, &#39;O&#39;), (&#39;below&#39;, &#39;O&#39;), (&#39;0.5Hz&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;this&#39;, &#39;O&#39;), (&#39;procedure&#39;, &#39;O&#39;), (&#39;enables&#39;, &#39;O&#39;), (&#39;an&#39;, &#39;O&#39;), (&#39;accurate&#39;, &#39;B&#39;), (&#39;recording&#39;, &#39;I&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;the&#39;, &#39;I&#39;), (&#39;potential&#39;, &#39;I&#39;), (&#39;noise&#39;, &#39;I&#39;), (&#39;in&#39;, &#39;I&#39;), (&#39;the&#39;, &#39;I&#39;), (&#39;frequencies&#39;, &#39;I&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;interest&#39;, &#39;L&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;avoiding&#39;, &#39;O&#39;), (&#39;aliasing&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;frequencies&#39;, &#39;O&#39;), (&#39;between&#39;, &#39;O&#39;), (&#39;0.5&#39;, &#39;O&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;1023Hz&#39;, &#39;O&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;minimizing&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;50Hz&#39;, &#39;O&#39;), (&#39;interference&#39;, &#39;O&#39;), (&#39;from&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;mains&#39;, &#39;O&#39;), (&#39;supply&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;This&#39;, &#39;O&#39;), (&#39;particular&#39;, &#39;O&#39;), (&#39;version&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;SAFT&#39;, &#39;U&#39;), (&#39;provides&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;closed&#39;, &#39;B&#39;), (&#39;form&#39;, &#39;I&#39;), (&#39;EoS&#39;, &#39;L&#39;), (&#39;that&#39;, &#39;O&#39;), (&#39;describes&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;macroscopical&#39;, &#39;O&#39;), (&#39;properties&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;Mie&#39;, &#39;B&#39;), (&#39;potential&#39;, &#39;L&#39;), (&#39;[&#39;, &#39;O&#39;), (&#39;56&#39;, &#39;O&#39;), (&#39;]&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;also&#39;, &#39;O&#39;), (&#39;known&#39;, &#39;O&#39;), (&#39;as&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;B&#39;), (&#39;m&#39;, &#39;I&#39;), (&#39;,&#39;, &#39;I&#39;), (&#39;n&#39;, &#39;I&#39;), (&#39;)&#39;, &#39;I&#39;), (&#39;potential&#39;, &#39;L&#39;), (&#39;;&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;generalized&#39;, &#39;O&#39;), (&#39;form&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;LJ&#39;, &#39;B&#39;), (&#39;potential&#39;, &#39;L&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;albeit&#39;, &#39;O&#39;), (&#39;predating&#39;, &#39;O&#39;), (&#39;it&#39;, &#39;O&#39;), (&#39;by&#39;, &#39;O&#39;), (&#39;decades&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;An&#39;, &#39;O&#39;), (&#39;essential&#39;, &#39;O&#39;), (&#39;part&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;nuclear&#39;, &#39;B&#39;), (&#39;reactor&#39;, &#39;I&#39;), (&#39;analysis&#39;, &#39;L&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;prediction&#39;, &#39;B&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;the&#39;, &#39;I&#39;), (&#39;three-dimensional&#39;, &#39;I&#39;), (&#39;space-time&#39;, &#39;I&#39;), (&#39;kinetics&#39;, &#39;I&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;neutrons&#39;, &#39;L&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;relatively&#39;, &#39;O&#39;), (&#39;large&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;finite&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;heterogeneous&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;three-dimensional&#39;, &#39;O&#39;), (&#39;reactor&#39;, &#39;B&#39;), (&#39;core&#39;, &#39;L&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;As&#39;, &#39;O&#39;), (&#39;described&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;detail&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;Section&#39;, &#39;O&#39;), (&#39;3.1&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;Rosenblatt&#39;, &#39;B&#39;), (&#39;transformation&#39;, &#39;L&#39;), (&#39;allows&#39;, &#39;O&#39;), (&#39;for&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;mapping&#39;, &#39;O&#39;), (&#39;between&#39;, &#39;O&#39;), (&#39;any&#39;, &#39;O&#39;), (&#39;domain&#39;, &#39;O&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;unit&#39;, &#39;O&#39;), (&#39;hypercube&#39;, &#39;O&#39;), (&#39;[&#39;, &#39;O&#39;), (&#39;0&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;1&#39;, &#39;O&#39;), (&#39;]&#39;, &#39;O&#39;), (&#39;D.&#39;, &#39;O&#39;), (&#39;With&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;double&#39;, &#39;O&#39;), (&#39;transformation&#39;, &#39;O&#39;), (&#39;we&#39;, &#39;O&#39;), (&#39;can&#39;, &#39;O&#39;), (&#39;reformulate&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;response&#39;, &#39;O&#39;), (&#39;function&#39;, &#39;O&#39;), (&#39;f&#39;, &#39;O&#39;), (&#39;asf&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;x&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;t&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;Q&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;=f&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;x&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;t&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;TQ1&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;TR&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;R&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;f&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;x&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;t&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;R&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;=nINcn&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;x&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;t&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;n&#39;, &#39;O&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;R&#39;, &#39;O&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;where&#39;, &#39;O&#39;), (&#39;R&#39;, &#39;O&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;any&#39;, &#39;O&#39;), (&#39;random&#39;, &#39;O&#39;), (&#39;variable&#39;, &#39;O&#39;), (&#39;drawn&#39;, &#39;O&#39;), (&#39;from&#39;, &#39;O&#39;), (&#39;pR&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;which&#39;, &#39;O&#39;), (&#39;for&#39;, &#39;O&#39;), (&#39;simplicity&#39;, &#39;O&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;chosen&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;consists&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;independent&#39;, &#39;O&#39;), (&#39;components&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;The&#39;, &#39;O&#39;), (&#39;aim&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;this&#39;, &#39;O&#39;), (&#39;paper&#39;, &#39;O&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;provide&#39;, &#39;B&#39;), (&#39;a&#39;, &#39;I&#39;), (&#39;complete&#39;, &#39;I&#39;), (&#39;assignment&#39;, &#39;I&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;the&#39;, &#39;I&#39;), (&#39;vibrational&#39;, &#39;I&#39;), (&#39;spectra&#39;, &#39;I&#39;), (&#39;of&#39;, &#39;I&#39;), (&#39;l-cysteine&#39;, &#39;L&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;both&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;orthorhombic&#39;, &#39;O&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;monoclinic&#39;, &#39;O&#39;), (&#39;forms&#39;, &#39;O&#39;), (&#39;by&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;use&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;combination&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;computational&#39;, &#39;B&#39;), (&#39;and&#39;, &#39;I&#39;), (&#39;experimental&#39;, &#39;I&#39;), (&#39;methods&#39;, &#39;L&#39;), (&#39;.&#39;, &#39;O&#39;)]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Measuring lengths&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">all_sentences_train</span> <span class="o">+</span> <span class="n">all_sentences_val</span><span class="p">):</span>
    <span class="n">sen</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span>
    <span class="n">encoded_sent</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sen</span><span class="p">,</span> <span class="n">add_special_tokens</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="n">lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoded_sent</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   Min length: </span><span class="si">{:,}</span><span class="s1"> tokens&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">lengths</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   Max length: </span><span class="si">{:,}</span><span class="s1"> tokens&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   Median length: </span><span class="si">{:,}</span><span class="s1"> tokens&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">lengths</span><span class="p">))))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Measuring lengths
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 2815/2815 [00:03&lt;00:00, 853.74it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
   Min length: 4 tokens
   Max length: 187 tokens
   Median length: 31 tokens
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>

<span class="c1"># Increase the plot size and font size.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Plot the distribution of comment lengths.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rug</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sentence Lengths&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sentence Length&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;# of Sentences&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">200</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Since we built our sentence with nltk tokenizers, we need to adapt the tagging system </span>
<span class="c1"># We don&#39;t use the tutorial version because it doesn&#39;t consider, for example, that the character &#39;-&#39; is considered to devide a word for bert but not for nltk</span>
<span class="n">null_tag</span> <span class="o">=</span> <span class="s1">&#39;-N-&#39;</span>
<span class="k">def</span> <span class="nf">tokenize_with_tags</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">):</span>
  <span class="n">complete_tags</span> <span class="o">=</span> <span class="p">[</span><span class="n">null_tag</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">):</span>
    <span class="n">complete_tags</span> <span class="o">+=</span> <span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">null_tag</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">token</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">complete_tags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">null_tag</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">complete_tags</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># This function is used for printing comprehensive representation of the data tokenized by BERT. </span>

<span class="k">def</span> <span class="nf">get_bert_token</span><span class="p">(</span><span class="n">token_id</span><span class="p">):</span>
  <span class="n">token_id</span> <span class="o">=</span> <span class="n">token_id</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">token_id</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;PAD&quot;</span>
  <span class="k">elif</span> <span class="n">token_id</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;CLS&quot;</span>
  <span class="k">elif</span> <span class="n">token_id</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;SEP&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">ids_to_tokens</span><span class="p">[</span><span class="n">token_id</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="k">import</span> <span class="n">pad_sequences</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># def pad_sequences(sequences, max_len, value,dtype=object):</span>
<span class="c1">#   ret = np.zeros((len(sequences),max_len), dtype=dtype)</span>
<span class="c1">#   for i, sequence in enumerate(sequences):</span>
<span class="c1">#     for j, elt in enumerate(sequence):</span>
<span class="c1">#       ret[i, j] = elt</span>
<span class="c1">#     ret[i,len(sequence):] = value</span>
<span class="c1">#     print(ret)</span>
<span class="c1">#     print()</span>
<span class="c1">#   return ret</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># a = [[&quot;aze&quot;, &quot;fe&quot;, &quot;e&quot;]]</span>
<span class="c1"># pad_sequences(a, 10, value=&#39;N&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># We construct final vectors, ready to be transformed into torch tensors.</span>

<span class="k">def</span> <span class="nf">get_final_data</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">all_tags</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">all_tags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> 
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Adapting tags to BERT tokenizer...&quot;</span><span class="p">)</span>
    <span class="n">ta</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize_with_tags</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">)</span> <span class="k">for</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">all_tags</span><span class="p">)))]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   DONE.&quot;</span><span class="p">)</span>
    <span class="n">tags_tokenized</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">ta</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">null_tag</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">tags_tokenized</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">sentences_X</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">attention_masks</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Applying BERT tokenizer to the sentences...&quot;</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">sentences</span><span class="p">):</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">encoded_dict</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> 
                      <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                      <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span>
                      <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> 
                      <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                      <span class="n">return_tensors</span> <span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span>
    <span class="n">sentences_X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_dict</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">attention_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_dict</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   DONE.&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">all_tags</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Looking at some sentences randomly:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences_X</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">get_bert_token</span><span class="p">(</span><span class="n">elt</span><span class="p">)</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="n">sentences_X</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">tags_tokenized</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">[</span><span class="n">elt</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="n">attention_masks</span><span class="p">[</span><span class="n">i</span><span class="p">]])))</span>

  <span class="k">return</span> <span class="n">sentences_X</span><span class="p">,</span> <span class="n">attention_masks</span><span class="p">,</span> <span class="n">tags_tokenized</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Train dataset ====&quot;</span><span class="p">)</span>
<span class="n">train_sentences_X</span><span class="p">,</span> <span class="n">train_attention_masks</span><span class="p">,</span> <span class="n">train_tags_tokenized</span> <span class="o">=</span> <span class="n">get_final_data</span><span class="p">(</span><span class="n">all_sentences_train</span><span class="p">,</span> <span class="n">all_tags_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Validation dataset ====&quot;</span><span class="p">)</span>
<span class="n">val_sentences_X</span><span class="p">,</span> <span class="n">val_attention_masks</span><span class="p">,</span> <span class="n">val_tags_tokenized</span> <span class="o">=</span> <span class="n">get_final_data</span><span class="p">(</span><span class="n">all_sentences_val</span><span class="p">,</span> <span class="n">all_tags_val</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>==== Train dataset ====
Adapting tags to BERT tokenizer...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 2402/2402 [00:06&lt;00:00, 372.89it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.
Applying BERT tokenizer to the sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 2402/2402 [00:03&lt;00:00, 705.34it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Looking at some sentences randomly:
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;micro&#39;, &#39;U&#39;, 1), (&#39;##hard&#39;, &#39;-N-&#39;, 1), (&#39;##ness&#39;, &#39;-N-&#39;, 1), (&#39;can&#39;, &#39;O&#39;, 1), (&#39;be&#39;, &#39;O&#39;, 1), (&#39;related&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;other&#39;, &#39;O&#39;, 1), (&#39;macro&#39;, &#39;O&#39;, 1), (&#39;##scopic&#39;, &#39;-N-&#39;, 1), (&#39;mechanical&#39;, &#39;O&#39;, 1), (&#39;properties&#39;, &#39;O&#39;, 1), (&#39;such&#39;, &#39;O&#39;, 1), (&#39;as&#39;, &#39;O&#39;, 1), (&#39;yield&#39;, &#39;O&#39;, 1), (&#39;stress&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;elastic&#39;, &#39;O&#39;, 1), (&#39;mod&#39;, &#39;O&#39;, 1), (&#39;##ulus&#39;, &#39;-N-&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;e&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;both&#39;, &#39;O&#39;, 1), (&#39;derived&#39;, &#39;O&#39;, 1), (&#39;from&#39;, &#39;O&#39;, 1), (&#39;compression&#39;, &#39;B&#39;, 1), (&#39;testing&#39;, &#39;L&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;longitudinal&#39;, &#39;B&#39;, 1), (&#39;beam&#39;, &#39;I&#39;, 1), (&#39;and&#39;, &#39;I&#39;, 1), (&#39;target&#39;, &#39;I&#39;, 1), (&#39;single&#39;, &#39;I&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;spin&#39;, &#39;-N-&#39;, 1), (&#39;as&#39;, &#39;L&#39;, 1), (&#39;##ym&#39;, &#39;-N-&#39;, 1), (&#39;##met&#39;, &#39;-N-&#39;, 1), (&#39;##ries&#39;, &#39;-N-&#39;, 1), (&#39;have&#39;, &#39;O&#39;, 1), (&#39;been&#39;, &#39;O&#39;, 1), (&#39;at&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;center&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;attention&#39;, &#39;O&#39;, 1), (&#39;lately&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;since&#39;, &#39;O&#39;, 1), (&#39;they&#39;, &#39;O&#39;, 1), (&#39;have&#39;, &#39;O&#39;, 1), (&#39;been&#39;, &#39;O&#39;, 1), (&#39;measured&#39;, &#39;O&#39;, 1), (&#39;by&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;hermes&#39;, &#39;B&#39;, 1), (&#39;and&#39;, &#39;I&#39;, 1), (&#39;cl&#39;, &#39;I&#39;, 1), (&#39;##as&#39;, &#39;-N-&#39;, 1), (&#39;experimental&#39;, &#39;I&#39;, 1), (&#39;collaborations&#39;, &#39;L&#39;, 1), (&#39;[&#39;, &#39;O&#39;, 1), (&#39;1&#39;, &#39;O&#39;, 1), (&#39;&#39;, &#39;-N-&#39;, 1), (&#39;4&#39;, &#39;-N-&#39;, 1), (&#39;]&#39;, &#39;O&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;more&#39;, &#39;O&#39;, 1), (&#39;measurements&#39;, &#39;O&#39;, 1), (&#39;are&#39;, &#39;O&#39;, 1), (&#39;planned&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;process&#39;, &#39;O&#39;, 1), (&#39;describes&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;activities&#39;, &#39;O&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;relationships&#39;, &#39;O&#39;, 1), (&#39;among&#39;, &#39;O&#39;, 1), (&#39;them&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;since&#39;, &#39;O&#39;, 1), (&#39;both&#39;, &#39;O&#39;, 1), (&#39;regression&#39;, &#39;U&#39;, 1), (&#39;##s&#39;, &#39;-N-&#39;, 1), (&#39;predict&#39;, &#39;O&#39;, 1), (&#39;air&#39;, &#39;B&#39;, 1), (&#39;void&#39;, &#39;I&#39;, 1), (&#39;content&#39;, &#39;L&#39;, 1), (&#39;at&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;maximum&#39;, &#39;O&#39;, 1), (&#39;difference&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;0&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;-N-&#39;, 1), (&#39;56&#39;, &#39;-N-&#39;, 1), (&#39;%&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;which&#39;, &#39;O&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;within&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;uncertainty&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;core&#39;, &#39;B&#39;, 1), (&#39;measurement&#39;, &#39;I&#39;, 1), (&#39;precision&#39;, &#39;L&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;0&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;-N-&#39;, 1), (&#39;7&#39;, &#39;-N-&#39;, 1), (&#39;%&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;use&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;either&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;initial&#39;, &#39;B&#39;, 1), (&#39;or&#39;, &#39;I&#39;, 1), (&#39;repeat&#39;, &#39;I&#39;, 1), (&#39;run&#39;, &#39;I&#39;, 1), (&#39;regression&#39;, &#39;I&#39;, 1), (&#39;predictions&#39;, &#39;L&#39;, 1), (&#39;are&#39;, &#39;O&#39;, 1), (&#39;appropriate&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;however&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;it&#39;, &#39;O&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;not&#39;, &#39;O&#39;, 1), (&#39;without&#39;, &#39;O&#39;, 1), (&#39;its&#39;, &#39;O&#39;, 1), (&#39;faults&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]


==== Validation dataset ====
Adapting tags to BERT tokenizer...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 413/413 [00:01&lt;00:00, 361.57it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.
Applying BERT tokenizer to the sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 413/413 [00:00&lt;00:00, 734.14it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Looking at some sentences randomly:
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;3&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;each&#39;, &#39;O&#39;, 1), (&#39;failed&#39;, &#39;B&#39;, 1), (&#39;face&#39;, &#39;L&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;graph&#39;, &#39;O&#39;, 1), (&#39;node&#39;, &#39;O&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;each&#39;, &#39;O&#39;, 1), (&#39;pair&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;neighbouring&#39;, &#39;O&#39;, 1), (&#39;failed&#39;, &#39;B&#39;, 1), (&#39;faces&#39;, &#39;L&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;graph&#39;, &#39;O&#39;, 1), (&#39;edge&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;where&#39;, &#39;O&#39;, 1), (&#39;two&#39;, &#39;O&#39;, 1), (&#39;micro&#39;, &#39;U&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;cracks&#39;, &#39;-N-&#39;, 1), (&#39;formed&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;continuous&#39;, &#39;O&#39;, 1), (&#39;larger&#39;, &#39;O&#39;, 1), (&#39;crack&#39;, &#39;U&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;long&#39;, &#39;B&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;chain&#39;, &#39;-N-&#39;, 1), (&#39;qu&#39;, &#39;I&#39;, 1), (&#39;##ater&#39;, &#39;-N-&#39;, 1), (&#39;##nary&#39;, &#39;-N-&#39;, 1), (&#39;am&#39;, &#39;I&#39;, 1), (&#39;##monium&#39;, &#39;-N-&#39;, 1), (&#39;bro&#39;, &#39;L&#39;, 1), (&#39;##mide&#39;, &#39;-N-&#39;, 1), (&#39;##s&#39;, &#39;-N-&#39;, 1), (&#39;were&#39;, &#39;O&#39;, 1), (&#39;also&#39;, &#39;O&#39;, 1), (&#39;reported&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;work&#39;, &#39;O&#39;, 1), (&#39;as&#39;, &#39;O&#39;, 1), (&#39;efficient&#39;, &#39;O&#39;, 1), (&#39;cis&#39;, &#39;U&#39;, 1), (&#39;for&#39;, &#39;O&#39;, 1), (&#39;steel&#39;, &#39;B&#39;, 1), (&#39;materials&#39;, &#39;L&#39;, 1), (&#39;[&#39;, &#39;O&#39;, 1), (&#39;106&#39;, &#39;O&#39;, 1), (&#39;]&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;moreover&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;even&#39;, &#39;O&#39;, 1), (&#39;for&#39;, &#39;O&#39;, 1), (&#39;it&#39;, &#39;U&#39;, 1), (&#39;##er&#39;, &#39;-N-&#39;, 1), (&#39;this&#39;, &#39;O&#39;, 1), (&#39;study&#39;, &#39;O&#39;, 1), (&#39;could&#39;, &#39;O&#39;, 1), (&#39;be&#39;, &#39;O&#39;, 1), (&#39;useful&#39;, &#39;O&#39;, 1), (&#39;if&#39;, &#39;O&#39;, 1), (&#39;carbon&#39;, &#39;B&#39;, 1), (&#39;materials&#39;, &#39;L&#39;, 1), (&#39;have&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;be&#39;, &#39;O&#39;, 1), (&#39;eventually&#39;, &#39;O&#39;, 1), (&#39;installed&#39;, &#39;O&#39;, 1), (&#39;in&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;case&#39;, &#39;O&#39;, 1), (&#39;that&#39;, &#39;O&#39;, 1), (&#39;operation&#39;, &#39;O&#39;, 1), (&#39;with&#39;, &#39;O&#39;, 1), (&#39;tung&#39;, &#39;B&#39;, 1), (&#39;##sten&#39;, &#39;-N-&#39;, 1), (&#39;tiles&#39;, &#39;L&#39;, 1), (&#39;at&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;strike&#39;, &#39;O&#39;, 1), (&#39;points&#39;, &#39;O&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;pre&#39;, &#39;O&#39;, 1), (&#39;##cl&#39;, &#39;-N-&#39;, 1), (&#39;##uded&#39;, &#39;-N-&#39;, 1), (&#39;by&#39;, &#39;O&#39;, 1), (&#39;unexpected&#39;, &#39;O&#39;, 1), (&#39;reasons&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;[&#39;, &#39;O&#39;, 1), (&#39;4&#39;, &#39;O&#39;, 1), (&#39;]&#39;, &#39;O&#39;, 1), (&#39;took&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;more&#39;, &#39;O&#39;, 1), (&#39;systematic&#39;, &#39;O&#39;, 1), (&#39;approach&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;such&#39;, &#39;O&#39;, 1), (&#39;glass&#39;, &#39;B&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;ceramic&#39;, &#39;-N-&#39;, 1), (&#39;waste&#39;, &#39;L&#39;, 1), (&#39;##forms&#39;, &#39;-N-&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Map each unique label to an integer.</span>
<span class="c1"># label_map = {&#39;N&#39;:-100} # we don&#39;t keep that to be able to apply one_hot encoding for custom BERT</span>
<span class="n">label_map</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># For each label...</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">tag</span> <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">train_tags_tokenized</span> <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">L</span><span class="p">])):</span>
    
    <span class="c1"># Map it to its integer.</span>
    <span class="n">label_map</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;O&#39;: 0, &#39;I&#39;: 1, &#39;-N-&#39;: 2, &#39;U&#39;: 3, &#39;B&#39;: 4, &#39;L&#39;: 5}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_new_labels</span> <span class="o">=</span> <span class="p">[[</span><span class="n">label_map</span><span class="p">[</span><span class="n">elt</span><span class="p">]</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="n">L</span><span class="p">]</span> <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">train_tags_tokenized</span><span class="p">]</span>
<span class="n">val_new_labels</span> <span class="o">=</span> <span class="p">[[</span><span class="n">label_map</span><span class="p">[</span><span class="n">elt</span><span class="p">]</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="n">L</span><span class="p">]</span> <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">val_tags_tokenized</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># We construct the torch data structures that will be used for creating batches to pass to the different Bert models</span>

<span class="k">def</span> <span class="nf">get_data_loader</span><span class="p">(</span><span class="n">sentences_X</span><span class="p">,</span> <span class="n">attention_masks</span><span class="p">,</span> <span class="n">new_labels</span><span class="p">,</span> <span class="n">sampler</span><span class="p">):</span>
  <span class="n">pt_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">sentences_X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">pt_attention_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">attention_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> 
    <span class="n">pt_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">new_labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">pt_input_ids</span><span class="p">,</span> <span class="n">pt_attention_masks</span><span class="p">,</span> <span class="n">pt_labels</span><span class="p">)</span>

  <span class="k">else</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">pt_input_ids</span><span class="p">,</span> <span class="n">pt_attention_masks</span><span class="p">)</span>

  <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
  <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span>  <span class="c1"># The training samples.</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="c1"># Select batches randomly</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="c1"># Trains with this batch size.</span>
        <span class="p">)</span>
  <span class="k">return</span> <span class="n">dataloader</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">get_data_loader</span><span class="p">(</span><span class="n">train_sentences_X</span><span class="p">,</span> <span class="n">train_attention_masks</span><span class="p">,</span> <span class="n">train_new_labels</span><span class="p">,</span> <span class="n">RandomSampler</span><span class="p">)</span>
<span class="n">validation_dataloader</span> <span class="o">=</span> <span class="n">get_data_loader</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">,</span> <span class="n">val_attention_masks</span><span class="p">,</span> <span class="n">val_new_labels</span><span class="p">,</span> <span class="n">SequentialSampler</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-definition">Model definition<a class="anchor-link" href="#Model-definition">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">format_time</span><span class="p">(</span><span class="n">elapsed</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Takes a time in seconds and returns a string hh:mm:ss</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Round to the nearest second.</span>
    <span class="n">elapsed_rounded</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">((</span><span class="n">elapsed</span><span class="p">)))</span>
    
    <span class="c1"># Format as hh:mm:ss</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="n">elapsed_rounded</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_BertForTokenClassification</span><span class="p">(</span><span class="n">label_map</span><span class="p">):</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">BertForTokenClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="c1"># Use the 12-layer BERT model, with an uncased vocab.</span>
    <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># The number of output labels</span>
    <span class="n">output_attentions</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># Whether the model returns attentions weights.</span>
    <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># Whether the model returns all hidden-states.</span>
  <span class="p">)</span>
  <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Here we difine different strategies for aggregating the last layers of Bert into a single vector to pass to the fine-tuned part</span>

<span class="k">def</span> <span class="nf">Nth_layer</span><span class="p">(</span><span class="n">layer_list</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;return layer at index N statring from the end. For example to get last lyer you should use N=0&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">layer_list</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">get_Nth_layer</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
  <span class="k">return</span> <span class="k">lambda</span> <span class="n">layer_list</span><span class="p">:</span> <span class="n">Nth_layer</span><span class="p">(</span><span class="n">layer_list</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

<span class="n">last_layer_alone</span> <span class="o">=</span> <span class="n">get_Nth_layer</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">mean_N_last_layer</span><span class="p">(</span><span class="n">layer_list</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">layer_list</span><span class="p">[</span><span class="o">-</span><span class="n">N</span><span class="p">:]),</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_mean_N_last_layer</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
  <span class="k">return</span> <span class="k">lambda</span> <span class="n">layer_list</span><span class="p">:</span> <span class="n">mean_N_last_layer</span><span class="p">(</span><span class="n">layer_list</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
  
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">BertModel</span>

<span class="k">class</span> <span class="nc">BertCustom</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aggregation_stategy</span><span class="o">=</span><span class="n">last_layer_alone</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">freeze_bert</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BertCustom</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="c1"># Instantiate BERT model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-uncased&#39;</span><span class="p">)</span>

        <span class="c1"># Bert-base embedding have dim 768</span>
        <span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D_out</span> <span class="o">=</span>  <span class="mi">768</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># Instantiate an one-layer feed-forward network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="c1">#nn.Dropout(0.5),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Freeze the BERT model</span>
        <span class="k">if</span> <span class="n">freeze_bert</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_stategy</span> <span class="o">=</span> <span class="n">aggregation_stategy</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
        <span class="c1"># Feed input to BERT</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                            <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Extract the last hidden state of the token `[CLS]` for classification task</span>
        <span class="n">hidden_state_aggregation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_stategy</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="c1"># Feed input to classifier to compute logits</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">hidden_state_aggregation</span><span class="p">)</span>

        <span class="c1"># Compute loss</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="kc">None</span>

        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="n">cat_labels</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">cat_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span><span class="n">cat_labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_Bert_custom</span><span class="p">(</span><span class="n">aggregation_stategy</span><span class="o">=</span><span class="n">last_layer_alone</span><span class="p">,</span><span class="n">H</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">BertCustom</span><span class="p">(</span><span class="n">aggregation_stategy</span><span class="o">=</span><span class="n">aggregation_stategy</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="n">H</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-training-and-saving-explicit">Model training and saving explicit<a class="anchor-link" href="#Model-training-and-saving-explicit">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load model </span>
<span class="c1"># model = get_Bert_custom(aggregation_stategy=get_mean_N_last_layer(6))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_BertForTokenClassification</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span>

<span class="c1"># # Tell pytorch to run this model on the GPU.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>





 
 
<div id="6a9bb652-bac2-4fa1-a883-5fc82ab6aebb"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#6a9bb652-bac2-4fa1-a883-5fc82ab6aebb');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "24dee2ed298e466b8b9cdc1afe66b729", "version_minor": 0, "version_major": 2}
</script>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: [&#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.bias&#39;]
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load the AdamW optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                  <span class="n">lr</span> <span class="o">=</span> <span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="c1"># args.learning_rate </span>
                  <span class="n">eps</span> <span class="o">=</span> <span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">8</span> <span class="c1"># args.adam_epsilon </span>
                <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of training epochs </span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Total number of training steps is number of batches * number of epochs.</span>
<span class="n">total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">epochs</span>

<span class="c1"># Create the learning rate scheduler.</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> 
                                            <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                                            <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># This training code is based on the `run_glue.py` script here:</span>
<span class="c1"># https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128</span>


<span class="c1"># Set the seed value all over the place to make this reproducible.</span>
<span class="n">seed_val</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>

<span class="c1"># Store the average loss after each epoch so we can plot them.</span>
<span class="n">loss_values</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each epoch...</span>
<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
  <span class="c1"># print(i)</span>
  <span class="c1"># print(isinstance(model,BertClassifier))</span>
    
  <span class="c1"># ========================================</span>
  <span class="c1">#               Training</span>
  <span class="c1"># ========================================</span>
  
  <span class="c1"># Perform one full pass over the training set.</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;======== Epoch </span><span class="si">{:}</span><span class="s1"> / </span><span class="si">{:}</span><span class="s1"> ========&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training...&#39;</span><span class="p">)</span>

  <span class="c1"># Measure how long the training epoch takes.</span>
  <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

  <span class="c1"># Reset the total loss for this epoch.</span>
  <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># Put the model into training mode. Don&#39;t be mislead--the call to </span>
  <span class="c1"># `train` just changes the *mode*, it doesn&#39;t *perform* the training.</span>
  <span class="c1"># `dropout` and `batchnorm` layers behave differently during training</span>
  <span class="c1"># vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

  <span class="c1"># For each batch of training data...</span>
  <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)):</span>

      <span class="c1"># Unpack this training batch from our dataloader. </span>
      <span class="c1">#</span>
      <span class="c1"># As we unpack the batch, we&#39;ll also copy each tensor to the GPU using the </span>
      <span class="c1"># `to` method.</span>
      <span class="c1">#</span>
      <span class="c1"># `batch` contains three pytorch tensors:</span>
      <span class="c1">#   [0]: input ids </span>
      <span class="c1">#   [1]: attention masks</span>
      <span class="c1">#   [2]: labels </span>
      <span class="n">b_input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">b_input_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">b_labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

      <span class="c1"># Always clear any previously calculated gradients before performing a</span>
      <span class="c1"># backward pass. PyTorch doesn&#39;t do this automatically because </span>
      <span class="c1"># accumulating the gradients is &quot;convenient while training RNNs&quot;. </span>
      <span class="c1"># (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)</span>
      <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>        

      <span class="c1"># In PyTorch, calling `model` will in turn call the model&#39;s `forward` </span>
      <span class="c1"># function and pass down the arguments. The `forward` function is </span>
      <span class="c1"># documented here: </span>
      <span class="c1"># https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification</span>
      <span class="c1"># The results are returned in a results object, documented here:</span>
      <span class="c1"># https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.TokenClassifierOutput</span>
      
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">BertCustom</span><span class="p">):</span>
        <span class="n">logits</span><span class="p">,</span><span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span>
                  <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span>
                  <span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> 
                  <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                  <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span>
                  <span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">loss</span>

      <span class="c1"># Accumulate the training loss over all of the batches so that we can</span>
      <span class="c1"># calculate the average loss at the end. `loss` is a Tensor containing a</span>
      <span class="c1"># single value; the `.item()` function just returns the Python value </span>
      <span class="c1"># from the tensor.</span>
      <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

      <span class="c1"># Perform a backward pass to calculate the gradients.</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

      <span class="c1"># Clip the norm of the gradients to 1.0.</span>
      <span class="c1"># This is to help prevent the &quot;exploding gradients&quot; problem.</span>
      <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>

      <span class="c1"># Update parameters and take a step using the computed gradient.</span>
      <span class="c1"># The optimizer dictates the &quot;update rule&quot;--how the parameters are</span>
      <span class="c1"># modified based on their gradients, the learning rate, etc.</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># Update the learning rate.</span>
      <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
      

  <span class="c1"># Calculate the average loss over the training data.</span>
  <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>            
  
  <span class="c1"># Store the loss value for plotting the learning curve.</span>
  <span class="n">loss_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Average training loss: </span><span class="si">{0:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Training epoch took: </span><span class="si">{:}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">format_time</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)))</span>
        

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training complete!&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
======== Epoch 1 / 5 ========
Training...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre> 11%|         | 16/151 [00:16&lt;02:21,  1.05s/it]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-49-5566c9e08523&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     78</span>                   token_type_ids<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     79</span>                   attention_mask<span class="ansi-blue-fg">=</span>b_input_mask
<span class="ansi-green-fg">---&gt; 80</span><span class="ansi-red-fg">                   ,labels=b_labels)
</span><span class="ansi-green-intense-fg ansi-bold">     81</span>         loss <span class="ansi-blue-fg">=</span> result<span class="ansi-blue-fg">.</span>loss
<span class="ansi-green-intense-fg ansi-bold">     82</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1100</span>         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
<span class="ansi-green-intense-fg ansi-bold">   1101</span>                 or _global_forward_hooks or _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1102</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> forward_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1103</span>         <span class="ansi-red-fg"># Do not call functions when jit is used</span>
<span class="ansi-green-intense-fg ansi-bold">   1104</span>         full_backward_hooks<span class="ansi-blue-fg">,</span> non_full_backward_hooks <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)</span>
<span class="ansi-green-intense-fg ansi-bold">   1749</span>                 active_logits <span class="ansi-blue-fg">=</span> logits<span class="ansi-blue-fg">.</span>view<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>num_labels<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1750</span>                 active_labels = torch.where(
<span class="ansi-green-fg">-&gt; 1751</span><span class="ansi-red-fg">                     </span>active_loss<span class="ansi-blue-fg">,</span> labels<span class="ansi-blue-fg">.</span>view<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> torch<span class="ansi-blue-fg">.</span>tensor<span class="ansi-blue-fg">(</span>loss_fct<span class="ansi-blue-fg">.</span>ignore_index<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>type_as<span class="ansi-blue-fg">(</span>labels<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1752</span>                 )
<span class="ansi-green-intense-fg ansi-bold">   1753</span>                 loss <span class="ansi-blue-fg">=</span> loss_fct<span class="ansi-blue-fg">(</span>active_logits<span class="ansi-blue-fg">,</span> active_labels<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span> <span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Use plot styling from seaborn.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;darkgrid&#39;</span><span class="p">)</span>

<span class="c1"># Increase the plot size and font size.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>

<span class="c1"># Plot the learning curve.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_values</span><span class="p">,</span> <span class="s1">&#39;b-o&#39;</span><span class="p">)</span>

<span class="c1"># Label the plot.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># import os</span>

<span class="c1"># # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()</span>

<span class="c1"># output_dir = &#39;models/BERT_models_V5 (?)&#39;</span>

<span class="c1"># # Create output directory if needed</span>
<span class="c1"># if not os.path.exists(output_dir):</span>
<span class="c1">#     os.makedirs(output_dir)</span>

<span class="c1"># print(&quot;Saving model to %s&quot; % output_dir)</span>

<span class="c1"># # Save a trained model, configuration and tokenizer using `save_pretrained()`.</span>
<span class="c1"># # They can then be reloaded using `from_pretrained()`</span>
<span class="c1"># model_to_save = model.module if hasattr(model, &#39;module&#39;) else model  # Take care of distributed/parallel training</span>
<span class="c1"># if &#39;save_pretrained&#39; in dir(model_to_save):</span>
<span class="c1">#   model_to_save.save_pretrained(output_dir)</span>
<span class="c1"># else:</span>
<span class="c1">#   torch.save(model_to_save.state_dict(), os.path.join(output_dir, &#39;model.pt&#39;))</span>
<span class="c1"># tokenizer.save_pretrained(output_dir)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load a trained model and vocabulary that you have fine-tuned</span>
<span class="c1"># model = model_class.from_pretrained(output_dir)</span>
<span class="c1"># tokenizer = tokenizer_class.from_pretrained(output_dir)</span>

<span class="c1"># # Copy the model to the GPU.</span>
<span class="c1"># model.to(device)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-optimization">Model optimization<a class="anchor-link" href="#Model-optimization">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">8</span><span class="p">)</span>

  <span class="n">total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">epochs</span>

  <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
  <span class="n">seed_val</span> <span class="o">=</span> <span class="mi">42</span>

  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>

  <span class="n">loss_values</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">))):</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
        <span class="n">b_input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b_input_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b_labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>        

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">BertCustom</span><span class="p">):</span>
          <span class="n">logits</span><span class="p">,</span><span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span>
                    <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span>
                    <span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> 
                    <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                    <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span>
                    <span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">loss</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validation_dataloader</span><span class="p">,</span> <span class="n">label_map</span><span class="p">):</span>

  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

  <span class="n">predictions</span> <span class="p">,</span> <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_dataloader</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
    
    <span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span><span class="p">,</span> <span class="n">b_labels</span> <span class="o">=</span> <span class="n">batch</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">BertCustom</span><span class="p">):</span>
          <span class="n">logits</span><span class="p">,</span><span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span>
                    <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span>
                    <span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> 
                    <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                    <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span>
                    <span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">loss</span>
          <span class="n">logits</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">logits</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">label_ids</span> <span class="o">=</span> <span class="n">b_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">true_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

    <span class="n">all_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


  <span class="n">all_true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">predicted_label_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">all_predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

  <span class="n">predicted_label_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predicted_label_ids</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">all_true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_true_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">index_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">value</span><span class="p">:</span> <span class="n">key</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">label_map</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

  <span class="n">real_token_predictions</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">real_token_labels</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">predicted_label</span><span class="p">,</span> <span class="n">real_label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predicted_label_ids</span><span class="p">,</span><span class="n">all_true_labels</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">index_map</span><span class="p">[</span><span class="n">real_label</span><span class="p">]</span> <span class="ow">in</span> <span class="p">(</span><span class="n">null_tag</span><span class="p">,</span><span class="s2">&quot;P&quot;</span><span class="p">):</span>
          <span class="n">real_token_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_label</span><span class="p">)</span>
          <span class="n">real_token_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">real_label</span><span class="p">)</span>

  
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;f1 micro: {f1_score(real_token_labels, real_token_predictions, average=&#39;micro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Accuracy: {accuracy_score(real_token_labels, real_token_predictions):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">real_token_labels</span><span class="p">,</span> <span class="n">real_token_predictions</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">real_token_labels</span><span class="p">,</span> <span class="n">real_token_predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">get_BertForTokenClassification</span><span class="p">(),</span> <span class="c1"># default strategy, I don&#39;t know which it is</span>
          <span class="n">get_Bert_custom</span><span class="p">(),</span> <span class="c1"># using only last layer, I get equivalent to default strategy</span>
          <span class="n">get_Bert_custom</span><span class="p">(</span><span class="n">aggregation_stategy</span><span class="o">=</span><span class="n">get_mean_N_last_layer</span><span class="p">(</span><span class="mi">3</span><span class="p">)),</span> <span class="c1"># averaging 3 last layers</span>
          <span class="n">get_Bert_custom</span><span class="p">(</span><span class="n">aggregation_stategy</span><span class="o">=</span><span class="n">get_mean_N_last_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)),</span> <span class="c1"># averaging 5 last layers</span>
          <span class="n">get_Bert_custom</span><span class="p">(</span><span class="n">aggregation_stategy</span><span class="o">=</span><span class="n">get_Nth_layer</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="c1"># using only second last layer</span>
          <span class="n">get_Bert_custom</span><span class="p">(</span><span class="n">aggregation_stategy</span><span class="o">=</span><span class="n">get_Nth_layer</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="c1"># using only third last layer</span>
          <span class="p">]</span>
<span class="n">best_model</span><span class="p">,</span> <span class="n">best_score</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
  <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Model n</span><span class="si">{i}</span><span class="s2">/{len(models)}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training...&quot;</span><span class="p">)</span>
  <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Validation -&gt;&quot;</span><span class="p">)</span>
  <span class="n">score</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validation_dataloader</span><span class="p">,</span> <span class="n">label_map</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">model</span>
  <span class="nb">print</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">best_model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Model-test-predictions">Model test predictions<a class="anchor-link" href="#Model-test-predictions">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_sentences_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_doc_sentences</span><span class="p">(</span><span class="n">get_text_docs</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">test_sentences</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading docs...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 100/100 [00:39&lt;00:00,  2.52it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Constructing sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 100/100 [00:00&lt;00:00, 384.41it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
   DONE.

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Measuring lengths&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">all_sentences_test</span><span class="p">):</span>
    <span class="n">sen</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span>
    <span class="n">encoded_sent</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sen</span><span class="p">,</span> <span class="n">add_special_tokens</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="n">lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoded_sent</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   Min length: </span><span class="si">{:,}</span><span class="s1"> tokens&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">lengths</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   Max length: </span><span class="si">{:,}</span><span class="s1"> tokens&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   Median length: </span><span class="si">{:,}</span><span class="s1"> tokens&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">lengths</span><span class="p">))))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Measuring lengths
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 829/829 [00:00&lt;00:00, 937.34it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
   Min length: 4 tokens
   Max length: 137 tokens
   Median length: 31 tokens
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_sentences_X</span><span class="p">,</span> <span class="n">test_attention_masks</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_final_data</span><span class="p">(</span><span class="n">all_sentences_test</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Applying BERT tokenizer to the sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 829/829 [00:01&lt;00:00, 789.66it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">get_data_loader</span><span class="p">(</span><span class="n">test_sentences_X</span><span class="p">,</span> <span class="n">test_attention_masks</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">SequentialSampler</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Prediction on test set</span>

<span class="c1"># Put model in evaluation mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Tracking variables </span>
<span class="n">predictions_test</span> <span class="p">,</span> <span class="n">true_labels_test</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="c1"># Predict </span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
  <span class="c1"># Add batch to GPU</span>
  <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>

  <span class="c1"># Unpack the inputs from our dataloader</span>
  <span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span> <span class="o">=</span> <span class="n">batch</span>
  
  <span class="c1"># Telling the model not to compute or store gradients, saving memory and </span>
  <span class="c1"># speeding up prediction</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="c1"># Forward pass, calculate logit predictions</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">BertCustom</span><span class="p">):</span>
        <span class="n">logits</span><span class="p">,</span><span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> 
                      <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                      <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span>
                      <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">logits</span>

  <span class="c1"># Move logits and labels to CPU</span>
  <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">label_ids</span> <span class="o">=</span> <span class="n">b_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  
  <span class="c1"># Store predictions and true labels</span>
  <span class="n">predictions_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
  <span class="n">true_labels_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;    DONE.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 52/52 [00:25&lt;00:00,  2.05it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    DONE.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_predictions_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">predicted_label_ids_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">all_predictions_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">predicted_label_ids_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predicted_label_ids_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">value</span><span class="p">:</span> <span class="n">key</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">label_map</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">index_map</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{0: &#39;N&#39;, 1: &#39;B&#39;, 2: &#39;L&#39;, 3: &#39;U&#39;, 4: &#39;O&#39;, 5: &#39;I&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_df_soumission</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DocID&#39;</span><span class="p">,</span> <span class="s1">&#39;Token&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test_df_soumission</span> <span class="o">=</span> <span class="n">test_df_soumission</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s1">&#39;Tag&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">})</span>

<span class="n">clean_tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">clean_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predicted_label_ids_test</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_sentences_X</span><span class="p">)):</span>
  <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">):</span>
    <span class="n">clean_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">index_map</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span> <span class="o">==</span> <span class="n">null_tag</span><span class="p">:</span>
      <span class="n">clean_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;O&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">clean_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index_map</span><span class="p">[</span><span class="n">pred</span><span class="p">])</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_sentences_test</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ids</span><span class="p">)))):</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">test_df_soumission</span><span class="p">[</span><span class="n">test_df_soumission</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">word_id</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">test_df_soumission</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clean_predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">i</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre></pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_df_soumission</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TokenID</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0885230816301759-0</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0885230816301759-1</td>
      <td>O</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0885230816301759-2</td>
      <td>O</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0885230816301759-3</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0885230816301759-4</td>
      <td>B</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21706</th>
      <td>S1877750313001269-211</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21707</th>
      <td>S1877750313001269-212</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21708</th>
      <td>S1877750313001269-213</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21709</th>
      <td>S1877750313001269-214</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21710</th>
      <td>S1877750313001269-215</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
<p>21711 rows  2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_df_soumission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;submission_test_A_bert.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">plot_confusion_matrix</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="BERT-Evaluation">BERT Evaluation<a class="anchor-link" href="#BERT-Evaluation">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Prediction on test set</span>

<span class="c1"># Put model in evaluation mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Tracking variables </span>
<span class="n">predictions</span> <span class="p">,</span> <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="c1"># Predict </span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">validation_dataloader</span><span class="p">):</span>
  <span class="c1"># Add batch to GPU</span>
  <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
  
  <span class="c1"># Unpack the inputs from our dataloader</span>
  <span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span><span class="p">,</span> <span class="n">b_labels</span> <span class="o">=</span> <span class="n">batch</span>
  
  <span class="c1"># Telling the model not to compute or store gradients, saving memory and </span>
  <span class="c1"># speeding up prediction</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="c1"># Forward pass, calculate logit predictions</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">BertCustom</span><span class="p">):</span>
        <span class="n">logits</span><span class="p">,</span><span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span>
                  <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span>
                  <span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> 
                  <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                  <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span>
                  <span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">loss</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">logits</span>

  <span class="c1"># Move logits and labels to CPU</span>
  <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">label_ids</span> <span class="o">=</span> <span class="n">b_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  
  <span class="c1"># Store predictions and true labels</span>
  <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
  <span class="n">true_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;    DONE.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 26/26 [00:10&lt;00:00,  2.58it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    DONE.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predicted_label_ids</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(82600,)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">all_true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">predicted_label_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">all_predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">predicted_label_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predicted_label_ids</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">all_true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_true_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">value</span><span class="p">:</span> <span class="n">key</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">label_map</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">index_map</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{0: &#39;O&#39;, 1: &#39;I&#39;, 2: &#39;-N-&#39;, 3: &#39;U&#39;, 4: &#39;B&#39;, 5: &#39;L&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Construct new lists of predictions which don&#39;t include any null tokens.</span>
<span class="n">real_token_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">real_token_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each of the input tokens in the dataset...</span>
<span class="k">for</span> <span class="n">predicted_label</span><span class="p">,</span> <span class="n">real_label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predicted_label_ids</span><span class="p">,</span><span class="n">all_true_labels</span><span class="p">):</span>

    <span class="c1"># If it&#39;s not a token with a null label...</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">index_map_B</span><span class="p">[</span><span class="n">real_label</span><span class="p">]</span> <span class="o">==</span> <span class="n">null_tag</span><span class="p">:</span>
        
        <span class="c1"># Add the prediction and the ground truth to their lists.</span>
        <span class="k">if</span> <span class="n">index_map_B</span><span class="p">[</span><span class="n">predicted_label</span><span class="p">]</span> <span class="o">==</span> <span class="n">null_tag</span><span class="p">:</span>
          <span class="n">real_token_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_map</span><span class="p">[</span><span class="s2">&quot;O&quot;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">real_token_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_label</span><span class="p">)</span>
        <span class="n">real_token_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">real_label</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before filtering out `null` tokens, length = </span><span class="si">{:,}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_true_labels</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; After filtering out `null` tokens, length = </span><span class="si">{:,}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">real_token_labels</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Before filtering out `null` tokens, length = 82,600
 After filtering out `null` tokens, length = 11,161
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">set</span><span class="p">(</span><span class="n">all_true_labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{0, 1, 2, 3, 4, 5}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">label_map</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;B&#39;: 1, &#39;I&#39;: 5, &#39;L&#39;: 2, &#39;N&#39;: 0, &#39;O&#39;: 4, &#39;U&#39;: 3}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">index_map</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">target_names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">null_tag</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">real_token_labels</span><span class="p">,</span> <span class="n">real_token_predictions</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           B       0.59      0.72      0.65       694
           U       0.73      0.58      0.65       361
           I       0.56      0.59      0.57      1072
           L       0.68      0.82      0.74       694
           O       0.93      0.90      0.91      8340

    accuracy                           0.84     11161
   macro avg       0.70      0.72      0.70     11161
weighted avg       0.85      0.84      0.84     11161

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Bi-LSTM-Evaluation">Bi-LSTM Evaluation<a class="anchor-link" href="#Bi-LSTM-Evaluation">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_weights</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model = models[-2]</span>
<span class="k">def</span> <span class="nf">show_confusion</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
  <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">)</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
  <span class="n">true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">val_tags_y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;f1 micro:{f1_score(true, pred, average=&#39;micro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;f1 micro:{f1_score(true, pred, average=&#39;macro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;recall macro:{recall_score(true, pred, average=&#39;macro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span>
<span class="n">show_confusion</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="c1"># print(tag2weights_list[0])</span>
<span class="c1"># show_confusion(models[0])</span>
<span class="c1"># print()</span>
<span class="c1"># print(tag2weights_list[1])</span>
<span class="c1"># show_confusion(models[2])</span>
<span class="c1"># print()</span>
<span class="c1"># print(tag2weights_list[2])</span>
<span class="c1"># show_confusion(models[4])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-Sous-t&#226;che-B-:-Identification-des-mots-cl&#233;s-et-de-leurs-types-(85%)">2. Sous-t&#226;che B : Identification des mots-cl&#233;s et de leurs types (85%)<a class="anchor-link" href="#2.-Sous-t&#226;che-B-:-Identification-des-mots-cl&#233;s-et-de-leurs-types-(85%)">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="a.-Pr&#233;traitement-des-donn&#233;es">a. Pr&#233;traitement des donn&#233;es<a class="anchor-link" href="#a.-Pr&#233;traitement-des-donn&#233;es">&#182;</a></h2><p>Premires tapes de prtraitement communes  tous les modles. Nous rcuprons les informations des fichiers .ann pour associ les tags aux jetons</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_id</span> <span class="o">=</span> <span class="mi">18</span>
<span class="k">def</span> <span class="nf">set_tag_B</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">sub_data</span><span class="p">):</span>
  <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Tag&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
  <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
  <span class="n">doc_id</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))):</span>
    <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">doc_id</span><span class="p">:</span>
      <span class="n">i0</span> <span class="o">=</span> <span class="n">i</span>
      <span class="n">doc_id</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;DocID&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;data/</span><span class="si">{sub_data}</span><span class="s2">/</span><span class="si">{doc_id}</span><span class="s2">.ann&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Type&quot;</span><span class="p">,</span> <span class="s2">&quot;Annotation&quot;</span><span class="p">,</span> <span class="s2">&quot;Tokens&quot;</span><span class="p">])</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">ANN</span><span class="p">[</span><span class="n">ANN</span><span class="p">[</span><span class="s1">&#39;Type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="s2">&quot;T&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
      <span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Tokens begining&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Annotation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Type_Letter&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">ANN</span><span class="p">[</span><span class="s2">&quot;Annotation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
      <span class="n">ANN</span> <span class="o">=</span> <span class="n">ANN</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">ANN</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])]</span>

      <span class="n">tokens_id</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">match_id</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">tokens_id</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ANN</span><span class="p">):</span> 
      <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;O&quot;</span>
      <span class="k">continue</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">token</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Token&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">tokens</span><span class="p">[</span><span class="n">match_id</span><span class="p">]</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">match_id</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;U&quot;</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">previous_tokens_id</span> <span class="o">=</span> <span class="n">tokens_id</span>
        <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">tokens_id</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">ANN</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">previous_tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">]):</span>
          <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">elif</span> <span class="n">match_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">match_id</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="n">match_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">entity_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;B&quot;</span> <span class="o">+</span>  <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">entity_ids</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
          <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;I&quot;</span> <span class="o">+</span>  <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;L&quot;</span> <span class="o">+</span>  <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">match_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">previous_tokens_id</span> <span class="o">=</span> <span class="n">tokens_id</span>
        <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">tokens_id</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">ANN</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="nb">int</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; |;&quot;</span><span class="p">,</span> <span class="n">ANN</span><span class="p">[</span><span class="n">previous_tokens_id</span><span class="p">][</span><span class="mi">1</span><span class="p">])[</span><span class="mi">2</span><span class="p">]):</span>
          <span class="n">tokens_id</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">entity_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">match_id</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;O&quot;</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">entity_ids</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;O&quot;</span>
      <span class="n">entity_ids</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">match_id</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">return</span> <span class="n">df</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="s2">&quot;train_B_bilou.csv&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">():</span>
  <span class="n">train_B_df</span> <span class="o">=</span> <span class="n">set_tag_B</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>
  <span class="n">train_B_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;train_B_bilou.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">train_B_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;train_B_bilou.csv&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="s2">&quot;val_B_bilou.csv&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">():</span>
  <span class="n">val_B_df</span> <span class="o">=</span> <span class="n">set_tag_B</span><span class="p">(</span><span class="n">val_df</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)</span>
  <span class="n">val_B_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;val_B_bilou.csv&quot;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">val_B_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;val_B_bilou.csv&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_B_df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DocID</th>
      <th>TokenID</th>
      <th>Token</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-0</td>
      <td>The</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-1</td>
      <td>vapour</td>
      <td>B_M</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-2</td>
      <td>phase</td>
      <td>L_M</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-3</td>
      <td>consists</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0022311514001640</td>
      <td>S0022311514001640-4</td>
      <td>of</td>
      <td>O</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>64177</th>
      <td>S0370269304009979</td>
      <td>S0370269304009979-187</td>
      <td>various</td>
      <td>O</td>
    </tr>
    <tr>
      <th>64178</th>
      <td>S0370269304009979</td>
      <td>S0370269304009979-188</td>
      <td>brane</td>
      <td>B_P</td>
    </tr>
    <tr>
      <th>64179</th>
      <td>S0370269304009979</td>
      <td>S0370269304009979-189</td>
      <td>world</td>
      <td>I_P</td>
    </tr>
    <tr>
      <th>64180</th>
      <td>S0370269304009979</td>
      <td>S0370269304009979-190</td>
      <td>models</td>
      <td>L_P</td>
    </tr>
    <tr>
      <th>64181</th>
      <td>S0370269304009979</td>
      <td>S0370269304009979-191</td>
      <td>.</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
<p>64182 rows  4 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_sentences_B</span><span class="p">,</span> <span class="n">train_tags_B</span><span class="p">,</span> <span class="n">train_ids_B</span> <span class="o">=</span> <span class="n">vectorize_tagged_sentence</span><span class="p">(</span><span class="n">train_B_df</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">val_sentences_B</span><span class="p">,</span> <span class="n">val_tags_B</span><span class="p">,</span> <span class="n">val_ids_B</span> <span class="o">=</span> <span class="n">vectorize_tagged_sentence</span><span class="p">(</span><span class="n">val_B_df</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">)</span>
<span class="n">test_sentences_B</span><span class="p">,</span> <span class="n">test_ids_B</span> <span class="o">=</span> <span class="n">vectorize_test_sentence</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 350/350 [00:01&lt;00:00, 244.21it/s]
100%|| 50/50 [00:00&lt;00:00, 752.71it/s]
100%|| 100/100 [00:00&lt;00:00, 549.17it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="b.&amp;c.-Models-et-Evaluations">b.&amp;c. Models et Evaluations<a class="anchor-link" href="#b.&amp;c.-Models-et-Evaluations">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CRF">CRF<a class="anchor-link" href="#CRF">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On utilise le mme modle que pour la tache, L-BFGS avec Elastic Net (L1 + L2) regularization comme propos par le tutoriel en ligne.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Pre-traitement-des-donn&#233;es">Pre-traitement des donn&#233;es<a class="anchor-link" href="#Pre-traitement-des-donn&#233;es">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we define the input of our CRF by addind the POS tag for each sentence, </span>
<span class="c1"># we need them for the features of our CRF</span>
<span class="n">X_crf_train_B</span><span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag_sents</span><span class="p">(</span><span class="n">train_sentences_B</span><span class="p">)</span>
<span class="n">X_crf_val_B</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag_sents</span><span class="p">(</span><span class="n">val_sentences_B</span><span class="p">)</span>
<span class="n">X_crf_test_B</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag_sents</span><span class="p">(</span><span class="n">test_sentences_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="D&#233;fintion-du-model">D&#233;fintion du model<a class="anchor-link" href="#D&#233;fintion-du-model">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">CRF_train_sentences_B</span> <span class="o">=</span> <span class="n">transform_to_dataset</span><span class="p">(</span><span class="n">X_crf_train_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="training">training<a class="anchor-link" href="#training">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
<span class="n">model_CRF_tacheB_</span> <span class="o">=</span> <span class="n">CRF</span><span class="p">(</span>
    <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span>
    <span class="n">c1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">c2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">max_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">all_possible_transitions</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>


<span class="n">model_CRF_tacheB_</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">CRF_train_sentences_B</span><span class="p">,</span> <span class="n">train_tags_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.
  FutureWarning)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>CRF(algorithm=&#39;lbfgs&#39;, all_possible_transitions=True, c1=0.1, c2=0.1,
    keep_tempfiles=None, max_iterations=100)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_CRF_tacheB_</span><span class="o">.</span><span class="n">classes_</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>[&#39;O&#39;,
 &#39;B_P&#39;,
 &#39;L_P&#39;,
 &#39;U_T&#39;,
 &#39;I_P&#39;,
 &#39;B_M&#39;,
 &#39;I_M&#39;,
 &#39;L_M&#39;,
 &#39;U_M&#39;,
 &#39;U_P&#39;,
 &#39;B_T&#39;,
 &#39;L_T&#39;,
 &#39;I_T&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_CRF_tacheB</span> <span class="o">=</span><span class="n">model_CRF_tacheB_</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Gridsearch-sur-C1-et-C2-qui-sont-les-&quot;regularizers&quot;-L1-et-L2">Gridsearch sur C1 et C2 qui sont les "regularizers" L1 et L2<a class="anchor-link" href="#Gridsearch-sur-C1-et-C2-qui-sont-les-&quot;regularizers&quot;-L1-et-L2">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">model_CRF_tacheB = CRF(</span>
<span class="sd">    algorithm=&#39;lbfgs&#39;,</span>
<span class="sd">    max_iterations=100,</span>
<span class="sd">    all_possible_transitions=True</span>
<span class="sd">    )</span>

<span class="sd">params_space = {</span>
<span class="sd">    &#39;c1&#39;: scipy.stats.expon(scale=0.5),</span>
<span class="sd">    &#39;c2&#39;: scipy.stats.expon(scale=0.05),</span>
<span class="sd">}</span>

<span class="sd"># metric of evaluation</span>
<span class="sd">labels = list(model_CRF_tacheB_.classes_)</span>
<span class="sd">labels.remove(&#39;O&#39;)</span>
<span class="sd">f1_scorer = make_scorer(metrics.flat_f1_score,</span>
<span class="sd">                        average=&#39;weighted&#39;, labels=labels)</span>

<span class="sd"># search</span>
<span class="sd">rs_B = RandomizedSearchCV(model_CRF_tacheB, params_space,</span>
<span class="sd">                        cv=3,</span>
<span class="sd">                        verbose=1,</span>
<span class="sd">                        n_jobs=-1,</span>
<span class="sd">                        n_iter=50,</span>
<span class="sd">                        scoring=f1_scorer)</span>
<span class="sd">rs_B.fit(CRF_train_sentences_B, train_tags_B)</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;\nmodel_CRF_tacheB = CRF(\n    algorithm=&#39;lbfgs&#39;,\n    max_iterations=100,\n    all_possible_transitions=True\n    )\n\nparams_space = {\n    &#39;c1&#39;: scipy.stats.expon(scale=0.5),\n    &#39;c2&#39;: scipy.stats.expon(scale=0.05),\n}\n\n# metric of evaluation\nlabels = list(model_CRF_tacheB_.classes_)\nlabels.remove(&#39;O&#39;)\nf1_scorer = make_scorer(metrics.flat_f1_score,\n                        average=&#39;weighted&#39;, labels=labels)\n\n# search\nrs_B = RandomizedSearchCV(model_CRF_tacheB, params_space,\n                        cv=3,\n                        verbose=1,\n                        n_jobs=-1,\n                        n_iter=50,\n                        scoring=f1_scorer)\nrs_B.fit(CRF_train_sentences_B, train_tags_B)\n&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">print(&#39;best params:&#39;, rs_B.best_params_)</span>
<span class="sd">print(&#39;best CV score:&#39;, rs_B.best_score_)</span>
<span class="sd">print(&#39;model size: {:0.2f}M&#39;.format(rs_B.best_estimator_.size_ / 1000000))</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;\nprint(&#39;best params:&#39;, rs_B.best_params_)\nprint(&#39;best CV score:&#39;, rs_B.best_score_)\nprint(&#39;model size: {:0.2f}M&#39;.format(rs_B.best_estimator_.size_ / 1000000))\n&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#model_CRF_tacheB = rs_B.best_estimator_</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="prediction">prediction<a class="anchor-link" href="#prediction">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">CRF_train_sentences_B</span><span class="p">,</span> <span class="n">y_train_pred_B</span> <span class="o">=</span> <span class="n">tag_prediction</span><span class="p">(</span><span class="n">X_crf_train_B</span><span class="p">,</span><span class="n">model_CRF_tacheB</span><span class="p">)</span>
<span class="n">CRF_val_sentences_B</span><span class="p">,</span> <span class="n">y_val_pred_B</span> <span class="o">=</span> <span class="n">tag_prediction</span><span class="p">(</span><span class="n">X_crf_val_B</span><span class="p">,</span><span class="n">model_CRF_tacheB</span><span class="p">)</span>
<span class="n">CRF_test_sentences_B</span><span class="p">,</span> <span class="n">y_test_pred_B</span> <span class="o">=</span> <span class="n">tag_prediction</span><span class="p">(</span><span class="n">X_crf_test_B</span><span class="p">,</span><span class="n">model_CRF_tacheB</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Evaluation-sur-le-validation-set">Evaluation sur le validation set<a class="anchor-link" href="#Evaluation-sur-le-validation-set">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>val set</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[95]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">flat_accuracy_score</span><span class="p">(</span><span class="n">val_tags_B</span><span class="p">,</span> <span class="n">y_val_pred_B</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.7441089508108593
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">CRF_show_confusion</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">val_tags_B</span><span class="p">)),</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_val_pred_B</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>f1 micro:0.744
f1 micro:0.332
recall macro:0.307
Confusion Matrix:
[[  76   17    7   12   16   13    0    1    0   88    6    1    0]
 [  12  107   18    3   24   14    0    0    0  150    1    2    0]
 [   4   22   22    0    3    5    0    0    0   70    0    0    0]
 [  12    3    0   48   29   12    3    3    0   62    1    1    0]
 [   9   18    0   18  101   30    3   15    2  245    7    1    0]
 [   7   17    7    8   54   93    1    4    5  250    3    0    0]
 [   0    0    0    6    4    5   91   29   15   84    3    0    0]
 [   0    0    0    2   13    8   19  121   22  141    4    1    0]
 [   0    0    0    0    4    3   10   34   26   47    2    0    0]
 [  45   87   55   54  207  193   36   71   40 7533    4   15    0]
 [  10   12    4    2    8   11   12    7    3  132   51   12    0]
 [   1    4    1    1    3    4    0    1    1   33    3   36    0]
 [   0    0    0    0    0    0    1    0    0    8    0    0    0]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">model_CRF_tacheB</span><span class="o">.</span><span class="n">classes_</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">flat_classification_report</span><span class="p">(</span>
    <span class="n">y_val_pred_B</span><span class="p">,</span> <span class="n">val_tags_B</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">digits</span><span class="o">=</span><span class="mi">3</span>
<span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           O      0.903     0.852     0.877      8843
         B_P      0.323     0.373     0.346       287
         L_P      0.366     0.423     0.392       286
         U_T      0.000     0.000     0.000         0
         I_P      0.225     0.217     0.221       466
         B_M      0.321     0.432     0.368       176
         I_M      0.276     0.312     0.293       154
         L_M      0.384     0.517     0.441       176
         U_M      0.193     0.600     0.292        85
         U_P      0.409     0.522     0.459        69
         B_T      0.175     0.193     0.183       114
         L_T      0.206     0.228     0.217       114
         I_T      0.207     0.238     0.221       391

    accuracy                          0.744     11161
   macro avg      0.307     0.377     0.332     11161
weighted avg      0.773     0.744     0.757     11161

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[&#39;O&#39;, &#39;B_P&#39;, &#39;L_P&#39;, &#39;U_T&#39;, &#39;I_P&#39;, &#39;B_M&#39;, &#39;I_M&#39;, &#39;L_M&#39;, &#39;U_M&#39;, &#39;U_P&#39;, &#39;B_T&#39;, &#39;L_T&#39;, &#39;I_T&#39;] as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>REMARQUE</em></strong></p>
<p>ENcore une fois le label 'O' est le mieux prdit. Par rapport  la tache A c'est encore plus flagrant. En effet, notre modle CRF ne prend pas en compte le dsquilibre du jeu de donnes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Fichiers-de-soumissions-for-CRF">Fichiers de soumissions for CRF<a class="anchor-link" href="#Fichiers-de-soumissions-for-CRF">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_val_csv</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_val_pred</span><span class="p">))</span>

<span class="n">CRF_val_df_soumission</span><span class="o">=</span><span class="n">val_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DocID&#39;</span><span class="p">,</span> <span class="s1">&#39;Token&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">CRF_val_df_soumission</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">y_val_csv</span>
<span class="n">CRF_val_df_soumission</span>

<span class="n">CRF_val_df_soumission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;CRF_submission_val_B.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_test_csv</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">y_test_pred</span><span class="p">))</span>

<span class="n">CRF_test_df_soumission</span><span class="o">=</span><span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DocID&#39;</span><span class="p">,</span> <span class="s1">&#39;Token&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">CRF_test_df_soumission</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">y_test_csv</span>
<span class="n">CRF_test_df_soumission</span>

<span class="n">CRF_test_df_soumission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;CRF_submission_test_B.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">CRF_test_df_soumission</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[99]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TokenID</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0885230816301759-0</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0885230816301759-1</td>
      <td>B</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0885230816301759-2</td>
      <td>I</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0885230816301759-3</td>
      <td>I</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0885230816301759-4</td>
      <td>I</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Bilstm-CRF-avec-glove-embedding">Bilstm-CRF avec glove embedding<a class="anchor-link" href="#Bilstm-CRF-avec-glove-embedding">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># few parameters</span>
<span class="n">MAX_LEN</span> <span class="o">=</span> <span class="n">MAX_LENGTH_B</span>  <span class="c1"># Max length of words</span>
<span class="n">WORD_EMBEDDING_OUT_DIM</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">tags_B</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;-PAD-&#39;</span><span class="p">,</span> <span class="s1">&#39;O&#39;</span><span class="p">,</span> <span class="s1">&#39;U_M&#39;</span><span class="p">,</span> <span class="s1">&#39;I_M&#39;</span><span class="p">,</span> <span class="s1">&#39;B_M&#39;</span><span class="p">,</span> <span class="s1">&#39;L_M&#39;</span><span class="p">,</span> <span class="s1">&#39;U_P&#39;</span><span class="p">,</span> <span class="s1">&#39;I_P&#39;</span><span class="p">,</span> <span class="s1">&#39;B_P&#39;</span><span class="p">,</span> <span class="s1">&#39;L_P&#39;</span><span class="p">,</span> <span class="s1">&#39;U_T&#39;</span><span class="p">,</span> <span class="s1">&#39;I_T&#39;</span><span class="p">,</span> <span class="s1">&#39;B_T&#39;</span><span class="p">,</span> <span class="s1">&#39;L_T&#39;</span><span class="p">]</span>
<span class="n">n_tags</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tags_B</span><span class="p">)</span>
<span class="n">words_voc</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">train_B_df</span><span class="p">[</span><span class="s2">&quot;Token&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
<span class="n">n_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">words_voc</span><span class="p">)</span> <span class="o">+</span><span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words_voc</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">max_word_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">words_voc</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">key</span><span class="o">=</span><span class="nb">len</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>7
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Importation-de-Glove">Importation de Glove<a class="anchor-link" href="#Importation-de-Glove">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">words_not_found</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_words</span><span class="p">,</span> <span class="n">WORD_EMBEDDING_OUT_DIM</span><span class="p">))</span>

<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word2indexB</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">n_words</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">embeddings_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">embedding_vector</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># words not found in embedding index will be all-zeros.</span>
        <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">words_not_found</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;number of null word embeddings: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>number of null word embeddings: 1302
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="D&#233;finition-du-mod&#233;le-Bilstm+Crf">D&#233;finition du mod&#233;le Bilstm+Crf<a class="anchor-link" href="#D&#233;finition-du-mod&#233;le-Bilstm+Crf">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On utilise la librairie tf2crf de pypi, qui est est un module permettant d'implmenter un layer crf sur tensorflow 2. Ici on utilise la fonction ModelWithCRFLossDSCLoss qui permet d'uitiliser la fonction de cout DSC (Dice similarity coefficient) qui est trs pratique dans le cadre des donnes qui sont dsquilibrs. On utilise galement de l'early stopping et un checkpoint conservant le meilleur modle en terme d'accuracy sur le validation set. Finalement, un embedding glove est utilis pour augementer nos performances. On compare galement le GRU et le LSTM comme layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_model_Bilstm_crf_B</span><span class="p">(</span> <span class="n">optimizer</span><span class="p">,</span><span class="n">embedding_name</span><span class="p">,</span><span class="n">layer</span><span class="p">,</span><span class="n">dropout</span><span class="p">,</span> <span class="n">unit</span><span class="p">):</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="p">))</span>
  <span class="k">if</span> <span class="n">embedding_name</span> <span class="o">==</span> <span class="s1">&#39;Glove&#39;</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">n_words</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">WORD_EMBEDDING_OUT_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">])(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">n_words</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">WORD_EMBEDDING_OUT_DIM</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="s1">&#39;GRU&#39;</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">unit</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">unit</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">crf</span> <span class="o">=</span> <span class="n">CRF</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">n_tags</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">crf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">base_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
  <span class="n">model_crf</span> <span class="o">=</span> <span class="n">ModelWithCRFLossDSCLoss</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span><span class="n">sparse_target</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">model_crf</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">model_crf</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Benchmark/Grid-search">Benchmark/Grid search<a class="anchor-link" href="#Benchmark/Grid-search">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;adam&#39;</span><span class="p">]</span> <span class="c1">#[&#39;adam&#39;,&#39;rmsprop&#39;,&#39;SGD&#39;]#[&#39;rmsprop&#39;,&#39;adam&#39;,&#39;SGD&#39;,&#39;adadelta&#39;]#[&#39;Adam()&#39;, &#39;SGD()&#39;, &#39;RMSprop()&#39;,&#39;Adagrad()&#39;,&#39;Adadelta()&#39;]</span>
<span class="n">all_dropouts</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">]</span>
<span class="n">units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">64</span><span class="p">]</span> <span class="c1">#[10, 64, 150, 250]</span>
<span class="n">embeddin_meth</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Glove&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="c1">#[&#39;Glove&#39;, None] </span>
<span class="n">models_bilstm_crf_param</span> <span class="o">=</span> <span class="p">[[</span><span class="n">optimizer</span><span class="p">,</span><span class="n">embedding_name</span><span class="p">,</span><span class="n">layer</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">unit</span><span class="p">]</span> <span class="k">for</span> <span class="n">unit</span> <span class="ow">in</span> <span class="n">units</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;GRU&#39;</span><span class="p">,</span> <span class="s1">&#39;LSTM&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">dropout</span> <span class="ow">in</span> <span class="n">all_dropouts</span> <span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span> <span class="k">for</span> <span class="n">embedding_name</span> <span class="ow">in</span>  <span class="n">embeddin_meth</span> <span class="p">]</span>
<span class="n">models_bilstm_crf</span><span class="o">=</span> <span class="p">[</span><span class="n">create_model_Bilstm_crf_B</span><span class="p">(</span> <span class="n">optimizer</span><span class="p">,</span><span class="n">embedding_name</span><span class="p">,</span><span class="n">layer</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">unit</span><span class="p">)</span> <span class="k">for</span> <span class="n">unit</span> <span class="ow">in</span> <span class="n">units</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;GRU&#39;</span><span class="p">,</span> <span class="s1">&#39;LSTM&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">dropout</span> <span class="ow">in</span> <span class="n">all_dropouts</span> <span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span> <span class="k">for</span> <span class="n">embedding_name</span> <span class="ow">in</span>  <span class="n">embeddin_meth</span> <span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">callback2</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss_val&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">histories_B_Bilstm_crf</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">model</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">models_bilstm_crf</span><span class="p">)):</span>
  <span class="n">checkpoint2</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;./models/Bilstm_crf/best_model_bilstm&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;.hdf5&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_val_accuracy&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">histories_B_Bilstm_crf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_sentences_X_B</span><span class="p">,</span> <span class="n">train_tags_y_B</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_sentences_X_B</span><span class="p">,</span><span class="n">val_tags_y_B</span><span class="p">),</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint2</span><span class="p">,</span><span class="n">callback2</span><span class="p">],</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="c1">#model_tuning = create_model_B_glove(all_weights_B[0], optimizer=&#39;adam&#39;,embedding_name=&#39;Glove&#39;)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>0it [00:00, ?it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 807.0024 - accuracy: 0.5411
Epoch 00001: val_val_accuracy improved from -inf to 0.83979, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 20s 2s/step - loss: 807.0024 - accuracy: 0.5411 - val_loss_val: 680.4657 - val_val_accuracy: 0.8398
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 587.5208 - accuracy: 0.8569
Epoch 00002: val_val_accuracy improved from 0.83979 to 0.85170, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 19s 2s/step - loss: 587.5208 - accuracy: 0.8569 - val_loss_val: 469.6287 - val_val_accuracy: 0.8517
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 381.4702 - accuracy: 0.8624
Epoch 00003: val_val_accuracy improved from 0.85170 to 0.85443, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 19s 2s/step - loss: 381.4702 - accuracy: 0.8624 - val_loss_val: 326.3964 - val_val_accuracy: 0.8544
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 271.4140 - accuracy: 0.8646
Epoch 00004: val_val_accuracy improved from 0.85443 to 0.85459, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 19s 2s/step - loss: 271.4140 - accuracy: 0.8646 - val_loss_val: 269.8978 - val_val_accuracy: 0.8546
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 231.8076 - accuracy: 0.8648
Epoch 00005: val_val_accuracy did not improve from 0.85459
11/11 [==============================] - 18s 2s/step - loss: 231.8076 - accuracy: 0.8648 - val_loss_val: 247.4249 - val_val_accuracy: 0.8545
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 214.0408 - accuracy: 0.8650
Epoch 00006: val_val_accuracy did not improve from 0.85459
11/11 [==============================] - 18s 2s/step - loss: 214.0408 - accuracy: 0.8650 - val_loss_val: 234.9150 - val_val_accuracy: 0.8545
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 203.0500 - accuracy: 0.8655
Epoch 00007: val_val_accuracy improved from 0.85459 to 0.85474, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 203.0500 - accuracy: 0.8655 - val_loss_val: 226.6723 - val_val_accuracy: 0.8547
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 194.8345 - accuracy: 0.8664
Epoch 00008: val_val_accuracy improved from 0.85474 to 0.85515, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 194.8345 - accuracy: 0.8664 - val_loss_val: 220.2858 - val_val_accuracy: 0.8552
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 187.9812 - accuracy: 0.8672
Epoch 00009: val_val_accuracy improved from 0.85515 to 0.85536, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 187.9812 - accuracy: 0.8672 - val_loss_val: 214.9545 - val_val_accuracy: 0.8554
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 181.6240 - accuracy: 0.8689
Epoch 00010: val_val_accuracy did not improve from 0.85536
11/11 [==============================] - 18s 2s/step - loss: 181.6240 - accuracy: 0.8689 - val_loss_val: 209.4672 - val_val_accuracy: 0.8552
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 176.1293 - accuracy: 0.8701
Epoch 00011: val_val_accuracy did not improve from 0.85536
11/11 [==============================] - 18s 2s/step - loss: 176.1293 - accuracy: 0.8701 - val_loss_val: 206.0206 - val_val_accuracy: 0.8549
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 170.9489 - accuracy: 0.8720
Epoch 00012: val_val_accuracy improved from 0.85536 to 0.85634, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 170.9489 - accuracy: 0.8720 - val_loss_val: 201.8775 - val_val_accuracy: 0.8563
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 165.8206 - accuracy: 0.8736
Epoch 00013: val_val_accuracy did not improve from 0.85634
11/11 [==============================] - 18s 2s/step - loss: 165.8206 - accuracy: 0.8736 - val_loss_val: 198.5037 - val_val_accuracy: 0.8558
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 161.2365 - accuracy: 0.8754
Epoch 00014: val_val_accuracy improved from 0.85634 to 0.85722, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 161.2365 - accuracy: 0.8754 - val_loss_val: 195.3550 - val_val_accuracy: 0.8572
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 156.6047 - accuracy: 0.8768
Epoch 00015: val_val_accuracy improved from 0.85722 to 0.85753, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 156.6047 - accuracy: 0.8768 - val_loss_val: 193.5338 - val_val_accuracy: 0.8575
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 152.0824 - accuracy: 0.8796
Epoch 00016: val_val_accuracy did not improve from 0.85753
11/11 [==============================] - 18s 2s/step - loss: 152.0824 - accuracy: 0.8796 - val_loss_val: 190.8756 - val_val_accuracy: 0.8568
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 147.9516 - accuracy: 0.8821
Epoch 00017: val_val_accuracy did not improve from 0.85753
11/11 [==============================] - 18s 2s/step - loss: 147.9516 - accuracy: 0.8821 - val_loss_val: 188.4414 - val_val_accuracy: 0.8572
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 143.9324 - accuracy: 0.8841
Epoch 00018: val_val_accuracy improved from 0.85753 to 0.85938, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 19s 2s/step - loss: 143.9324 - accuracy: 0.8841 - val_loss_val: 185.4940 - val_val_accuracy: 0.8594
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 140.0131 - accuracy: 0.8876
Epoch 00019: val_val_accuracy did not improve from 0.85938
11/11 [==============================] - 18s 2s/step - loss: 140.0131 - accuracy: 0.8876 - val_loss_val: 183.6222 - val_val_accuracy: 0.8585
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 136.3965 - accuracy: 0.8897
Epoch 00020: val_val_accuracy did not improve from 0.85938
11/11 [==============================] - 18s 2s/step - loss: 136.3965 - accuracy: 0.8897 - val_loss_val: 182.1151 - val_val_accuracy: 0.8591
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 132.1985 - accuracy: 0.8933
Epoch 00021: val_val_accuracy did not improve from 0.85938
11/11 [==============================] - 18s 2s/step - loss: 132.1985 - accuracy: 0.8933 - val_loss_val: 180.2946 - val_val_accuracy: 0.8587
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 128.6931 - accuracy: 0.8959
Epoch 00022: val_val_accuracy improved from 0.85938 to 0.86000, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 19s 2s/step - loss: 128.6931 - accuracy: 0.8959 - val_loss_val: 179.0367 - val_val_accuracy: 0.8600
Epoch 23/50
11/11 [==============================] - ETA: 0s - loss: 124.9890 - accuracy: 0.8990
Epoch 00023: val_val_accuracy improved from 0.86000 to 0.86082, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 124.9890 - accuracy: 0.8990 - val_loss_val: 178.0174 - val_val_accuracy: 0.8608
Epoch 24/50
11/11 [==============================] - ETA: 0s - loss: 121.7529 - accuracy: 0.9025
Epoch 00024: val_val_accuracy did not improve from 0.86082
11/11 [==============================] - 18s 2s/step - loss: 121.7529 - accuracy: 0.9025 - val_loss_val: 177.0018 - val_val_accuracy: 0.8587
Epoch 25/50
11/11 [==============================] - ETA: 0s - loss: 118.6632 - accuracy: 0.9039
Epoch 00025: val_val_accuracy improved from 0.86082 to 0.86098, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 18s 2s/step - loss: 118.6632 - accuracy: 0.9039 - val_loss_val: 175.3280 - val_val_accuracy: 0.8610
Epoch 26/50
11/11 [==============================] - ETA: 0s - loss: 115.2608 - accuracy: 0.9075
Epoch 00026: val_val_accuracy did not improve from 0.86098
11/11 [==============================] - 18s 2s/step - loss: 115.2608 - accuracy: 0.9075 - val_loss_val: 173.6423 - val_val_accuracy: 0.8601
Epoch 27/50
11/11 [==============================] - ETA: 0s - loss: 111.9921 - accuracy: 0.9100
Epoch 00027: val_val_accuracy did not improve from 0.86098
11/11 [==============================] - 18s 2s/step - loss: 111.9921 - accuracy: 0.9100 - val_loss_val: 172.5751 - val_val_accuracy: 0.8605
Epoch 28/50
11/11 [==============================] - ETA: 0s - loss: 109.0982 - accuracy: 0.9128
Epoch 00028: val_val_accuracy did not improve from 0.86098
11/11 [==============================] - 18s 2s/step - loss: 109.0982 - accuracy: 0.9128 - val_loss_val: 171.7777 - val_val_accuracy: 0.8601
Epoch 29/50
11/11 [==============================] - ETA: 0s - loss: 106.2899 - accuracy: 0.9150
Epoch 00029: val_val_accuracy improved from 0.86098 to 0.86103, saving model to ./models/Bilstm_crf/best_model_bilstm0.hdf5
11/11 [==============================] - 19s 2s/step - loss: 106.2899 - accuracy: 0.9150 - val_loss_val: 169.7029 - val_val_accuracy: 0.8610
Epoch 30/50
11/11 [==============================] - ETA: 0s - loss: 103.2630 - accuracy: 0.9178
Epoch 00030: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 103.2630 - accuracy: 0.9178 - val_loss_val: 170.3106 - val_val_accuracy: 0.8605
Epoch 31/50
11/11 [==============================] - ETA: 0s - loss: 100.5167 - accuracy: 0.9192
Epoch 00031: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 100.5167 - accuracy: 0.9192 - val_loss_val: 169.3535 - val_val_accuracy: 0.8604
Epoch 32/50
11/11 [==============================] - ETA: 0s - loss: 97.8038 - accuracy: 0.9217
Epoch 00032: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 97.8038 - accuracy: 0.9217 - val_loss_val: 169.1068 - val_val_accuracy: 0.8574
Epoch 33/50
11/11 [==============================] - ETA: 0s - loss: 95.1800 - accuracy: 0.9234
Epoch 00033: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 95.1800 - accuracy: 0.9234 - val_loss_val: 167.7753 - val_val_accuracy: 0.8601
Epoch 34/50
11/11 [==============================] - ETA: 0s - loss: 92.6479 - accuracy: 0.9264
Epoch 00034: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 92.6479 - accuracy: 0.9264 - val_loss_val: 168.0924 - val_val_accuracy: 0.8596
Epoch 35/50
11/11 [==============================] - ETA: 0s - loss: 90.2592 - accuracy: 0.9273
Epoch 00035: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 90.2592 - accuracy: 0.9273 - val_loss_val: 167.4370 - val_val_accuracy: 0.8589
Epoch 36/50
11/11 [==============================] - ETA: 0s - loss: 87.7203 - accuracy: 0.9304
Epoch 00036: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 87.7203 - accuracy: 0.9304 - val_loss_val: 167.9478 - val_val_accuracy: 0.8578
Epoch 37/50
11/11 [==============================] - ETA: 0s - loss: 85.5144 - accuracy: 0.9315
Epoch 00037: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 85.5144 - accuracy: 0.9315 - val_loss_val: 167.0571 - val_val_accuracy: 0.8586
Epoch 38/50
11/11 [==============================] - ETA: 0s - loss: 83.4391 - accuracy: 0.9335
Epoch 00038: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 83.4391 - accuracy: 0.9335 - val_loss_val: 167.6400 - val_val_accuracy: 0.8592
Epoch 39/50
11/11 [==============================] - ETA: 0s - loss: 81.1359 - accuracy: 0.9352
Epoch 00039: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 81.1359 - accuracy: 0.9352 - val_loss_val: 164.4895 - val_val_accuracy: 0.8604
Epoch 40/50
11/11 [==============================] - ETA: 0s - loss: 79.3323 - accuracy: 0.9368
Epoch 00040: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 79.3323 - accuracy: 0.9368 - val_loss_val: 166.2983 - val_val_accuracy: 0.8581
Epoch 41/50
11/11 [==============================] - ETA: 0s - loss: 77.3066 - accuracy: 0.9391
Epoch 00041: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 77.3066 - accuracy: 0.9391 - val_loss_val: 164.2630 - val_val_accuracy: 0.8587
Epoch 42/50
11/11 [==============================] - ETA: 0s - loss: 75.0338 - accuracy: 0.9406
Epoch 00042: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 75.0338 - accuracy: 0.9406 - val_loss_val: 164.6913 - val_val_accuracy: 0.8605
Epoch 43/50
11/11 [==============================] - ETA: 0s - loss: 73.3967 - accuracy: 0.9418
Epoch 00043: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 73.3967 - accuracy: 0.9418 - val_loss_val: 165.5882 - val_val_accuracy: 0.8545
Epoch 44/50
11/11 [==============================] - ETA: 0s - loss: 71.7665 - accuracy: 0.9434
Epoch 00044: val_val_accuracy did not improve from 0.86103
11/11 [==============================] - 18s 2s/step - loss: 71.7665 - accuracy: 0.9434 - val_loss_val: 164.9940 - val_val_accuracy: 0.8585
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>1it [13:23, 803.74s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 871.5256 - accuracy: 0.3423
Epoch 00001: val_val_accuracy improved from -inf to 0.43830, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 30s 2s/step - loss: 871.5256 - accuracy: 0.3423 - val_loss_val: 789.3542 - val_val_accuracy: 0.4383
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 660.3671 - accuracy: 0.7099
Epoch 00002: val_val_accuracy improved from 0.43830 to 0.84510, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 660.3671 - accuracy: 0.7099 - val_loss_val: 592.8926 - val_val_accuracy: 0.8451
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 458.4522 - accuracy: 0.8601
Epoch 00003: val_val_accuracy improved from 0.84510 to 0.85052, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 458.4522 - accuracy: 0.8601 - val_loss_val: 430.0552 - val_val_accuracy: 0.8505
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 324.2320 - accuracy: 0.8622
Epoch 00004: val_val_accuracy improved from 0.85052 to 0.85371, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 324.2320 - accuracy: 0.8622 - val_loss_val: 314.1929 - val_val_accuracy: 0.8537
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 249.9963 - accuracy: 0.8647
Epoch 00005: val_val_accuracy improved from 0.85371 to 0.85448, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 249.9963 - accuracy: 0.8647 - val_loss_val: 260.6068 - val_val_accuracy: 0.8545
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 224.1168 - accuracy: 0.8647
Epoch 00006: val_val_accuracy did not improve from 0.85448
11/11 [==============================] - 18s 2s/step - loss: 224.1168 - accuracy: 0.8647 - val_loss_val: 243.7290 - val_val_accuracy: 0.8544
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 209.6086 - accuracy: 0.8647
Epoch 00007: val_val_accuracy did not improve from 0.85448
11/11 [==============================] - 18s 2s/step - loss: 209.6086 - accuracy: 0.8647 - val_loss_val: 233.7501 - val_val_accuracy: 0.8544
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 197.6908 - accuracy: 0.8649
Epoch 00008: val_val_accuracy did not improve from 0.85448
11/11 [==============================] - 18s 2s/step - loss: 197.6908 - accuracy: 0.8649 - val_loss_val: 227.7679 - val_val_accuracy: 0.8545
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 188.9259 - accuracy: 0.8657
Epoch 00009: val_val_accuracy improved from 0.85448 to 0.85479, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 188.9259 - accuracy: 0.8657 - val_loss_val: 222.6234 - val_val_accuracy: 0.8548
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 181.3447 - accuracy: 0.8673
Epoch 00010: val_val_accuracy improved from 0.85479 to 0.85495, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 181.3447 - accuracy: 0.8673 - val_loss_val: 217.6735 - val_val_accuracy: 0.8549
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 174.6202 - accuracy: 0.8696
Epoch 00011: val_val_accuracy improved from 0.85495 to 0.85536, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 174.6202 - accuracy: 0.8696 - val_loss_val: 213.6043 - val_val_accuracy: 0.8554
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 168.3243 - accuracy: 0.8731
Epoch 00012: val_val_accuracy improved from 0.85536 to 0.85567, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 168.3243 - accuracy: 0.8731 - val_loss_val: 210.2421 - val_val_accuracy: 0.8557
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 162.4570 - accuracy: 0.8775
Epoch 00013: val_val_accuracy did not improve from 0.85567
11/11 [==============================] - 18s 2s/step - loss: 162.4570 - accuracy: 0.8775 - val_loss_val: 207.6731 - val_val_accuracy: 0.8549
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 156.8461 - accuracy: 0.8813
Epoch 00014: val_val_accuracy did not improve from 0.85567
11/11 [==============================] - 18s 2s/step - loss: 156.8461 - accuracy: 0.8813 - val_loss_val: 205.1167 - val_val_accuracy: 0.8546
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 151.3116 - accuracy: 0.8837
Epoch 00015: val_val_accuracy did not improve from 0.85567
11/11 [==============================] - 18s 2s/step - loss: 151.3116 - accuracy: 0.8837 - val_loss_val: 202.6045 - val_val_accuracy: 0.8540
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 145.8942 - accuracy: 0.8864
Epoch 00016: val_val_accuracy did not improve from 0.85567
11/11 [==============================] - 18s 2s/step - loss: 145.8942 - accuracy: 0.8864 - val_loss_val: 200.5817 - val_val_accuracy: 0.8543
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 140.4946 - accuracy: 0.8901
Epoch 00017: val_val_accuracy did not improve from 0.85567
11/11 [==============================] - 18s 2s/step - loss: 140.4946 - accuracy: 0.8901 - val_loss_val: 198.7187 - val_val_accuracy: 0.8544
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 135.2005 - accuracy: 0.8944
Epoch 00018: val_val_accuracy did not improve from 0.85567
11/11 [==============================] - 18s 2s/step - loss: 135.2005 - accuracy: 0.8944 - val_loss_val: 196.6920 - val_val_accuracy: 0.8549
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 129.9295 - accuracy: 0.8992
Epoch 00019: val_val_accuracy improved from 0.85567 to 0.85577, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 129.9295 - accuracy: 0.8992 - val_loss_val: 195.2861 - val_val_accuracy: 0.8558
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 124.6647 - accuracy: 0.9048
Epoch 00020: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 124.6647 - accuracy: 0.9048 - val_loss_val: 194.1591 - val_val_accuracy: 0.8551
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 119.7257 - accuracy: 0.9099
Epoch 00021: val_val_accuracy improved from 0.85577 to 0.85634, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 119.7257 - accuracy: 0.9099 - val_loss_val: 192.6086 - val_val_accuracy: 0.8563
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 114.8866 - accuracy: 0.9142
Epoch 00022: val_val_accuracy did not improve from 0.85634
11/11 [==============================] - 18s 2s/step - loss: 114.8866 - accuracy: 0.9142 - val_loss_val: 192.1039 - val_val_accuracy: 0.8563
Epoch 23/50
11/11 [==============================] - ETA: 0s - loss: 110.2162 - accuracy: 0.9183
Epoch 00023: val_val_accuracy improved from 0.85634 to 0.85660, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 110.2162 - accuracy: 0.9183 - val_loss_val: 191.4704 - val_val_accuracy: 0.8566
Epoch 24/50
11/11 [==============================] - ETA: 0s - loss: 105.9025 - accuracy: 0.9223
Epoch 00024: val_val_accuracy improved from 0.85660 to 0.85665, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 105.9025 - accuracy: 0.9223 - val_loss_val: 190.7731 - val_val_accuracy: 0.8566
Epoch 25/50
11/11 [==============================] - ETA: 0s - loss: 101.5757 - accuracy: 0.9265
Epoch 00025: val_val_accuracy improved from 0.85665 to 0.85861, saving model to ./models/Bilstm_crf/best_model_bilstm1.hdf5
11/11 [==============================] - 18s 2s/step - loss: 101.5757 - accuracy: 0.9265 - val_loss_val: 190.6421 - val_val_accuracy: 0.8586
Epoch 26/50
11/11 [==============================] - ETA: 0s - loss: 97.3890 - accuracy: 0.9298
Epoch 00026: val_val_accuracy did not improve from 0.85861
11/11 [==============================] - 18s 2s/step - loss: 97.3890 - accuracy: 0.9298 - val_loss_val: 190.2722 - val_val_accuracy: 0.8574
Epoch 27/50
11/11 [==============================] - ETA: 0s - loss: 93.6885 - accuracy: 0.9334
Epoch 00027: val_val_accuracy did not improve from 0.85861
11/11 [==============================] - 18s 2s/step - loss: 93.6885 - accuracy: 0.9334 - val_loss_val: 189.9235 - val_val_accuracy: 0.8563
Epoch 28/50
11/11 [==============================] - ETA: 0s - loss: 89.8938 - accuracy: 0.9357
Epoch 00028: val_val_accuracy did not improve from 0.85861
11/11 [==============================] - 18s 2s/step - loss: 89.8938 - accuracy: 0.9357 - val_loss_val: 190.6770 - val_val_accuracy: 0.8561
Epoch 29/50
11/11 [==============================] - ETA: 0s - loss: 86.3524 - accuracy: 0.9390
Epoch 00029: val_val_accuracy did not improve from 0.85861
11/11 [==============================] - 18s 2s/step - loss: 86.3524 - accuracy: 0.9390 - val_loss_val: 190.2195 - val_val_accuracy: 0.8564
Epoch 30/50
11/11 [==============================] - ETA: 0s - loss: 83.1249 - accuracy: 0.9413
Epoch 00030: val_val_accuracy did not improve from 0.85861
11/11 [==============================] - 18s 2s/step - loss: 83.1249 - accuracy: 0.9413 - val_loss_val: 190.4482 - val_val_accuracy: 0.8572
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>2it [23:32, 688.83s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 1000.4501 - accuracy: 0.2004
Epoch 00001: val_val_accuracy improved from -inf to 0.49113, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 29s 2s/step - loss: 1000.4501 - accuracy: 0.2004 - val_loss_val: 859.6066 - val_val_accuracy: 0.4911
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 795.4606 - accuracy: 0.4976
Epoch 00002: val_val_accuracy improved from 0.49113 to 0.57567, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 795.4606 - accuracy: 0.4976 - val_loss_val: 658.5172 - val_val_accuracy: 0.5757
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 603.5964 - accuracy: 0.7917
Epoch 00003: val_val_accuracy improved from 0.57567 to 0.85103, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 603.5964 - accuracy: 0.7917 - val_loss_val: 484.3324 - val_val_accuracy: 0.8510
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 436.3708 - accuracy: 0.8612
Epoch 00004: val_val_accuracy did not improve from 0.85103
11/11 [==============================] - 18s 2s/step - loss: 436.3708 - accuracy: 0.8612 - val_loss_val: 366.4328 - val_val_accuracy: 0.8508
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 330.2451 - accuracy: 0.8596
Epoch 00005: val_val_accuracy did not improve from 0.85103
11/11 [==============================] - 18s 2s/step - loss: 330.2451 - accuracy: 0.8596 - val_loss_val: 305.0280 - val_val_accuracy: 0.8480
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 272.1318 - accuracy: 0.8576
Epoch 00006: val_val_accuracy did not improve from 0.85103
11/11 [==============================] - 18s 2s/step - loss: 272.1318 - accuracy: 0.8576 - val_loss_val: 270.3025 - val_val_accuracy: 0.8461
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 239.1347 - accuracy: 0.8576
Epoch 00007: val_val_accuracy did not improve from 0.85103
11/11 [==============================] - 18s 2s/step - loss: 239.1347 - accuracy: 0.8576 - val_loss_val: 250.2759 - val_val_accuracy: 0.8469
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 219.7594 - accuracy: 0.8585
Epoch 00008: val_val_accuracy did not improve from 0.85103
11/11 [==============================] - 18s 2s/step - loss: 219.7594 - accuracy: 0.8585 - val_loss_val: 236.8110 - val_val_accuracy: 0.8487
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 206.4988 - accuracy: 0.8600
Epoch 00009: val_val_accuracy did not improve from 0.85103
11/11 [==============================] - 18s 2s/step - loss: 206.4988 - accuracy: 0.8600 - val_loss_val: 226.8684 - val_val_accuracy: 0.8498
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 196.7215 - accuracy: 0.8619
Epoch 00010: val_val_accuracy improved from 0.85103 to 0.85222, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 19s 2s/step - loss: 196.7215 - accuracy: 0.8619 - val_loss_val: 219.1879 - val_val_accuracy: 0.8522
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 188.8311 - accuracy: 0.8637
Epoch 00011: val_val_accuracy improved from 0.85222 to 0.85325, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 19s 2s/step - loss: 188.8311 - accuracy: 0.8637 - val_loss_val: 213.4052 - val_val_accuracy: 0.8532
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 182.6172 - accuracy: 0.8644
Epoch 00012: val_val_accuracy improved from 0.85325 to 0.85412, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 182.6172 - accuracy: 0.8644 - val_loss_val: 208.5168 - val_val_accuracy: 0.8541
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 176.8681 - accuracy: 0.8647
Epoch 00013: val_val_accuracy improved from 0.85412 to 0.85433, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 176.8681 - accuracy: 0.8647 - val_loss_val: 204.8638 - val_val_accuracy: 0.8543
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 171.9780 - accuracy: 0.8648
Epoch 00014: val_val_accuracy improved from 0.85433 to 0.85443, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 171.9780 - accuracy: 0.8648 - val_loss_val: 201.2421 - val_val_accuracy: 0.8544
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 167.3855 - accuracy: 0.8649
Epoch 00015: val_val_accuracy did not improve from 0.85443
11/11 [==============================] - 18s 2s/step - loss: 167.3855 - accuracy: 0.8649 - val_loss_val: 198.2790 - val_val_accuracy: 0.8543
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 163.3582 - accuracy: 0.8650
Epoch 00016: val_val_accuracy improved from 0.85443 to 0.85459, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 163.3582 - accuracy: 0.8650 - val_loss_val: 195.6873 - val_val_accuracy: 0.8546
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 159.4690 - accuracy: 0.8653
Epoch 00017: val_val_accuracy improved from 0.85459 to 0.85495, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 19s 2s/step - loss: 159.4690 - accuracy: 0.8653 - val_loss_val: 193.1258 - val_val_accuracy: 0.8549
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 155.8446 - accuracy: 0.8659
Epoch 00018: val_val_accuracy improved from 0.85495 to 0.85500, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 155.8446 - accuracy: 0.8659 - val_loss_val: 191.4008 - val_val_accuracy: 0.8550
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 152.2604 - accuracy: 0.8665
Epoch 00019: val_val_accuracy improved from 0.85500 to 0.85536, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 19s 2s/step - loss: 152.2604 - accuracy: 0.8665 - val_loss_val: 189.7997 - val_val_accuracy: 0.8554
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 148.9368 - accuracy: 0.8680
Epoch 00020: val_val_accuracy improved from 0.85536 to 0.85582, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 148.9368 - accuracy: 0.8680 - val_loss_val: 187.8717 - val_val_accuracy: 0.8558
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 145.7547 - accuracy: 0.8692
Epoch 00021: val_val_accuracy improved from 0.85582 to 0.85649, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 145.7547 - accuracy: 0.8692 - val_loss_val: 186.6556 - val_val_accuracy: 0.8565
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 142.7641 - accuracy: 0.8710
Epoch 00022: val_val_accuracy improved from 0.85649 to 0.85716, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 142.7641 - accuracy: 0.8710 - val_loss_val: 184.5565 - val_val_accuracy: 0.8572
Epoch 23/50
11/11 [==============================] - ETA: 0s - loss: 139.4743 - accuracy: 0.8728
Epoch 00023: val_val_accuracy improved from 0.85716 to 0.85742, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 139.4743 - accuracy: 0.8728 - val_loss_val: 183.4504 - val_val_accuracy: 0.8574
Epoch 24/50
11/11 [==============================] - ETA: 0s - loss: 136.5791 - accuracy: 0.8750
Epoch 00024: val_val_accuracy improved from 0.85742 to 0.85758, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 136.5791 - accuracy: 0.8750 - val_loss_val: 181.6310 - val_val_accuracy: 0.8576
Epoch 25/50
11/11 [==============================] - ETA: 0s - loss: 133.7520 - accuracy: 0.8783
Epoch 00025: val_val_accuracy improved from 0.85758 to 0.85763, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 133.7520 - accuracy: 0.8783 - val_loss_val: 180.3508 - val_val_accuracy: 0.8576
Epoch 26/50
11/11 [==============================] - ETA: 0s - loss: 130.8305 - accuracy: 0.8810
Epoch 00026: val_val_accuracy improved from 0.85763 to 0.85948, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 19s 2s/step - loss: 130.8305 - accuracy: 0.8810 - val_loss_val: 179.9841 - val_val_accuracy: 0.8595
Epoch 27/50
11/11 [==============================] - ETA: 0s - loss: 127.7480 - accuracy: 0.8833
Epoch 00027: val_val_accuracy did not improve from 0.85948
11/11 [==============================] - 18s 2s/step - loss: 127.7480 - accuracy: 0.8833 - val_loss_val: 178.1965 - val_val_accuracy: 0.8588
Epoch 28/50
11/11 [==============================] - ETA: 0s - loss: 124.8237 - accuracy: 0.8866
Epoch 00028: val_val_accuracy improved from 0.85948 to 0.85959, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 18s 2s/step - loss: 124.8237 - accuracy: 0.8866 - val_loss_val: 177.6303 - val_val_accuracy: 0.8596
Epoch 29/50
11/11 [==============================] - ETA: 0s - loss: 122.1869 - accuracy: 0.8903
Epoch 00029: val_val_accuracy improved from 0.85959 to 0.86015, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 19s 2s/step - loss: 122.1869 - accuracy: 0.8903 - val_loss_val: 177.1898 - val_val_accuracy: 0.8602
Epoch 30/50
11/11 [==============================] - ETA: 0s - loss: 119.1689 - accuracy: 0.8920
Epoch 00030: val_val_accuracy did not improve from 0.86015
11/11 [==============================] - 18s 2s/step - loss: 119.1689 - accuracy: 0.8920 - val_loss_val: 175.5113 - val_val_accuracy: 0.8589
Epoch 31/50
11/11 [==============================] - ETA: 0s - loss: 116.6416 - accuracy: 0.8959
Epoch 00031: val_val_accuracy improved from 0.86015 to 0.86052, saving model to ./models/Bilstm_crf/best_model_bilstm2.hdf5
11/11 [==============================] - 19s 2s/step - loss: 116.6416 - accuracy: 0.8959 - val_loss_val: 174.5383 - val_val_accuracy: 0.8605
Epoch 32/50
11/11 [==============================] - ETA: 0s - loss: 114.2859 - accuracy: 0.8991
Epoch 00032: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 114.2859 - accuracy: 0.8991 - val_loss_val: 173.8984 - val_val_accuracy: 0.8596
Epoch 33/50
11/11 [==============================] - ETA: 0s - loss: 111.8299 - accuracy: 0.9021
Epoch 00033: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 111.8299 - accuracy: 0.9021 - val_loss_val: 173.7524 - val_val_accuracy: 0.8593
Epoch 34/50
11/11 [==============================] - ETA: 0s - loss: 108.8355 - accuracy: 0.9044
Epoch 00034: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 108.8355 - accuracy: 0.9044 - val_loss_val: 171.6891 - val_val_accuracy: 0.8595
Epoch 35/50
11/11 [==============================] - ETA: 0s - loss: 106.0489 - accuracy: 0.9069
Epoch 00035: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 106.0489 - accuracy: 0.9069 - val_loss_val: 172.9250 - val_val_accuracy: 0.8579
Epoch 36/50
11/11 [==============================] - ETA: 0s - loss: 103.8723 - accuracy: 0.9099
Epoch 00036: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 103.8723 - accuracy: 0.9099 - val_loss_val: 172.0298 - val_val_accuracy: 0.8602
Epoch 37/50
11/11 [==============================] - ETA: 0s - loss: 100.9214 - accuracy: 0.9127
Epoch 00037: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 100.9214 - accuracy: 0.9127 - val_loss_val: 171.2651 - val_val_accuracy: 0.8593
Epoch 38/50
11/11 [==============================] - ETA: 0s - loss: 99.0146 - accuracy: 0.9151
Epoch 00038: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 99.0146 - accuracy: 0.9151 - val_loss_val: 170.6615 - val_val_accuracy: 0.8598
Epoch 39/50
11/11 [==============================] - ETA: 0s - loss: 96.4071 - accuracy: 0.9164
Epoch 00039: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 96.4071 - accuracy: 0.9164 - val_loss_val: 170.9069 - val_val_accuracy: 0.8558
Epoch 40/50
11/11 [==============================] - ETA: 0s - loss: 94.1100 - accuracy: 0.9188
Epoch 00040: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 94.1100 - accuracy: 0.9188 - val_loss_val: 170.0628 - val_val_accuracy: 0.8584
Epoch 41/50
11/11 [==============================] - ETA: 0s - loss: 92.0098 - accuracy: 0.9216
Epoch 00041: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 92.0098 - accuracy: 0.9216 - val_loss_val: 171.0191 - val_val_accuracy: 0.8553
Epoch 42/50
11/11 [==============================] - ETA: 0s - loss: 89.9254 - accuracy: 0.9236
Epoch 00042: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 89.9254 - accuracy: 0.9236 - val_loss_val: 168.2649 - val_val_accuracy: 0.8580
Epoch 43/50
11/11 [==============================] - ETA: 0s - loss: 87.7833 - accuracy: 0.9252
Epoch 00043: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 87.7833 - accuracy: 0.9252 - val_loss_val: 168.2213 - val_val_accuracy: 0.8575
Epoch 44/50
11/11 [==============================] - ETA: 0s - loss: 85.5751 - accuracy: 0.9275
Epoch 00044: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 85.5751 - accuracy: 0.9275 - val_loss_val: 169.6542 - val_val_accuracy: 0.8578
Epoch 45/50
11/11 [==============================] - ETA: 0s - loss: 83.2842 - accuracy: 0.9292
Epoch 00045: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 83.2842 - accuracy: 0.9292 - val_loss_val: 168.3815 - val_val_accuracy: 0.8580
Epoch 46/50
11/11 [==============================] - ETA: 0s - loss: 81.4998 - accuracy: 0.9319
Epoch 00046: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 81.4998 - accuracy: 0.9319 - val_loss_val: 167.8617 - val_val_accuracy: 0.8593
Epoch 47/50
11/11 [==============================] - ETA: 0s - loss: 79.5027 - accuracy: 0.9330
Epoch 00047: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 79.5027 - accuracy: 0.9330 - val_loss_val: 166.0894 - val_val_accuracy: 0.8578
Epoch 48/50
11/11 [==============================] - ETA: 0s - loss: 77.5573 - accuracy: 0.9352
Epoch 00048: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 77.5573 - accuracy: 0.9352 - val_loss_val: 166.8419 - val_val_accuracy: 0.8580
Epoch 49/50
11/11 [==============================] - ETA: 0s - loss: 75.5265 - accuracy: 0.9377
Epoch 00049: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 75.5265 - accuracy: 0.9377 - val_loss_val: 167.4304 - val_val_accuracy: 0.8581
Epoch 50/50
11/11 [==============================] - ETA: 0s - loss: 73.5888 - accuracy: 0.9394
Epoch 00050: val_val_accuracy did not improve from 0.86052
11/11 [==============================] - 18s 2s/step - loss: 73.5888 - accuracy: 0.9394 - val_loss_val: 167.3110 - val_val_accuracy: 0.8581
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>3it [39:07, 801.60s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 1037.2866 - accuracy: 0.0334
Epoch 00001: val_val_accuracy improved from -inf to 0.33866, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 28s 2s/step - loss: 1037.2866 - accuracy: 0.0334 - val_loss_val: 953.7915 - val_val_accuracy: 0.3387
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 830.5369 - accuracy: 0.5674
Epoch 00002: val_val_accuracy improved from 0.33866 to 0.61902, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 830.5369 - accuracy: 0.5674 - val_loss_val: 746.5834 - val_val_accuracy: 0.6190
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 596.9462 - accuracy: 0.7110
Epoch 00003: val_val_accuracy improved from 0.61902 to 0.72948, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 596.9462 - accuracy: 0.7110 - val_loss_val: 544.5524 - val_val_accuracy: 0.7295
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 419.9850 - accuracy: 0.8385
Epoch 00004: val_val_accuracy improved from 0.72948 to 0.84376, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 419.9850 - accuracy: 0.8385 - val_loss_val: 412.3529 - val_val_accuracy: 0.8438
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 324.5074 - accuracy: 0.8562
Epoch 00005: val_val_accuracy improved from 0.84376 to 0.84665, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 324.5074 - accuracy: 0.8562 - val_loss_val: 331.4955 - val_val_accuracy: 0.8466
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 271.8617 - accuracy: 0.8583
Epoch 00006: val_val_accuracy improved from 0.84665 to 0.84840, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 271.8617 - accuracy: 0.8583 - val_loss_val: 285.2889 - val_val_accuracy: 0.8484
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 245.2692 - accuracy: 0.8600
Epoch 00007: val_val_accuracy improved from 0.84840 to 0.84959, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 245.2692 - accuracy: 0.8600 - val_loss_val: 264.3402 - val_val_accuracy: 0.8496
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 232.0424 - accuracy: 0.8611
Epoch 00008: val_val_accuracy improved from 0.84959 to 0.85046, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 232.0424 - accuracy: 0.8611 - val_loss_val: 253.7720 - val_val_accuracy: 0.8505
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 222.5263 - accuracy: 0.8615
Epoch 00009: val_val_accuracy improved from 0.85046 to 0.85088, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 222.5263 - accuracy: 0.8615 - val_loss_val: 246.1937 - val_val_accuracy: 0.8509
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 213.9485 - accuracy: 0.8616
Epoch 00010: val_val_accuracy improved from 0.85088 to 0.85093, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 213.9485 - accuracy: 0.8616 - val_loss_val: 239.8134 - val_val_accuracy: 0.8509
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 206.3823 - accuracy: 0.8618
Epoch 00011: val_val_accuracy improved from 0.85093 to 0.85119, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 206.3823 - accuracy: 0.8618 - val_loss_val: 234.5891 - val_val_accuracy: 0.8512
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 199.7957 - accuracy: 0.8622
Epoch 00012: val_val_accuracy improved from 0.85119 to 0.85155, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 199.7957 - accuracy: 0.8622 - val_loss_val: 229.6388 - val_val_accuracy: 0.8515
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 194.0285 - accuracy: 0.8631
Epoch 00013: val_val_accuracy improved from 0.85155 to 0.85273, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 194.0285 - accuracy: 0.8631 - val_loss_val: 225.2984 - val_val_accuracy: 0.8527
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 188.7492 - accuracy: 0.8642
Epoch 00014: val_val_accuracy improved from 0.85273 to 0.85351, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 188.7492 - accuracy: 0.8642 - val_loss_val: 221.7331 - val_val_accuracy: 0.8535
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 184.0856 - accuracy: 0.8647
Epoch 00015: val_val_accuracy improved from 0.85351 to 0.85428, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 184.0856 - accuracy: 0.8647 - val_loss_val: 218.7234 - val_val_accuracy: 0.8543
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 179.6953 - accuracy: 0.8652
Epoch 00016: val_val_accuracy improved from 0.85428 to 0.85454, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 19s 2s/step - loss: 179.6953 - accuracy: 0.8652 - val_loss_val: 216.0714 - val_val_accuracy: 0.8545
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 175.6617 - accuracy: 0.8659
Epoch 00017: val_val_accuracy improved from 0.85454 to 0.85490, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 175.6617 - accuracy: 0.8659 - val_loss_val: 213.6754 - val_val_accuracy: 0.8549
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 171.9500 - accuracy: 0.8669
Epoch 00018: val_val_accuracy improved from 0.85490 to 0.85500, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 171.9500 - accuracy: 0.8669 - val_loss_val: 211.5154 - val_val_accuracy: 0.8550
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 168.2829 - accuracy: 0.8680
Epoch 00019: val_val_accuracy improved from 0.85500 to 0.85505, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 168.2829 - accuracy: 0.8680 - val_loss_val: 209.4816 - val_val_accuracy: 0.8551
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 164.7503 - accuracy: 0.8694
Epoch 00020: val_val_accuracy improved from 0.85505 to 0.85552, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 164.7503 - accuracy: 0.8694 - val_loss_val: 207.8281 - val_val_accuracy: 0.8555
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 161.2651 - accuracy: 0.8707
Epoch 00021: val_val_accuracy did not improve from 0.85552
11/11 [==============================] - 18s 2s/step - loss: 161.2651 - accuracy: 0.8707 - val_loss_val: 205.7540 - val_val_accuracy: 0.8551
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 157.8397 - accuracy: 0.8722
Epoch 00022: val_val_accuracy improved from 0.85552 to 0.85557, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 157.8397 - accuracy: 0.8722 - val_loss_val: 203.9187 - val_val_accuracy: 0.8556
Epoch 23/50
11/11 [==============================] - ETA: 0s - loss: 154.2894 - accuracy: 0.8734
Epoch 00023: val_val_accuracy improved from 0.85557 to 0.85562, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 154.2894 - accuracy: 0.8734 - val_loss_val: 202.2564 - val_val_accuracy: 0.8556
Epoch 24/50
11/11 [==============================] - ETA: 0s - loss: 150.6281 - accuracy: 0.8752
Epoch 00024: val_val_accuracy did not improve from 0.85562
11/11 [==============================] - 18s 2s/step - loss: 150.6281 - accuracy: 0.8752 - val_loss_val: 200.4837 - val_val_accuracy: 0.8556
Epoch 25/50
11/11 [==============================] - ETA: 0s - loss: 146.7316 - accuracy: 0.8773
Epoch 00025: val_val_accuracy improved from 0.85562 to 0.85572, saving model to ./models/Bilstm_crf/best_model_bilstm3.hdf5
11/11 [==============================] - 18s 2s/step - loss: 146.7316 - accuracy: 0.8773 - val_loss_val: 199.0683 - val_val_accuracy: 0.8557
Epoch 26/50
11/11 [==============================] - ETA: 0s - loss: 142.7421 - accuracy: 0.8797
Epoch 00026: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 142.7421 - accuracy: 0.8797 - val_loss_val: 197.4565 - val_val_accuracy: 0.8553
Epoch 27/50
11/11 [==============================] - ETA: 0s - loss: 138.7747 - accuracy: 0.8836
Epoch 00027: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 138.7747 - accuracy: 0.8836 - val_loss_val: 195.8799 - val_val_accuracy: 0.8551
Epoch 28/50
11/11 [==============================] - ETA: 0s - loss: 134.5864 - accuracy: 0.8857
Epoch 00028: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 134.5864 - accuracy: 0.8857 - val_loss_val: 194.9100 - val_val_accuracy: 0.8552
Epoch 29/50
11/11 [==============================] - ETA: 0s - loss: 130.5572 - accuracy: 0.8887
Epoch 00029: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 130.5572 - accuracy: 0.8887 - val_loss_val: 193.2687 - val_val_accuracy: 0.8540
Epoch 30/50
11/11 [==============================] - ETA: 0s - loss: 126.5577 - accuracy: 0.8929
Epoch 00030: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 126.5577 - accuracy: 0.8929 - val_loss_val: 192.1401 - val_val_accuracy: 0.8547
Epoch 31/50
11/11 [==============================] - ETA: 0s - loss: 122.4981 - accuracy: 0.8959
Epoch 00031: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 122.4981 - accuracy: 0.8959 - val_loss_val: 191.0064 - val_val_accuracy: 0.8543
Epoch 32/50
11/11 [==============================] - ETA: 0s - loss: 118.7879 - accuracy: 0.9001
Epoch 00032: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 118.7879 - accuracy: 0.9001 - val_loss_val: 189.9629 - val_val_accuracy: 0.8548
Epoch 33/50
11/11 [==============================] - ETA: 0s - loss: 115.1863 - accuracy: 0.9043
Epoch 00033: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 115.1863 - accuracy: 0.9043 - val_loss_val: 189.6470 - val_val_accuracy: 0.8551
Epoch 34/50
11/11 [==============================] - ETA: 0s - loss: 111.5758 - accuracy: 0.9075
Epoch 00034: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 111.5758 - accuracy: 0.9075 - val_loss_val: 188.1612 - val_val_accuracy: 0.8551
Epoch 35/50
11/11 [==============================] - ETA: 0s - loss: 108.0923 - accuracy: 0.9118
Epoch 00035: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 108.0923 - accuracy: 0.9118 - val_loss_val: 188.3520 - val_val_accuracy: 0.8543
Epoch 36/50
11/11 [==============================] - ETA: 0s - loss: 104.8971 - accuracy: 0.9152
Epoch 00036: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 104.8971 - accuracy: 0.9152 - val_loss_val: 187.3990 - val_val_accuracy: 0.8533
Epoch 37/50
11/11 [==============================] - ETA: 0s - loss: 101.8638 - accuracy: 0.9177
Epoch 00037: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 101.8638 - accuracy: 0.9177 - val_loss_val: 186.7913 - val_val_accuracy: 0.8533
Epoch 38/50
11/11 [==============================] - ETA: 0s - loss: 98.6825 - accuracy: 0.9209
Epoch 00038: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 98.6825 - accuracy: 0.9209 - val_loss_val: 186.2752 - val_val_accuracy: 0.8525
Epoch 39/50
11/11 [==============================] - ETA: 0s - loss: 95.8951 - accuracy: 0.9232
Epoch 00039: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 95.8951 - accuracy: 0.9232 - val_loss_val: 185.8512 - val_val_accuracy: 0.8528
Epoch 40/50
11/11 [==============================] - ETA: 0s - loss: 93.0262 - accuracy: 0.9262
Epoch 00040: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 93.0262 - accuracy: 0.9262 - val_loss_val: 185.2719 - val_val_accuracy: 0.8529
Epoch 41/50
11/11 [==============================] - ETA: 0s - loss: 90.4176 - accuracy: 0.9278
Epoch 00041: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 90.4176 - accuracy: 0.9278 - val_loss_val: 184.7023 - val_val_accuracy: 0.8519
Epoch 42/50
11/11 [==============================] - ETA: 0s - loss: 87.7708 - accuracy: 0.9300
Epoch 00042: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 87.7708 - accuracy: 0.9300 - val_loss_val: 184.3493 - val_val_accuracy: 0.8530
Epoch 43/50
11/11 [==============================] - ETA: 0s - loss: 85.1647 - accuracy: 0.9321
Epoch 00043: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 85.1647 - accuracy: 0.9321 - val_loss_val: 184.2959 - val_val_accuracy: 0.8543
Epoch 44/50
11/11 [==============================] - ETA: 0s - loss: 82.8496 - accuracy: 0.9342
Epoch 00044: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 82.8496 - accuracy: 0.9342 - val_loss_val: 183.7374 - val_val_accuracy: 0.8546
Epoch 45/50
11/11 [==============================] - ETA: 0s - loss: 80.5893 - accuracy: 0.9353
Epoch 00045: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 80.5893 - accuracy: 0.9353 - val_loss_val: 184.2998 - val_val_accuracy: 0.8529
Epoch 46/50
11/11 [==============================] - ETA: 0s - loss: 78.2256 - accuracy: 0.9378
Epoch 00046: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 78.2256 - accuracy: 0.9378 - val_loss_val: 183.2210 - val_val_accuracy: 0.8518
Epoch 47/50
11/11 [==============================] - ETA: 0s - loss: 76.1089 - accuracy: 0.9393
Epoch 00047: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 76.1089 - accuracy: 0.9393 - val_loss_val: 182.8904 - val_val_accuracy: 0.8519
Epoch 48/50
11/11 [==============================] - ETA: 0s - loss: 74.0875 - accuracy: 0.9413
Epoch 00048: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 74.0875 - accuracy: 0.9413 - val_loss_val: 183.1541 - val_val_accuracy: 0.8539
Epoch 49/50
11/11 [==============================] - ETA: 0s - loss: 72.0150 - accuracy: 0.9427
Epoch 00049: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 72.0150 - accuracy: 0.9427 - val_loss_val: 184.1532 - val_val_accuracy: 0.8524
Epoch 50/50
11/11 [==============================] - ETA: 0s - loss: 69.9955 - accuracy: 0.9452
Epoch 00050: val_val_accuracy did not improve from 0.85572
11/11 [==============================] - 18s 2s/step - loss: 69.9955 - accuracy: 0.9452 - val_loss_val: 184.1506 - val_val_accuracy: 0.8534
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>4it [54:35, 851.35s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 743.4224 - accuracy: 0.5356
Epoch 00001: val_val_accuracy improved from -inf to 0.84830, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 27s 2s/step - loss: 743.4224 - accuracy: 0.5356 - val_loss_val: 562.0449 - val_val_accuracy: 0.8483
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 470.6226 - accuracy: 0.8608
Epoch 00002: val_val_accuracy improved from 0.84830 to 0.85423, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 19s 2s/step - loss: 470.6226 - accuracy: 0.8608 - val_loss_val: 285.1451 - val_val_accuracy: 0.8542
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 216.0299 - accuracy: 0.8630
Epoch 00003: val_val_accuracy did not improve from 0.85423
11/11 [==============================] - 18s 2s/step - loss: 216.0299 - accuracy: 0.8630 - val_loss_val: 224.8109 - val_val_accuracy: 0.8517
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 188.0731 - accuracy: 0.8650
Epoch 00004: val_val_accuracy improved from 0.85423 to 0.85485, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 188.0731 - accuracy: 0.8650 - val_loss_val: 207.9885 - val_val_accuracy: 0.8548
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 177.1631 - accuracy: 0.8677
Epoch 00005: val_val_accuracy improved from 0.85485 to 0.85686, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 19s 2s/step - loss: 177.1631 - accuracy: 0.8677 - val_loss_val: 199.9566 - val_val_accuracy: 0.8569
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 168.4441 - accuracy: 0.8700
Epoch 00006: val_val_accuracy improved from 0.85686 to 0.85804, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 168.4441 - accuracy: 0.8700 - val_loss_val: 191.5057 - val_val_accuracy: 0.8580
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 160.3216 - accuracy: 0.8727
Epoch 00007: val_val_accuracy improved from 0.85804 to 0.86026, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 160.3216 - accuracy: 0.8727 - val_loss_val: 185.5939 - val_val_accuracy: 0.8603
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 152.8682 - accuracy: 0.8771
Epoch 00008: val_val_accuracy improved from 0.86026 to 0.86206, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 152.8682 - accuracy: 0.8771 - val_loss_val: 178.0694 - val_val_accuracy: 0.8621
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 145.8248 - accuracy: 0.8794
Epoch 00009: val_val_accuracy improved from 0.86206 to 0.86273, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 19s 2s/step - loss: 145.8248 - accuracy: 0.8794 - val_loss_val: 173.9385 - val_val_accuracy: 0.8627
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 138.7645 - accuracy: 0.8842
Epoch 00010: val_val_accuracy improved from 0.86273 to 0.86515, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 138.7645 - accuracy: 0.8842 - val_loss_val: 169.0667 - val_val_accuracy: 0.8652
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 131.5433 - accuracy: 0.8886
Epoch 00011: val_val_accuracy improved from 0.86515 to 0.86552, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 131.5433 - accuracy: 0.8886 - val_loss_val: 165.6495 - val_val_accuracy: 0.8655
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 124.3978 - accuracy: 0.8942
Epoch 00012: val_val_accuracy improved from 0.86552 to 0.86577, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 124.3978 - accuracy: 0.8942 - val_loss_val: 162.2051 - val_val_accuracy: 0.8658
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 117.2854 - accuracy: 0.8991
Epoch 00013: val_val_accuracy improved from 0.86577 to 0.86691, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 117.2854 - accuracy: 0.8991 - val_loss_val: 160.2056 - val_val_accuracy: 0.8669
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 110.3157 - accuracy: 0.9036
Epoch 00014: val_val_accuracy improved from 0.86691 to 0.86825, saving model to ./models/Bilstm_crf/best_model_bilstm4.hdf5
11/11 [==============================] - 18s 2s/step - loss: 110.3157 - accuracy: 0.9036 - val_loss_val: 157.1483 - val_val_accuracy: 0.8682
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 102.8738 - accuracy: 0.9104
Epoch 00015: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 102.8738 - accuracy: 0.9104 - val_loss_val: 156.7975 - val_val_accuracy: 0.8673
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 96.4286 - accuracy: 0.9162
Epoch 00016: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 96.4286 - accuracy: 0.9162 - val_loss_val: 157.4594 - val_val_accuracy: 0.8669
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 90.0859 - accuracy: 0.9219
Epoch 00017: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 90.0859 - accuracy: 0.9219 - val_loss_val: 155.8476 - val_val_accuracy: 0.8671
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 84.2307 - accuracy: 0.9273
Epoch 00018: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 84.2307 - accuracy: 0.9273 - val_loss_val: 158.5376 - val_val_accuracy: 0.8657
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 78.0186 - accuracy: 0.9322
Epoch 00019: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 78.0186 - accuracy: 0.9322 - val_loss_val: 155.8327 - val_val_accuracy: 0.8669
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 72.5234 - accuracy: 0.9378
Epoch 00020: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 72.5234 - accuracy: 0.9378 - val_loss_val: 158.8300 - val_val_accuracy: 0.8626
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 67.8043 - accuracy: 0.9415
Epoch 00021: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 67.8043 - accuracy: 0.9415 - val_loss_val: 158.5603 - val_val_accuracy: 0.8657
Epoch 22/50
11/11 [==============================] - ETA: 0s - loss: 63.1150 - accuracy: 0.9461
Epoch 00022: val_val_accuracy did not improve from 0.86825
11/11 [==============================] - 18s 2s/step - loss: 63.1150 - accuracy: 0.9461 - val_loss_val: 161.6916 - val_val_accuracy: 0.8632
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>5it [1:01:42, 698.37s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 869.6631 - accuracy: 0.4574
Epoch 00001: val_val_accuracy improved from -inf to 0.83598, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 27s 2s/step - loss: 869.6631 - accuracy: 0.4574 - val_loss_val: 624.7947 - val_val_accuracy: 0.8360
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 413.4493 - accuracy: 0.8498
Epoch 00002: val_val_accuracy improved from 0.83598 to 0.84129, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 18s 2s/step - loss: 413.4493 - accuracy: 0.8498 - val_loss_val: 368.8108 - val_val_accuracy: 0.8413
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 253.4279 - accuracy: 0.8569
Epoch 00003: val_val_accuracy improved from 0.84129 to 0.85072, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 18s 2s/step - loss: 253.4279 - accuracy: 0.8569 - val_loss_val: 242.6870 - val_val_accuracy: 0.8507
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 205.0997 - accuracy: 0.8641
Epoch 00004: val_val_accuracy improved from 0.85072 to 0.85448, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 18s 2s/step - loss: 205.0997 - accuracy: 0.8641 - val_loss_val: 230.2374 - val_val_accuracy: 0.8545
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 187.0229 - accuracy: 0.8647
Epoch 00005: val_val_accuracy improved from 0.85448 to 0.85459, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 18s 2s/step - loss: 187.0229 - accuracy: 0.8647 - val_loss_val: 210.9201 - val_val_accuracy: 0.8546
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 172.9125 - accuracy: 0.8654
Epoch 00006: val_val_accuracy improved from 0.85459 to 0.85469, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 18s 2s/step - loss: 172.9125 - accuracy: 0.8654 - val_loss_val: 204.3195 - val_val_accuracy: 0.8547
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 162.0789 - accuracy: 0.8674
Epoch 00007: val_val_accuracy improved from 0.85469 to 0.85515, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 18s 2s/step - loss: 162.0789 - accuracy: 0.8674 - val_loss_val: 196.5636 - val_val_accuracy: 0.8552
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 152.6302 - accuracy: 0.8751
Epoch 00008: val_val_accuracy improved from 0.85515 to 0.85577, saving model to ./models/Bilstm_crf/best_model_bilstm5.hdf5
11/11 [==============================] - 18s 2s/step - loss: 152.6302 - accuracy: 0.8751 - val_loss_val: 192.3775 - val_val_accuracy: 0.8558
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 143.8112 - accuracy: 0.8818
Epoch 00009: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 143.8112 - accuracy: 0.8818 - val_loss_val: 190.5510 - val_val_accuracy: 0.8539
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 134.6599 - accuracy: 0.8894
Epoch 00010: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 134.6599 - accuracy: 0.8894 - val_loss_val: 188.4390 - val_val_accuracy: 0.8535
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 124.9362 - accuracy: 0.8979
Epoch 00011: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 124.9362 - accuracy: 0.8979 - val_loss_val: 188.7616 - val_val_accuracy: 0.8529
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 114.8958 - accuracy: 0.9068
Epoch 00012: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 114.8958 - accuracy: 0.9068 - val_loss_val: 188.8639 - val_val_accuracy: 0.8514
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 105.0866 - accuracy: 0.9148
Epoch 00013: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 105.0866 - accuracy: 0.9148 - val_loss_val: 188.3698 - val_val_accuracy: 0.8517
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 95.5014 - accuracy: 0.9222
Epoch 00014: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 95.5014 - accuracy: 0.9222 - val_loss_val: 191.1317 - val_val_accuracy: 0.8493
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 86.5684 - accuracy: 0.9310
Epoch 00015: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 86.5684 - accuracy: 0.9310 - val_loss_val: 192.2762 - val_val_accuracy: 0.8519
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 78.4896 - accuracy: 0.9384
Epoch 00016: val_val_accuracy did not improve from 0.85577
11/11 [==============================] - 18s 2s/step - loss: 78.4896 - accuracy: 0.9384 - val_loss_val: 196.6446 - val_val_accuracy: 0.8467
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>6it [1:07:19, 575.39s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 795.4254 - accuracy: 0.3729
Epoch 00001: val_val_accuracy improved from -inf to 0.83649, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 28s 2s/step - loss: 795.4254 - accuracy: 0.3729 - val_loss_val: 551.2900 - val_val_accuracy: 0.8365
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 397.7016 - accuracy: 0.8570
Epoch 00002: val_val_accuracy improved from 0.83649 to 0.85072, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 19s 2s/step - loss: 397.7016 - accuracy: 0.8570 - val_loss_val: 259.1644 - val_val_accuracy: 0.8507
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 224.5286 - accuracy: 0.8580
Epoch 00003: val_val_accuracy did not improve from 0.85072
11/11 [==============================] - 18s 2s/step - loss: 224.5286 - accuracy: 0.8580 - val_loss_val: 246.6926 - val_val_accuracy: 0.8475
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 209.0459 - accuracy: 0.8622
Epoch 00004: val_val_accuracy improved from 0.85072 to 0.85402, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 209.0459 - accuracy: 0.8622 - val_loss_val: 229.0817 - val_val_accuracy: 0.8540
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 198.8728 - accuracy: 0.8648
Epoch 00005: val_val_accuracy improved from 0.85402 to 0.85438, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 19s 2s/step - loss: 198.8728 - accuracy: 0.8648 - val_loss_val: 220.2141 - val_val_accuracy: 0.8544
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 190.2677 - accuracy: 0.8654
Epoch 00006: val_val_accuracy improved from 0.85438 to 0.85515, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 19s 2s/step - loss: 190.2677 - accuracy: 0.8654 - val_loss_val: 212.9374 - val_val_accuracy: 0.8552
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 182.1038 - accuracy: 0.8671
Epoch 00007: val_val_accuracy improved from 0.85515 to 0.85649, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 182.1038 - accuracy: 0.8671 - val_loss_val: 205.7927 - val_val_accuracy: 0.8565
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 174.8570 - accuracy: 0.8701
Epoch 00008: val_val_accuracy improved from 0.85649 to 0.85887, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 174.8570 - accuracy: 0.8701 - val_loss_val: 198.9313 - val_val_accuracy: 0.8589
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 167.6190 - accuracy: 0.8735
Epoch 00009: val_val_accuracy improved from 0.85887 to 0.86005, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 167.6190 - accuracy: 0.8735 - val_loss_val: 193.4623 - val_val_accuracy: 0.8601
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 160.3369 - accuracy: 0.8759
Epoch 00010: val_val_accuracy improved from 0.86005 to 0.86284, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 160.3369 - accuracy: 0.8759 - val_loss_val: 188.5827 - val_val_accuracy: 0.8628
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 152.9917 - accuracy: 0.8796
Epoch 00011: val_val_accuracy improved from 0.86284 to 0.86335, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 152.9917 - accuracy: 0.8796 - val_loss_val: 182.5237 - val_val_accuracy: 0.8634
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 145.0149 - accuracy: 0.8834
Epoch 00012: val_val_accuracy improved from 0.86335 to 0.86366, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 145.0149 - accuracy: 0.8834 - val_loss_val: 177.2776 - val_val_accuracy: 0.8637
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 137.0461 - accuracy: 0.8882
Epoch 00013: val_val_accuracy did not improve from 0.86366
11/11 [==============================] - 18s 2s/step - loss: 137.0461 - accuracy: 0.8882 - val_loss_val: 174.9149 - val_val_accuracy: 0.8611
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 129.8146 - accuracy: 0.8937
Epoch 00014: val_val_accuracy improved from 0.86366 to 0.86376, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 129.8146 - accuracy: 0.8937 - val_loss_val: 170.5806 - val_val_accuracy: 0.8638
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 121.7186 - accuracy: 0.8983
Epoch 00015: val_val_accuracy improved from 0.86376 to 0.86464, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 121.7186 - accuracy: 0.8983 - val_loss_val: 168.3234 - val_val_accuracy: 0.8646
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 113.7512 - accuracy: 0.9046
Epoch 00016: val_val_accuracy did not improve from 0.86464
11/11 [==============================] - 18s 2s/step - loss: 113.7512 - accuracy: 0.9046 - val_loss_val: 167.9857 - val_val_accuracy: 0.8630
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 105.3593 - accuracy: 0.9123
Epoch 00017: val_val_accuracy did not improve from 0.86464
11/11 [==============================] - 18s 2s/step - loss: 105.3593 - accuracy: 0.9123 - val_loss_val: 167.0740 - val_val_accuracy: 0.8641
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 98.7250 - accuracy: 0.9168
Epoch 00018: val_val_accuracy did not improve from 0.86464
11/11 [==============================] - 18s 2s/step - loss: 98.7250 - accuracy: 0.9168 - val_loss_val: 165.8655 - val_val_accuracy: 0.8625
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 92.0058 - accuracy: 0.9229
Epoch 00019: val_val_accuracy did not improve from 0.86464
11/11 [==============================] - 18s 2s/step - loss: 92.0058 - accuracy: 0.9229 - val_loss_val: 166.8245 - val_val_accuracy: 0.8637
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 85.6248 - accuracy: 0.9278
Epoch 00020: val_val_accuracy did not improve from 0.86464
11/11 [==============================] - 18s 2s/step - loss: 85.6248 - accuracy: 0.9278 - val_loss_val: 167.9448 - val_val_accuracy: 0.8592
Epoch 21/50
11/11 [==============================] - ETA: 0s - loss: 79.6531 - accuracy: 0.9332
Epoch 00021: val_val_accuracy improved from 0.86464 to 0.86500, saving model to ./models/Bilstm_crf/best_model_bilstm6.hdf5
11/11 [==============================] - 18s 2s/step - loss: 79.6531 - accuracy: 0.9332 - val_loss_val: 168.5295 - val_val_accuracy: 0.8650
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>7it [1:14:23, 525.80s/it]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/50
11/11 [==============================] - ETA: 0s - loss: 823.4320 - accuracy: 0.4440
Epoch 00001: val_val_accuracy improved from -inf to 0.53670, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 27s 2s/step - loss: 823.4320 - accuracy: 0.4440 - val_loss_val: 621.2227 - val_val_accuracy: 0.5367
Epoch 2/50
11/11 [==============================] - ETA: 0s - loss: 457.6543 - accuracy: 0.6558
Epoch 00002: val_val_accuracy improved from 0.53670 to 0.76371, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 18s 2s/step - loss: 457.6543 - accuracy: 0.6558 - val_loss_val: 417.7347 - val_val_accuracy: 0.7637
Epoch 3/50
11/11 [==============================] - ETA: 0s - loss: 288.0335 - accuracy: 0.8502
Epoch 00003: val_val_accuracy improved from 0.76371 to 0.85330, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 19s 2s/step - loss: 288.0335 - accuracy: 0.8502 - val_loss_val: 287.4465 - val_val_accuracy: 0.8533
Epoch 4/50
11/11 [==============================] - ETA: 0s - loss: 243.9925 - accuracy: 0.8638
Epoch 00004: val_val_accuracy improved from 0.85330 to 0.85433, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 18s 2s/step - loss: 243.9925 - accuracy: 0.8638 - val_loss_val: 264.7958 - val_val_accuracy: 0.8543
Epoch 5/50
11/11 [==============================] - ETA: 0s - loss: 226.7943 - accuracy: 0.8643
Epoch 00005: val_val_accuracy did not improve from 0.85433
11/11 [==============================] - 18s 2s/step - loss: 226.7943 - accuracy: 0.8643 - val_loss_val: 251.0077 - val_val_accuracy: 0.8536
Epoch 6/50
11/11 [==============================] - ETA: 0s - loss: 216.9130 - accuracy: 0.8642
Epoch 00006: val_val_accuracy did not improve from 0.85433
11/11 [==============================] - 18s 2s/step - loss: 216.9130 - accuracy: 0.8642 - val_loss_val: 245.3092 - val_val_accuracy: 0.8539
Epoch 7/50
11/11 [==============================] - ETA: 0s - loss: 209.0712 - accuracy: 0.8646
Epoch 00007: val_val_accuracy improved from 0.85433 to 0.85443, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 18s 2s/step - loss: 209.0712 - accuracy: 0.8646 - val_loss_val: 237.7454 - val_val_accuracy: 0.8544
Epoch 8/50
11/11 [==============================] - ETA: 0s - loss: 200.9320 - accuracy: 0.8647
Epoch 00008: val_val_accuracy improved from 0.85443 to 0.85448, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 19s 2s/step - loss: 200.9320 - accuracy: 0.8647 - val_loss_val: 230.1772 - val_val_accuracy: 0.8545
Epoch 9/50
11/11 [==============================] - ETA: 0s - loss: 192.6641 - accuracy: 0.8648
Epoch 00009: val_val_accuracy improved from 0.85448 to 0.85454, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 19s 2s/step - loss: 192.6641 - accuracy: 0.8648 - val_loss_val: 222.7895 - val_val_accuracy: 0.8545
Epoch 10/50
11/11 [==============================] - ETA: 0s - loss: 184.0183 - accuracy: 0.8648
Epoch 00010: val_val_accuracy improved from 0.85454 to 0.85459, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 19s 2s/step - loss: 184.0183 - accuracy: 0.8648 - val_loss_val: 216.1654 - val_val_accuracy: 0.8546
Epoch 11/50
11/11 [==============================] - ETA: 0s - loss: 175.4963 - accuracy: 0.8653
Epoch 00011: val_val_accuracy did not improve from 0.85459
11/11 [==============================] - 18s 2s/step - loss: 175.4963 - accuracy: 0.8653 - val_loss_val: 209.9115 - val_val_accuracy: 0.8546
Epoch 12/50
11/11 [==============================] - ETA: 0s - loss: 167.1657 - accuracy: 0.8663
Epoch 00012: val_val_accuracy improved from 0.85459 to 0.85552, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 18s 2s/step - loss: 167.1657 - accuracy: 0.8663 - val_loss_val: 204.8066 - val_val_accuracy: 0.8555
Epoch 13/50
11/11 [==============================] - ETA: 0s - loss: 158.9868 - accuracy: 0.8689
Epoch 00013: val_val_accuracy improved from 0.85552 to 0.85603, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 19s 2s/step - loss: 158.9868 - accuracy: 0.8689 - val_loss_val: 200.5554 - val_val_accuracy: 0.8560
Epoch 14/50
11/11 [==============================] - ETA: 0s - loss: 150.9649 - accuracy: 0.8735
Epoch 00014: val_val_accuracy improved from 0.85603 to 0.85716, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 18s 2s/step - loss: 150.9649 - accuracy: 0.8735 - val_loss_val: 197.4810 - val_val_accuracy: 0.8572
Epoch 15/50
11/11 [==============================] - ETA: 0s - loss: 142.8816 - accuracy: 0.8788
Epoch 00015: val_val_accuracy did not improve from 0.85716
11/11 [==============================] - 18s 2s/step - loss: 142.8816 - accuracy: 0.8788 - val_loss_val: 194.6909 - val_val_accuracy: 0.8566
Epoch 16/50
11/11 [==============================] - ETA: 0s - loss: 134.5408 - accuracy: 0.8839
Epoch 00016: val_val_accuracy did not improve from 0.85716
11/11 [==============================] - 18s 2s/step - loss: 134.5408 - accuracy: 0.8839 - val_loss_val: 192.7493 - val_val_accuracy: 0.8560
Epoch 17/50
11/11 [==============================] - ETA: 0s - loss: 126.0100 - accuracy: 0.8910
Epoch 00017: val_val_accuracy did not improve from 0.85716
11/11 [==============================] - 18s 2s/step - loss: 126.0100 - accuracy: 0.8910 - val_loss_val: 192.7042 - val_val_accuracy: 0.8554
Epoch 18/50
11/11 [==============================] - ETA: 0s - loss: 117.3941 - accuracy: 0.8986
Epoch 00018: val_val_accuracy did not improve from 0.85716
11/11 [==============================] - 18s 2s/step - loss: 117.3941 - accuracy: 0.8986 - val_loss_val: 194.0066 - val_val_accuracy: 0.8539
Epoch 19/50
11/11 [==============================] - ETA: 0s - loss: 108.7834 - accuracy: 0.9065
Epoch 00019: val_val_accuracy did not improve from 0.85716
11/11 [==============================] - 18s 2s/step - loss: 108.7834 - accuracy: 0.9065 - val_loss_val: 194.2857 - val_val_accuracy: 0.8550
Epoch 20/50
11/11 [==============================] - ETA: 0s - loss: 100.6973 - accuracy: 0.9158
Epoch 00020: val_val_accuracy improved from 0.85716 to 0.85722, saving model to ./models/Bilstm_crf/best_model_bilstm7.hdf5
11/11 [==============================] - 18s 2s/step - loss: 100.6973 - accuracy: 0.9158 - val_loss_val: 205.0542 - val_val_accuracy: 0.8572
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>8it [1:20:37, 604.69s/it]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Evaluation-Grid-search">Evaluation Grid search<a class="anchor-link" href="#Evaluation-Grid-search">&#182;</a></h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">val_true</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">val_tags_y_B</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#We evaluate the different model based on their best perfomance</span>

<span class="n">grid_search_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="s1">&#39;f1 score micro&#39;</span><span class="p">,</span><span class="s1">&#39;f1 score macro&#39;</span><span class="p">])</span>
<span class="n">grid_search_results</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">models_bilstm_crf_param</span>

<span class="n">f1_scores_micro</span><span class="o">=</span><span class="p">[]</span>
<span class="n">f1_scores_macro</span><span class="o">=</span><span class="p">[]</span>

<span class="n">f1_score_selected</span><span class="o">=</span><span class="mi">0</span>
<span class="c1">#model_selected=build_model()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">models_bilstm_crf</span><span class="p">)):</span>
  <span class="c1"># Restore the weights</span>
  <span class="n">model_i</span> <span class="o">=</span> <span class="n">models_bilstm_crf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">model_i</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s2">&quot;./models/Bilstm_crf/best_model_bilstm&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;.hdf5&quot;</span><span class="p">)</span>
  <span class="n">val_pred_ner_i</span> <span class="o">=</span> <span class="n">model_i</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences_X_B</span><span class="p">)</span>
  
  
  <span class="n">f1_score_micro</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
  <span class="n">f1_score_macro</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner_i</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
  <span class="n">f1_scores_micro</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score_micro</span><span class="p">)</span>
  <span class="n">f1_scores_macro</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score_macro</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">f1_score_macro</span> <span class="o">&gt;=</span> <span class="n">f1_score_selected</span><span class="p">:</span>
    
    <span class="n">model_selected</span> <span class="o">=</span> <span class="n">model_i</span>
    <span class="n">f1_score_selected</span> <span class="o">=</span> <span class="n">f1_score_macro</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_selected</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;tf2crf.model_wrapper.ModelWithCRFLossDSCLoss object at 0x7f17fc77b390&gt;
&lt;tf2crf.model_wrapper.ModelWithCRFLossDSCLoss object at 0x7f17a2acdf50&gt;
&lt;tf2crf.model_wrapper.ModelWithCRFLossDSCLoss object at 0x7f17d09a4310&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search_results</span><span class="p">[</span><span class="s1">&#39;f1 score micro&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1_scores_micro</span>
<span class="n">grid_search_results</span><span class="p">[</span><span class="s1">&#39;f1 score macro&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f1_scores_macro</span>
<span class="n">grid_search_results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>f1 score micro</th>
      <th>f1 score macro</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[adam, Glove, GRU, 0.3, 10]</td>
      <td>0.862887</td>
      <td>0.277990</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[adam, None, GRU, 0.3, 10]</td>
      <td>0.856804</td>
      <td>0.250600</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[adam, Glove, LSTM, 0.3, 10]</td>
      <td>0.860412</td>
      <td>0.221649</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[adam, None, LSTM, 0.3, 10]</td>
      <td>0.855567</td>
      <td>0.155894</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[adam, Glove, GRU, 0.3, 64]</td>
      <td>0.870000</td>
      <td>0.326773</td>
    </tr>
    <tr>
      <th>5</th>
      <td>[adam, None, GRU, 0.3, 64]</td>
      <td>0.855361</td>
      <td>0.156574</td>
    </tr>
    <tr>
      <th>6</th>
      <td>[adam, Glove, LSTM, 0.3, 64]</td>
      <td>0.865619</td>
      <td>0.377952</td>
    </tr>
    <tr>
      <th>7</th>
      <td>[adam, None, LSTM, 0.3, 64]</td>
      <td>0.857113</td>
      <td>0.209945</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Tout d'abord on remarque que compar  la tache A, les score en f1 macro sont plus faible. Cependendant on remarque galement que ce sont les mmes paramtres qui donne les meilleurs rsultats c'est  dire: [adam, Glove, GRU, 0.3, 64] avec 0.87 de f1 score sur les donnes de validations. En soumissioin kaggle nous avons obtenu 73 % environ. Ces rsultats ne sont pas satisfaisants car il ne dpasse pas un modle simple qui ne prdirait que des 'O'.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Evaluation-du-mod&#232;le-(confusion-matrix-et-autre-metrics)">Evaluation du mod&#232;le (confusion matrix et autre metrics)<a class="anchor-link" href="#Evaluation-du-mod&#232;le-(confusion-matrix-et-autre-metrics)">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># to not do the grid search again</span>
<span class="n">model_selected</span> <span class="o">=</span> <span class="n">models_bilstm_crf</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span>
<span class="n">callback2</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss_val&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">checkpoint2</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;./models/Bilstm_crf/best_model_bilstm_select.hdf5&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_val_accuracy&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model_selected</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_sentences_X_B</span><span class="p">,</span> <span class="n">train_tags_y_B</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_sentences_X_B</span><span class="p">,</span><span class="n">val_tags_y_B</span><span class="p">),</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint2</span><span class="p">,</span><span class="n">callback2</span><span class="p">],</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_confusion_bis</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;f1 micro:{f1_score(true, pred, average=&#39;micro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;f1 macro:{f1_score(true, pred, average=&#39;macro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;recall macro:{recall_score(true, pred, average=&#39;macro&#39;):.3f}&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">val_pred_ner</span> <span class="o">=</span> <span class="n">model_selected</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences_X_B</span><span class="p">)</span>
<span class="n">labels_for_confusion_m</span><span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tags_B</span><span class="p">))</span>
<span class="n">show_confusion_bis</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">labels</span><span class="o">=</span><span class="n">labels_for_confusion_m</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>f1 micro:0.865
f1 macro:0.371
recall macro:0.333
Confusion Matrix:
[[8239    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0   89   10    0   31    0    3    0   96    0    1    4    0    3]
 [   0    7   28    0   17    1    2    0   61    0    2    8    0    0]
 [   0    0    0    0    1    0    0    0    8    0    0    0    0    0]
 [   0   11   17    0  145    2    0    0  142    2    5    5    0    2]
 [   0    1    1    0    2    9    2    1   63    5    1    1    2    0]
 [   4   11    2    0    4    0   48    1  158    8    6   10   11    1]
 [   0    1    0    0    0    0    1   20   76   14    3   10    1    0]
 [   3   38   25    0   90    0    6   16 7780   81  128  145   22    6]
 [   0    0    2    0    2    0    0    5  168  108   21   17    7    1]
 [   0    5    3    0   18    0    2    2  262   19   98   32    8    0]
 [   0    2   12    0    9    0    1    6  253   10   21  130    5    0]
 [   0    1    0    0    1    0    7    0  106   26   15   12   66    3]
 [   0   10    1    0    4    0    5    1   81    3   20   10   14   25]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Remarque</em></strong></p>
<p>on peut voir que les 'O' sont les tags les plus prdits et menant aux plus de faux-positifs du fait du dsquiliibre de nos donnes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tags_names_ordered</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;-PAD-&#39;</span><span class="p">,</span><span class="s1">&#39;L_M&#39;</span><span class="p">,</span><span class="s1">&#39;L_T&#39;</span><span class="p">,</span><span class="s1">&#39;U_T&#39;</span><span class="p">,</span><span class="s1">&#39;L_P&#39;</span><span class="p">,</span><span class="s1">&#39;U_P&#39;</span><span class="p">,</span><span class="s1">&#39;U_M&#39;</span><span class="p">,</span><span class="s1">&#39;B_T&#39;</span><span class="p">,</span><span class="s1">&#39;O&#39;</span><span class="p">,</span><span class="s1">&#39;B_P&#39;</span><span class="p">,</span><span class="s1">&#39;I_P&#39;</span><span class="p">,</span><span class="s1">&#39;I_T&#39;</span><span class="p">,</span><span class="s1">&#39;B_M&#39;</span><span class="p">,</span><span class="s1">&#39;I_M&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">val_true</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">val_pred_ner</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">target_names</span><span class="o">=</span><span class="n">tags_names_ordered</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

       -PAD-       1.00      1.00      1.00      8239
         L_M       0.52      0.41      0.46       237
         L_T       0.34      0.16      0.22       126
         U_T       0.00      0.00      0.00         9
         L_P       0.40      0.44      0.42       331
         U_P       0.37      0.08      0.13        88
         U_M       0.63      0.14      0.23       264
         B_T       0.39      0.15      0.22       126
           O       0.84      0.94      0.88      8340
         B_P       0.34      0.28      0.31       331
         I_P       0.26      0.19      0.22       449
         I_T       0.41      0.26      0.32       449
         B_M       0.46      0.29      0.35       237
         I_M       0.45      0.14      0.22       174

    accuracy                           0.86     19400
   macro avg       0.46      0.32      0.36     19400
weighted avg       0.84      0.86      0.85     19400

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>REMARQUE</em></strong></p>
<p>On remarque 'B_P' obtient un bon score de 75% en f1 micro. C'est celui qui le "mieux prdit" aprs le 'O'. On remarque 'L_T' n'est jamais classifi correctement et ce parce que il est trs rarement obtenu dans nos donnes (9 fois seulement). Il est donc difficilement prdictible. Le 'O' reste le tag ayant le meilleur f1 score car le plus prsent dans notre dataset. En conclusion les rsultats de notre algorithme dpend fortement de leur frquences d'apparitions dans nos donnes. Finalement, ces rsultats restent mdiocre et ne nous offre que 0.73 sur nos donnes de tests.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="cr&#233;ation-des-fichiers-de-soumission-de-validation-et-de-test">cr&#233;ation des fichiers de soumission de validation et de test<a class="anchor-link" href="#cr&#233;ation-des-fichiers-de-soumission-de-validation-et-de-test">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">suppress_pad</span><span class="p">(</span><span class="n">test_tags_y_predict</span><span class="p">,</span><span class="n">test_sentences_X_no_pad</span><span class="p">):</span>
  <span class="c1"># we supress the 0s correponding to the additional padding</span>
  <span class="c1">#test_tags_y_predict_no_pad = np.delete(test_tags_y_predict[0], np.where(test_tags_y_predict[0] == 0))</span>
  <span class="n">test_tags_y_predict_no_pad</span> <span class="o">=</span> <span class="n">test_tags_y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">test_tags_y_predict</span><span class="p">)):</span>
    <span class="n">A_i</span><span class="o">=</span><span class="n">test_tags_y_predict</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>
    <span class="n">test_tags_y_predict_no_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">test_tags_y_predict_no_pad</span> <span class="p">,</span><span class="n">A_i</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">!=</span><span class="nb">len</span><span class="p">(</span><span class="n">A_i</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A_i</span><span class="p">))</span>
      <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_sentences_X_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FALSE:&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">test_tags_y_predict_no_pad</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">val_pred_ner</span> <span class="o">=</span> <span class="n">model_selected</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_sentences_X_B</span><span class="p">)</span>
<span class="n">val_pred_ner_no_pad</span> <span class="o">=</span> <span class="n">suppress_pad</span><span class="p">(</span><span class="n">val_pred_ner</span><span class="p">,</span><span class="n">val_sentences_X_no_pad_B</span><span class="p">)</span>
<span class="n">submission_val_bilstm_crf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">])</span>
<span class="n">submission_val_bilstm_crf</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_B_df</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span>

<span class="n">val_ids_concat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">val_ids_B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_B_df</span><span class="p">))):</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">val_B_df</span><span class="p">[</span><span class="n">val_B_df</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">val_ids_concat</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">submission_val_bilstm_crf</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_pred_ner_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="n">submission_val_bilstm_crf</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission_val_bilstm_crf</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">index2tagB</span><span class="p">)</span>
<span class="n">submission_val_bilstm_crf</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 11161/11161 [00:13&lt;00:00, 830.46it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TokenID</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0301010415300355-0</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0301010415300355-1</td>
      <td>O</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0301010415300355-2</td>
      <td>O</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0301010415300355-3</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0301010415300355-4</td>
      <td>O</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>11156</th>
      <td>S1359028614000989-185</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11157</th>
      <td>S1359028614000989-186</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11158</th>
      <td>S1359028614000989-187</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11159</th>
      <td>S1359028614000989-188</td>
      <td>O</td>
    </tr>
    <tr>
      <th>11160</th>
      <td>S1359028614000989-189</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
<p>11161 rows  2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_pred_ner</span> <span class="o">=</span> <span class="n">model_selected</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_sentences_X_B</span><span class="p">)</span>
<span class="n">test_pred_ner_no_pad</span> <span class="o">=</span> <span class="n">suppress_pad</span><span class="p">(</span><span class="n">test_pred_ner</span><span class="p">,</span><span class="n">test_sentences_X_no_pad_B</span><span class="p">)</span>
<span class="n">submission_test_bilstm_crf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">,</span> <span class="s1">&#39;Tag&#39;</span><span class="p">])</span>
<span class="n">submission_test_bilstm_crf</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;TokenID&#39;</span><span class="p">]</span>


<span class="n">test_ids_concat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_ids_B</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">))):</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_ids_concat</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">submission_test_bilstm_crf</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_pred_ner_no_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>


<span class="n">submission_test_bilstm_crf</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission_test_bilstm_crf</span><span class="p">[</span><span class="s1">&#39;Tag&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">index2tagB</span><span class="p">)</span>
<span class="n">submission_test_bilstm_crf</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 21711/21711 [00:42&lt;00:00, 506.80it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TokenID</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0885230816301759-0</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0885230816301759-1</td>
      <td>O</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0885230816301759-2</td>
      <td>O</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0885230816301759-3</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0885230816301759-4</td>
      <td>I_T</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21706</th>
      <td>S1877750313001269-211</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21707</th>
      <td>S1877750313001269-212</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21708</th>
      <td>S1877750313001269-213</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21709</th>
      <td>S1877750313001269-214</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21710</th>
      <td>S1877750313001269-215</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
<p>21711 rows  2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">submission_test_bilstm_crf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Test_submission_Glove_Bilstm_CRF_tache_B.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">submission_val_bilstm_crf</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Val_submission_Glove_Bilstm_CRF_tache_B.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="BERT">BERT<a class="anchor-link" href="#BERT">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="k">import</span> <span class="n">sent_tokenize</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Train dataset ====&quot;</span><span class="p">)</span>
<span class="n">all_sentences_train</span><span class="p">,</span> <span class="n">all_tags_train_B</span> <span class="o">=</span> <span class="n">get_doc_sentences</span><span class="p">(</span><span class="n">get_text_docs</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">train_sentences</span><span class="p">,</span> <span class="n">train_tags_B</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Validation dataset ====&quot;</span><span class="p">)</span>
<span class="n">all_sentences_val</span><span class="p">,</span> <span class="n">all_tags_val_B</span> <span class="o">=</span> <span class="n">get_doc_sentences</span><span class="p">(</span><span class="n">get_text_docs</span><span class="p">(</span><span class="s1">&#39;val&#39;</span><span class="p">),</span> <span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">val_sentences</span><span class="p">,</span> <span class="n">val_tags_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>==== Train dataset ====
Loading docs...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 350/350 [00:00&lt;00:00, 777.32it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Constructing sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 350/350 [00:00&lt;00:00, 441.82it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
 Doc S0370269304009359 invalid
[&#39;Table&#39;, &#39;1&#39;, &#39;lists&#39;, &#39;8&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;B&#39;, &#39;decays&#39;, &#39;.&#39;, &#39;In&#39;, &#39;fact&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;more&#39;, &#39;decay&#39;, &#39;pairs&#39;, &#39;,&#39;, &#39;since&#39;, &#39;many&#39;, &#39;of&#39;, &#39;the&#39;, &#39;particles&#39;, &#39;in&#39;, &#39;the&#39;, &#39;final&#39;, &#39;states&#39;, &#39;can&#39;, &#39;be&#39;, &#39;observed&#39;, &#39;as&#39;, &#39;either&#39;, &#39;pseudoscalar&#39;, &#39;(&#39;, &#39;P&#39;, &#39;)&#39;, &#39;or&#39;, &#39;vector&#39;, &#39;(&#39;, &#39;V&#39;, &#39;)&#39;, &#39;mesons&#39;, &#39;.&#39;, &#39;Note&#39;, &#39;that&#39;, &#39;certain&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;written&#39;, &#39;in&#39;, &#39;terms&#39;, &#39;of&#39;, &#39;VV&#39;, &#39;final&#39;, &#39;states&#39;, &#39;,&#39;, &#39;while&#39;, &#39;others&#39;, &#39;are&#39;, &#39;have&#39;, &#39;PP&#39;, &#39;states&#39;, &#39;.&#39;, &#39;There&#39;, &#39;are&#39;, &#39;three&#39;, &#39;reasons&#39;, &#39;for&#39;, &#39;this&#39;, &#39;.&#39;, &#39;First&#39;, &#39;,&#39;, &#39;some&#39;, &#39;decays&#39;, &#39;involve&#39;, &#39;a&#39;, &#39;final-state&#39;, &#39;0&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;experimentally&#39;, &#39;it&#39;, &#39;will&#39;, &#39;be&#39;, &#39;necessary&#39;, &#39;to&#39;, &#39;find&#39;, &#39;the&#39;, &#39;decay&#39;, &#39;vertices&#39;, &#39;of&#39;, &#39;the&#39;, &#39;final&#39;, &#39;particles&#39;, &#39;.&#39;, &#39;This&#39;, &#39;is&#39;, &#39;virtually&#39;, &#39;impossible&#39;, &#39;for&#39;, &#39;a&#39;, &#39;0&#39;, &#39;,&#39;, &#39;and&#39;, &#39;so&#39;, &#39;we&#39;, &#39;always&#39;, &#39;use&#39;, &#39;a&#39;, &#39;0&#39;, &#39;.&#39;, &#39;Second&#39;, &#39;,&#39;, &#39;some&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;only&#39;, &#39;if&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;pair&#39;, &#39;is&#39;, &#39;used&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;no&#39;, &#39;P&#39;, &#34;&#39;s&#34;, &#39;which&#39;, &#39;are&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;.&#39;, &#39;The&#39;, &#39;mesons&#39;, &#39;&#39;, &#39;and&#39;, &#39;&#39;, &#39;have&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;component&#39;, &#39;,&#39;, &#39;but&#39;, &#39;they&#39;, &#39;also&#39;, &#39;have&#39;, &#39;significant&#39;, &#39;(&#39;, &#39;uu&#39;, &#39;)&#39;, &#39;and&#39;, &#39;(&#39;, &#39;dd&#39;, &#39;)&#39;, &#39;pieces&#39;, &#39;.&#39;, &#39;As&#39;, &#39;a&#39;, &#39;result&#39;, &#39;the&#39;, &#39;bs&#39;, &#39;and&#39;, &#39;bd&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;not&#39;, &#39;really&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;involves&#39;, &#39;an&#39;, &#39;&#39;, &#39;or&#39;, &#39;&#39;, &#39;.&#39;, &#39;We&#39;, &#39;therefore&#39;, &#39;consider&#39;, &#39;instead&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;&#39;, &#39;which&#39;, &#39;is&#39;, &#39;essentially&#39;, &#39;a&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;state&#39;, &#39;.&#39;, &#39;Finally&#39;, &#39;,&#39;, &#39;we&#39;, &#39;require&#39;, &#39;that&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;be&#39;, &#39;able&#39;, &#39;to&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;, &#39;This&#39;, &#39;can&#39;, &#39;not&#39;, &#39;happen&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;contains&#39;, &#39;a&#39;, &#39;single&#39;, &#39;K0&#39;, &#39;(&#39;, &#39;or&#39;, &#39;K0&#39;, &#39;)&#39;, &#39;meson&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;it&#39;, &#39;can&#39;, &#39;occur&#39;, &#39;if&#39;, &#39;this&#39;, &#39;final-state&#39;, &#39;particle&#39;, &#39;is&#39;, &#39;an&#39;, &#39;excited&#39;, &#39;neutral&#39;, &#39;kaon&#39;, &#39;.&#39;, &#39;In&#39;, &#39;this&#39;, &#39;case&#39;, &#39;one&#39;, &#39;decay&#39;, &#39;involves&#39;, &#39;K*0&#39;, &#39;,&#39;, &#39;while&#39;, &#39;the&#39;, &#39;other&#39;, &#39;has&#39;, &#39;K*0&#39;, &#39;.&#39;, &#39;Assuming&#39;, &#39;that&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;is&#39;, &#39;detected&#39;, &#39;via&#39;, &#39;its&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;Ks0&#39;, &#39;(&#39;, &#39;as&#39;, &#39;in&#39;, &#39;the&#39;, &#39;measurement&#39;, &#39;of&#39;, &#39;sin2&#39;, &#39;via&#39;, &#39;Bd0&#39;, &#39;(&#39;, &#39;t&#39;, &#39;)&#39;, &#39;J/K*&#39;, &#39;)&#39;, &#39;,&#39;, &#39;then&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;can&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;same&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;, &#39;.&#39;]
[&#39;Table&#39;, &#39;1&#39;, &#39;lists&#39;, &#39;8&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;B&#39;, &#39;decays&#39;, &#39;.&#39;, &#39;In&#39;, &#39;fact&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;more&#39;, &#39;decay&#39;, &#39;pairs&#39;, &#39;,&#39;, &#39;since&#39;, &#39;many&#39;, &#39;of&#39;, &#39;the&#39;, &#39;particles&#39;, &#39;in&#39;, &#39;the&#39;, &#39;final&#39;, &#39;states&#39;, &#39;can&#39;, &#39;be&#39;, &#39;observed&#39;, &#39;as&#39;, &#39;either&#39;, &#39;pseudoscalar&#39;, &#39;(&#39;, &#39;P&#39;, &#39;)&#39;, &#39;or&#39;, &#39;vector&#39;, &#39;(&#39;, &#39;V&#39;, &#39;)&#39;, &#39;mesons&#39;, &#39;.&#39;, &#39;Note&#39;, &#39;that&#39;, &#39;certain&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;written&#39;, &#39;in&#39;, &#39;terms&#39;, &#39;of&#39;, &#39;VV&#39;, &#39;final&#39;, &#39;states&#39;, &#39;,&#39;, &#39;while&#39;, &#39;others&#39;, &#39;are&#39;, &#39;have&#39;, &#39;PP&#39;, &#39;states&#39;, &#39;.&#39;, &#39;There&#39;, &#39;are&#39;, &#39;three&#39;, &#39;reasons&#39;, &#39;for&#39;, &#39;this&#39;, &#39;.&#39;, &#39;First&#39;, &#39;,&#39;, &#39;some&#39;, &#39;decays&#39;, &#39;involve&#39;, &#39;a&#39;, &#39;final-state&#39;, &#39;0&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;experimentally&#39;, &#39;it&#39;, &#39;will&#39;, &#39;be&#39;, &#39;necessary&#39;, &#39;to&#39;, &#39;find&#39;, &#39;the&#39;, &#39;decay&#39;, &#39;vertices&#39;, &#39;of&#39;, &#39;the&#39;, &#39;final&#39;, &#39;particles&#39;, &#39;.&#39;, &#39;This&#39;, &#39;is&#39;, &#39;virtually&#39;, &#39;impossible&#39;, &#39;for&#39;, &#39;a&#39;, &#39;0&#39;, &#39;,&#39;, &#39;and&#39;, &#39;so&#39;, &#39;we&#39;, &#39;always&#39;, &#39;use&#39;, &#39;a&#39;, &#39;0&#39;, &#39;.&#39;, &#39;Second&#39;, &#39;,&#39;, &#39;some&#39;, &#39;pairs&#39;, &#39;of&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;only&#39;, &#39;if&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;pair&#39;, &#39;is&#39;, &#39;used&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;there&#39;, &#39;are&#39;, &#39;no&#39;, &#39;P&#39;, &#34;&#39;s&#34;, &#39;which&#39;, &#39;are&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;.&#39;, &#39;The&#39;, &#39;mesons&#39;, &#39;&#39;, &#39;and&#39;, &#39;&#39;, &#39;have&#39;, &#39;an&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;component&#39;, &#39;,&#39;, &#39;but&#39;, &#39;they&#39;, &#39;also&#39;, &#39;have&#39;, &#39;significant&#39;, &#39;(&#39;, &#39;uu&#39;, &#39;)&#39;, &#39;and&#39;, &#39;(&#39;, &#39;dd&#39;, &#39;)&#39;, &#39;pieces&#39;, &#39;.&#39;, &#39;As&#39;, &#39;a&#39;, &#39;result&#39;, &#39;the&#39;, &#39;bs&#39;, &#39;and&#39;, &#39;bd&#39;, &#39;decays&#39;, &#39;are&#39;, &#39;not&#39;, &#39;really&#39;, &#39;related&#39;, &#39;by&#39;, &#39;SU&#39;, &#39;(&#39;, &#39;3&#39;, &#39;)&#39;, &#39;in&#39;, &#39;the&#39;, &#39;SM&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;involves&#39;, &#39;an&#39;, &#39;&#39;, &#39;or&#39;, &#39;&#39;, &#39;.&#39;, &#39;We&#39;, &#39;therefore&#39;, &#39;consider&#39;, &#39;instead&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;&#39;, &#39;which&#39;, &#39;is&#39;, &#39;essentially&#39;, &#39;a&#39;, &#39;pure&#39;, &#39;(&#39;, &#39;ss&#39;, &#39;)&#39;, &#39;quark&#39;, &#39;state&#39;, &#39;.&#39;, &#39;Finally&#39;, &#39;,&#39;, &#39;we&#39;, &#39;require&#39;, &#39;that&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;be&#39;, &#39;able&#39;, &#39;to&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;, &#39;This&#39;, &#39;can&#39;, &#39;not&#39;, &#39;happen&#39;, &#39;if&#39;, &#39;the&#39;, &#39;final&#39;, &#39;state&#39;, &#39;contains&#39;, &#39;a&#39;, &#39;single&#39;, &#39;K0&#39;, &#39;(&#39;, &#39;or&#39;, &#39;K0&#39;, &#39;)&#39;, &#39;meson&#39;, &#39;.&#39;, &#39;However&#39;, &#39;,&#39;, &#39;it&#39;, &#39;can&#39;, &#39;occur&#39;, &#39;if&#39;, &#39;this&#39;, &#39;final-state&#39;, &#39;particle&#39;, &#39;is&#39;, &#39;an&#39;, &#39;excited&#39;, &#39;neutral&#39;, &#39;kaon&#39;, &#39;.&#39;, &#39;In&#39;, &#39;this&#39;, &#39;case&#39;, &#39;one&#39;, &#39;decay&#39;, &#39;involves&#39;, &#39;K&#39;, &#39;*&#39;, &#39;0&#39;, &#39;,&#39;, &#39;while&#39;, &#39;the&#39;, &#39;other&#39;, &#39;has&#39;, &#39;K&#39;, &#39;*&#39;, &#39;0&#39;, &#39;.&#39;, &#39;Assuming&#39;, &#39;that&#39;, &#39;the&#39;, &#39;vector&#39;, &#39;meson&#39;, &#39;is&#39;, &#39;detected&#39;, &#39;via&#39;, &#39;its&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;Ks0&#39;, &#39;(&#39;, &#39;as&#39;, &#39;in&#39;, &#39;the&#39;, &#39;measurement&#39;, &#39;of&#39;, &#39;sin2&#39;, &#39;via&#39;, &#39;Bd0&#39;, &#39;(&#39;, &#39;t&#39;, &#39;)&#39;, &#39;J/K&#39;, &#39;*&#39;, &#39;)&#39;, &#39;,&#39;, &#39;then&#39;, &#39;both&#39;, &#39;B0&#39;, &#39;and&#39;, &#39;B0&#39;, &#39;can&#39;, &#39;decay&#39;, &#39;to&#39;, &#39;the&#39;, &#39;same&#39;, &#39;final&#39;, &#39;state&#39;, &#39;.&#39;]

   DONE.

Same number of sentences and tag sequences: True
Size: 2402
Looking at some sentences randomly:
[(&#39;The&#39;, &#39;O&#39;), (&#39;effect&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;increasing&#39;, &#39;B_P&#39;), (&#39;direct&#39;, &#39;I_P&#39;), (&#39;solar&#39;, &#39;I_P&#39;), (&#39;radiation&#39;, &#39;I_P&#39;), (&#39;on&#39;, &#39;I_P&#39;), (&#39;both&#39;, &#39;I_P&#39;), (&#39;solar&#39;, &#39;I_P&#39;), (&#39;cells&#39;, &#39;I_P&#39;), (&#39;and&#39;, &#39;I_P&#39;), (&#39;water&#39;, &#39;I_P&#39;), (&#39;temperatures&#39;, &#39;L_P&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;shown&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;Fig&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;The&#39;, &#39;O&#39;), (&#39;first&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;these&#39;, &#39;O&#39;), (&#39;systems&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;biopolymer&#39;, &#39;B_P&#39;), (&#39;gel&#39;, &#39;L_P&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;involves&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;thermoreversible&#39;, &#39;B_T&#39;), (&#39;gelation&#39;, &#39;L_T&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;aqueous&#39;, &#39;O&#39;), (&#39;gelatin&#39;, &#39;O&#39;), (&#39;solutions&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;form&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;physical&#39;, &#39;O&#39;), (&#39;gel&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;whereas&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;other&#39;, &#39;O&#39;), (&#39;systems&#39;, &#39;O&#39;), (&#39;considered&#39;, &#39;O&#39;), (&#39;herein&#39;, &#39;O&#39;), (&#39;involve&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;formation&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;chemical&#39;, &#39;O&#39;), (&#39;gels&#39;, &#39;O&#39;), (&#39;featuring&#39;, &#39;O&#39;), (&#39;permanent&#39;, &#39;O&#39;), (&#39;cross-linked&#39;, &#39;B_P&#39;), (&#39;branching&#39;, &#39;I_P&#39;), (&#39;networks&#39;, &#39;L_P&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;The&#39;, &#39;O&#39;), (&#39;Schrdinger-electrostatic&#39;, &#39;B_P&#39;), (&#39;algorithm&#39;, &#39;L_P&#39;), (&#39;was&#39;, &#39;O&#39;), (&#39;propounded&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;further&#39;, &#39;O&#39;), (&#39;increase&#39;, &#39;O&#39;), (&#39;both&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;accuracy&#39;, &#39;O&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;alacrity&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;detecting&#39;, &#39;B_P&#39;), (&#39;natural&#39;, &#39;I_P&#39;), (&#39;phenomena&#39;, &#39;I_P&#39;), (&#39;.&#39;, &#39;L_P&#39;)]
[(&#39;The&#39;, &#39;O&#39;), (&#39;analysis&#39;, &#39;O&#39;), (&#39;relies&#39;, &#39;O&#39;), (&#39;essentially&#39;, &#39;O&#39;), (&#39;on&#39;, &#39;O&#39;), (&#39;some&#39;, &#39;O&#39;), (&#39;new&#39;, &#39;B_M&#39;), (&#39;regularity&#39;, &#39;I_M&#39;), (&#39;results&#39;, &#39;L_M&#39;), (&#39;of&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;multi-term&#39;, &#39;O&#39;), (&#39;time&#39;, &#39;O&#39;), (&#39;fractional&#39;, &#39;O&#39;), (&#39;diffusion&#39;, &#39;O&#39;), (&#39;equation&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;We&#39;, &#39;O&#39;), (&#39;show&#39;, &#39;O&#39;), (&#39;that&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;method&#39;, &#39;O&#39;), (&#39;can&#39;, &#39;O&#39;), (&#39;be&#39;, &#39;O&#39;), (&#39;applied&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;isogeometric&#39;, &#39;B_T&#39;), (&#39;analysis&#39;, &#39;L_T&#39;), (&#39;with&#39;, &#39;O&#39;), (&#39;little&#39;, &#39;O&#39;), (&#39;effort&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;once&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;framework&#39;, &#39;B_M&#39;), (&#39;of&#39;, &#39;I_M&#39;), (&#39;NURBS&#39;, &#39;I_M&#39;), (&#39;based&#39;, &#39;I_M&#39;), (&#39;shape&#39;, &#39;I_M&#39;), (&#39;functions&#39;, &#39;L_M&#39;), (&#39;has&#39;, &#39;O&#39;), (&#39;been&#39;, &#39;O&#39;), (&#39;implemented&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]


==== Validation dataset ====
Loading docs...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 50/50 [00:00&lt;00:00, 683.46it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Constructing sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 50/50 [00:00&lt;00:00, 368.20it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
   DONE.

Same number of sentences and tag sequences: True
Size: 413
Looking at some sentences randomly:
[(&#39;The&#39;, &#39;O&#39;), (&#39;four&#39;, &#39;O&#39;), (&#39;bounding&#39;, &#39;B_M&#39;), (&#39;PCM&#39;, &#39;I_M&#39;), (&#39;wastes&#39;, &#39;L_M&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;given&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;Table&#39;, &#39;O&#39;), (&#39;1&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;were&#39;, &#39;O&#39;), (&#39;simulated&#39;, &#39;O&#39;), (&#39;using&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;most&#39;, &#39;O&#39;), (&#39;appropriate&#39;, &#39;O&#39;), (&#39;materials&#39;, &#39;O&#39;), (&#39;and&#39;, &#39;O&#39;), (&#39;geometries&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;Between&#39;, &#39;O&#39;), (&#39;iterations&#39;, &#39;O&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;1000&#39;, &#39;O&#39;), (&#39;values&#39;, &#39;O&#39;), (&#39;acquired&#39;, &#39;O&#39;), (&#39;were&#39;, &#39;O&#39;), (&#39;averaged&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;obtain&#39;, &#39;B_T&#39;), (&#39;a&#39;, &#39;I_T&#39;), (&#39;single&#39;, &#39;I_T&#39;), (&#39;value&#39;, &#39;I_T&#39;), (&#39;of&#39;, &#39;I_T&#39;), (&#39;potential&#39;, &#39;L_T&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;subsequently&#39;, &#39;O&#39;), (&#39;saved&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;file&#39;, &#39;O&#39;), (&#39;used&#39;, &#39;O&#39;), (&#39;for&#39;, &#39;O&#39;), (&#39;later&#39;, &#39;O&#39;), (&#39;processing&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;A&#39;, &#39;O&#39;), (&#39;frequently&#39;, &#39;O&#39;), (&#39;employed&#39;, &#39;O&#39;), (&#39;surfactant&#39;, &#39;U_M&#39;), (&#39;was&#39;, &#39;O&#39;), (&#39;N-dodecylpyridinium&#39;, &#39;B_M&#39;), (&#39;bromide&#39;, &#39;L_M&#39;), (&#39;(&#39;, &#39;O&#39;), (&#39;DDPB&#39;, &#39;U_M&#39;), (&#39;)&#39;, &#39;O&#39;), (&#39;[&#39;, &#39;O&#39;), (&#39;9,60,61,108,109&#39;, &#39;O&#39;), (&#39;]&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;This&#39;, &#39;O&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;a&#39;, &#39;O&#39;), (&#39;further&#39;, &#39;O&#39;), (&#39;reason&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;adopt&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;CLSVOF&#39;, &#39;B_P&#39;), (&#39;method&#39;, &#39;L_P&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;which&#39;, &#39;O&#39;), (&#39;has&#39;, &#39;O&#39;), (&#39;been&#39;, &#39;O&#39;), (&#39;used&#39;, &#39;O&#39;), (&#39;for&#39;, &#39;O&#39;), (&#39;all&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;following&#39;, &#39;O&#39;), (&#39;simulations&#39;, &#39;B_T&#39;), (&#39;of&#39;, &#39;I_T&#39;), (&#39;liquid&#39;, &#39;I_T&#39;), (&#39;jet&#39;, &#39;I_T&#39;), (&#39;primary&#39;, &#39;I_T&#39;), (&#39;breakup&#39;, &#39;L_T&#39;), (&#39;.&#39;, &#39;O&#39;)]
[(&#39;Such&#39;, &#39;O&#39;), (&#39;outcome&#39;, &#39;O&#39;), (&#39;is&#39;, &#39;O&#39;), (&#39;probably&#39;, &#39;O&#39;), (&#39;related&#39;, &#39;O&#39;), (&#39;to&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;simplified&#39;, &#39;B_P&#39;), (&#39;contact&#39;, &#39;I_P&#39;), (&#39;model&#39;, &#39;L_P&#39;), (&#39;used&#39;, &#39;O&#39;), (&#39;by&#39;, &#39;O&#39;), (&#39;FM&#39;, &#39;U_P&#39;), (&#39;,&#39;, &#39;O&#39;), (&#39;which&#39;, &#39;O&#39;), (&#39;makes&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;stent-graft&#39;, &#39;B_P&#39;), (&#39;expansion&#39;, &#39;L_P&#39;), (&#39;terminate&#39;, &#39;O&#39;), (&#39;once&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;nodes&#39;, &#39;U_M&#39;), (&#39;come&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;O&#39;), (&#39;contact&#39;, &#39;O&#39;), (&#39;with&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;O&#39;), (&#39;vessel&#39;, &#39;B_M&#39;), (&#39;wall&#39;, &#39;L_M&#39;), (&#39;.&#39;, &#39;O&#39;)]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_tags_train_B</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B_T&#39;, &#39;I_T&#39;, &#39;I_T&#39;, &#39;I_T&#39;,
       &#39;L_T&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;,
       &#39;O&#39;], dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Train dataset ====&quot;</span><span class="p">)</span>
<span class="n">train_sentences_X</span><span class="p">,</span> <span class="n">train_attention_masks</span><span class="p">,</span> <span class="n">train_tags_tokenized_B</span> <span class="o">=</span> <span class="n">get_final_data</span><span class="p">(</span><span class="n">all_sentences_train</span><span class="p">,</span> <span class="n">all_tags_train_B</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==== Validation dataset ====&quot;</span><span class="p">)</span>
<span class="n">val_sentences_X</span><span class="p">,</span> <span class="n">val_attention_masks</span><span class="p">,</span> <span class="n">val_tags_tokenized_B</span> <span class="o">=</span> <span class="n">get_final_data</span><span class="p">(</span><span class="n">all_sentences_val</span><span class="p">,</span> <span class="n">all_tags_val_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>==== Train dataset ====
Adapting tags to BERT tokenizer...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 2402/2402 [00:06&lt;00:00, 369.29it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.
Applying BERT tokenizer to the sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 2402/2402 [00:03&lt;00:00, 735.82it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Looking at some sentences randomly:
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;conversely&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;versa&#39;, &#39;B_P&#39;, 1), (&#39;##tility&#39;, &#39;-N-&#39;, 1), (&#39;of&#39;, &#39;I_P&#39;, 1), (&#39;simplified&#39;, &#39;I_P&#39;, 1), (&#39;(&#39;, &#39;I_P&#39;, 1), (&#39;approximate&#39;, &#39;I_P&#39;, 1), (&#39;)&#39;, &#39;I_P&#39;, 1), (&#39;methods&#39;, &#39;L_P&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;such&#39;, &#39;O&#39;, 1), (&#39;as&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;interaction&#39;, &#39;B_P&#39;, 1), (&#39;factor&#39;, &#39;I_P&#39;, 1), (&#39;approach&#39;, &#39;L_P&#39;, 1), (&#39;that&#39;, &#39;O&#39;, 1), (&#39;allows&#39;, &#39;O&#39;, 1), (&#39;capturing&#39;, &#39;B_P&#39;, 1), (&#39;the&#39;, &#39;I_P&#39;, 1), (&#39;(&#39;, &#39;I_P&#39;, 1), (&#39;e&#39;, &#39;I_P&#39;, 1), (&#39;.&#39;, &#39;-N-&#39;, 1), (&#39;g&#39;, &#39;-N-&#39;, 1), (&#39;.&#39;, &#39;-N-&#39;, 1), (&#39;,&#39;, &#39;I_P&#39;, 1), (&#39;vertical&#39;, &#39;I_P&#39;, 1), (&#39;)&#39;, &#39;I_P&#39;, 1), (&#39;displacement&#39;, &#39;I_P&#39;, 1), (&#39;##s&#39;, &#39;-N-&#39;, 1), (&#39;of&#39;, &#39;I_P&#39;, 1), (&#39;any&#39;, &#39;I_P&#39;, 1), (&#39;general&#39;, &#39;I_P&#39;, 1), (&#39;pile&#39;, &#39;I_P&#39;, 1), (&#39;group&#39;, &#39;L_P&#39;, 1), (&#39;by&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;analysis&#39;, &#39;B_P&#39;, 1), (&#39;of&#39;, &#39;I_P&#39;, 1), (&#39;the&#39;, &#39;I_P&#39;, 1), (&#39;displacement&#39;, &#39;I_P&#39;, 1), (&#39;interaction&#39;, &#39;I_P&#39;, 1), (&#39;between&#39;, &#39;I_P&#39;, 1), (&#39;two&#39;, &#39;I_P&#39;, 1), (&#39;identical&#39;, &#39;I_P&#39;, 1), (&#39;piles&#39;, &#39;L_P&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;by&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;use&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;elastic&#39;, &#39;B_P&#39;, 1), (&#39;principle&#39;, &#39;I_P&#39;, 1), (&#39;of&#39;, &#39;I_P&#39;, 1), (&#39;super&#39;, &#39;I_P&#39;, 1), (&#39;##position&#39;, &#39;-N-&#39;, 1), (&#39;of&#39;, &#39;I_P&#39;, 1), (&#39;effects&#39;, &#39;L_P&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;makes&#39;, &#39;O&#39;, 1), (&#39;them&#39;, &#39;O&#39;, 1), (&#39;attractive&#39;, &#39;O&#39;, 1), (&#39;as&#39;, &#39;O&#39;, 1), (&#39;design&#39;, &#39;B_M&#39;, 1), (&#39;tools&#39;, &#39;L_M&#39;, 1), (&#39;because&#39;, &#39;O&#39;, 1), (&#39;they&#39;, &#39;O&#39;, 1), (&#39;allow&#39;, &#39;O&#39;, 1), (&#39;for&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;use&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;ex&#39;, &#39;B_T&#39;, 1), (&#39;##ped&#39;, &#39;-N-&#39;, 1), (&#39;##ient&#39;, &#39;-N-&#39;, 1), (&#39;para&#39;, &#39;I_T&#39;, 1), (&#39;##metric&#39;, &#39;-N-&#39;, 1), (&#39;studies&#39;, &#39;L_T&#39;, 1), (&#39;under&#39;, &#39;O&#39;, 1), (&#39;various&#39;, &#39;O&#39;, 1), (&#39;design&#39;, &#39;O&#39;, 1), (&#39;conditions&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;for&#39;, &#39;O&#39;, 1), (&#39;d&#39;, &#39;U_M&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;me&#39;, &#39;-N-&#39;, 1), (&#39;##sons&#39;, &#39;-N-&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;we&#39;, &#39;O&#39;, 1), (&#39;found&#39;, &#39;O&#39;, 1), (&#39;that&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;difference&#39;, &#39;B_P&#39;, 1), (&#39;in&#39;, &#39;I_P&#39;, 1), (&#39;the&#39;, &#39;I_P&#39;, 1), (&#39;slope&#39;, &#39;I_P&#39;, 1), (&#39;parameters&#39;, &#39;L_P&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;pt&#39;, &#39;U_T&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;spectra&#39;, &#39;-N-&#39;, 1), (&#39;in&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;two&#39;, &#39;O&#39;, 1), (&#39;scenarios&#39;, &#39;O&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;less&#39;, &#39;O&#39;, 1), (&#39;pronounced&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;but&#39;, &#39;O&#39;, 1), (&#39;their&#39;, &#39;O&#39;, 1), (&#39;elliptic&#39;, &#39;B_P&#39;, 1), (&#39;flow&#39;, &#39;L_P&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;about&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;factor&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;2&#39;, &#39;O&#39;, 1), (&#39;larger&#39;, &#39;O&#39;, 1), (&#39;for&#39;, &#39;O&#39;, 1), (&#39;[UNK]&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;-N-&#39;, 1), (&#39;5&#39;, &#39;-N-&#39;, 1), (&#39;ge&#39;, &#39;O&#39;, 1), (&#39;##v&#39;, &#39;-N-&#39;, 1), (&#39;in&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;thermal&#39;, &#39;O&#39;, 1), (&#39;##ized&#39;, &#39;-N-&#39;, 1), (&#39;case&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;algorithm&#39;, &#39;O&#39;, 1), (&#39;used&#39;, &#39;O&#39;, 1), (&#39;by&#39;, &#39;O&#39;, 1), (&#39;us&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;evaluate&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;k&#39;, &#39;O&#39;, 1), (&#39;##rat&#39;, &#39;-N-&#39;, 1), (&#39;##ky&#39;, &#39;-N-&#39;, 1), (&#39;plots&#39;, &#39;O&#39;, 1), (&#39;by&#39;, &#39;O&#39;, 1), (&#39;sets&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;parallel&#39;, &#39;O&#39;, 1), (&#39;polymer&#39;, &#39;O&#39;, 1), (&#39;stems&#39;, &#39;O&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;very&#39;, &#39;O&#39;, 1), (&#39;simplified&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;patterned&#39;, &#39;B_M&#39;, 1), (&#39;hydro&#39;, &#39;I_M&#39;, 1), (&#39;##gel&#39;, &#39;-N-&#39;, 1), (&#39;films&#39;, &#39;L_M&#39;, 1), (&#39;can&#39;, &#39;O&#39;, 1), (&#39;be&#39;, &#39;O&#39;, 1), (&#39;triggered&#39;, &#39;B_P&#39;, 1), (&#39;consecutive&#39;, &#39;L_P&#39;, 1), (&#39;##ly&#39;, &#39;-N-&#39;, 1), (&#39;allowing&#39;, &#39;O&#39;, 1), (&#39;for&#39;, &#39;O&#39;, 1), (&#39;successive&#39;, &#39;O&#39;, 1), (&#39;rolling&#39;, &#39;U_P&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;un&#39;, &#39;U_P&#39;, 1), (&#39;##roll&#39;, &#39;-N-&#39;, 1), (&#39;##ing&#39;, &#39;-N-&#39;, 1), (&#39;depending&#39;, &#39;O&#39;, 1), (&#39;on&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;B_M&#39;, 1), (&#39;##que&#39;, &#39;-N-&#39;, 1), (&#39;##ous&#39;, &#39;-N-&#39;, 1), (&#39;ph&#39;, &#39;L_M&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;measurements&#39;, &#39;O&#39;, 1), (&#39;were&#39;, &#39;O&#39;, 1), (&#39;carried&#39;, &#39;O&#39;, 1), (&#39;out&#39;, &#39;O&#39;, 1), (&#39;under&#39;, &#39;O&#39;, 1), (&#39;an&#39;, &#39;O&#39;, 1), (&#39;ar&#39;, &#39;U_M&#39;, 1), (&#39;##gon&#39;, &#39;-N-&#39;, 1), (&#39;atmosphere&#39;, &#39;O&#39;, 1), (&#39;(&#39;, &#39;O&#39;, 1), (&#39;with&#39;, &#39;O&#39;, 1), (&#39;an&#39;, &#39;O&#39;, 1), (&#39;oxygen&#39;, &#39;U_M&#39;, 1), (&#39;content&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;7&#39;, &#39;O&#39;, 1), (&#39;pp&#39;, &#39;O&#39;, 1), (&#39;##m&#39;, &#39;-N-&#39;, 1), (&#39;)&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;using&#39;, &#39;O&#39;, 1), (&#39;pure&#39;, &#39;O&#39;, 1), (&#39;platinum&#39;, &#39;B_M&#39;, 1), (&#39;ing&#39;, &#39;L_M&#39;, 1), (&#39;##ots&#39;, &#39;-N-&#39;, 1), (&#39;(&#39;, &#39;O&#39;, 1), (&#39;64&#39;, &#39;O&#39;, 1), (&#39;&#39;, &#39;-N-&#39;, 1), (&#39;144&#39;, &#39;-N-&#39;, 1), (&#39;mg&#39;, &#39;O&#39;, 1), (&#39;)&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;99&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;-N-&#39;, 1), (&#39;95&#39;, &#39;-N-&#39;, 1), (&#39;at&#39;, &#39;O&#39;, 1), (&#39;%&#39;, &#39;O&#39;, 1), (&#39;purity&#39;, &#39;O&#39;, 1), (&#39;as&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;reference&#39;, &#39;B_M&#39;, 1), (&#39;material&#39;, &#39;L_M&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]


==== Validation dataset ====
Adapting tags to BERT tokenizer...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 413/413 [00:01&lt;00:00, 376.95it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.
Applying BERT tokenizer to the sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 413/413 [00:00&lt;00:00, 791.49it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Looking at some sentences randomly:
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;this&#39;, &#39;O&#39;, 1), (&#39;approach&#39;, &#39;O&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;helpful&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;but&#39;, &#39;O&#39;, 1), (&#39;it&#39;, &#39;O&#39;, 1), (&#39;might&#39;, &#39;O&#39;, 1), (&#39;be&#39;, &#39;O&#39;, 1), (&#39;extended&#39;, &#39;O&#39;, 1), (&#39;further&#39;, &#39;O&#39;, 1), (&#39;by&#39;, &#39;O&#39;, 1), (&#39;modelling&#39;, &#39;B_P&#39;, 1), (&#39;proximity&#39;, &#39;I_P&#39;, 1), (&#39;across&#39;, &#39;I_P&#39;, 1), (&#39;flows&#39;, &#39;L_P&#39;, 1), (&#39;through&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;distance&#39;, &#39;O&#39;, 1), (&#39;that&#39;, &#39;O&#39;, 1), (&#39;would&#39;, &#39;O&#39;, 1), (&#39;relate&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;flow&#39;, &#39;U_P&#39;, 1), (&#39;characteristics&#39;, &#39;O&#39;, 1), (&#39;in&#39;, &#39;O&#39;, 1), (&#39;order&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;borrow&#39;, &#39;O&#39;, 1), (&#39;strength&#39;, &#39;O&#39;, 1), (&#39;across&#39;, &#39;O&#39;, 1), (&#39;cal&#39;, &#39;O&#39;, 1), (&#39;##ib&#39;, &#39;-N-&#39;, 1), (&#39;##rations&#39;, &#39;-N-&#39;, 1), (&#39;instead&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;splitting&#39;, &#39;B_P&#39;, 1), (&#39;the&#39;, &#39;I_P&#39;, 1), (&#39;cal&#39;, &#39;I_P&#39;, 1), (&#39;##ib&#39;, &#39;-N-&#39;, 1), (&#39;##rations&#39;, &#39;-N-&#39;, 1), (&#39;and&#39;, &#39;I_P&#39;, 1), (&#39;then&#39;, &#39;I_P&#39;, 1), (&#39;merging&#39;, &#39;I_P&#39;, 1), (&#39;the&#39;, &#39;I_P&#39;, 1), (&#39;outcomes&#39;, &#39;L_P&#39;, 1), (&#39;afterwards&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;this&#39;, &#39;O&#39;, 1), (&#39;method&#39;, &#39;O&#39;, 1), (&#39;leads&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;solution&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;perhaps&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;most&#39;, &#39;O&#39;, 1), (&#39;known&#39;, &#39;O&#39;, 1), (&#39;test&#39;, &#39;O&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;case&#39;, &#39;-N-&#39;, 1), (&#39;that&#39;, &#39;O&#39;, 1), (&#39;exhibits&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;first&#39;, &#39;B_P&#39;, 1), (&#39;order&#39;, &#39;I_P&#39;, 1), (&#39;phase&#39;, &#39;I_P&#39;, 1), (&#39;transition&#39;, &#39;L_P&#39;, 1), (&#39;(&#39;, &#39;O&#39;, 1), (&#39;semi&#39;, &#39;O&#39;, 1), (&#39;-&#39;, &#39;-N-&#39;, 1), (&#39;he&#39;, &#39;-N-&#39;, 1), (&#39;##uri&#39;, &#39;-N-&#39;, 1), (&#39;##stic&#39;, &#39;-N-&#39;, 1), (&#39;##ally&#39;, &#39;-N-&#39;, 1), (&#39;described&#39;, &#39;O&#39;, 1), (&#39;)&#39;, &#39;O&#39;, 1), (&#39;such&#39;, &#39;O&#39;, 1), (&#39;as&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;van&#39;, &#39;B_P&#39;, 1), (&#39;der&#39;, &#39;I_P&#39;, 1), (&#39;wa&#39;, &#39;I_P&#39;, 1), (&#39;##als&#39;, &#39;-N-&#39;, 1), (&#39;model&#39;, &#39;L_P&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;major&#39;, &#39;O&#39;, 1), (&#39;deficiency&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;mor&#39;, &#39;B_P&#39;, 1), (&#39;##l&#39;, &#39;-N-&#39;, 1), (&#39;potential&#39;, &#39;L_P&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;that&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;cat&#39;, &#39;U_M&#39;, 1), (&#39;##ion&#39;, &#39;-N-&#39;, 1), (&#39;defect&#39;, &#39;O&#39;, 1), (&#39;energies&#39;, &#39;O&#39;, 1), (&#39;are&#39;, &#39;O&#39;, 1), (&#39;high&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;hence&#39;, &#39;O&#39;, 1), (&#39;the&#39;, &#39;O&#39;, 1), (&#39;number&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;cat&#39;, &#39;U_M&#39;, 1), (&#39;##ion&#39;, &#39;-N-&#39;, 1), (&#39;defects&#39;, &#39;O&#39;, 1), (&#39;will&#39;, &#39;O&#39;, 1), (&#39;be&#39;, &#39;O&#39;, 1), (&#39;under&#39;, &#39;O&#39;, 1), (&#39;##est&#39;, &#39;-N-&#39;, 1), (&#39;##imated&#39;, &#39;-N-&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;also&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;{&#39;, &#39;O&#39;, 1), (&#39;&#39;, &#39;O&#39;, 1), (&#39;##n&#39;, &#39;-N-&#39;, 1), (&#39;}&#39;, &#39;O&#39;, 1), (&#39;n&#39;, &#39;O&#39;, 1), (&#39;##&#39;, &#39;-N-&#39;, 1), (&#39;##in&#39;, &#39;-N-&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;constructed&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;be&#39;, &#39;O&#39;, 1), (&#39;orthogonal&#39;, &#39;O&#39;, 1), (&#39;with&#39;, &#39;O&#39;, 1), (&#39;respect&#39;, &#39;O&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;l&#39;, &#39;O&#39;, 1), (&#39;##r&#39;, &#39;-N-&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;not&#39;, &#39;O&#39;, 1), (&#39;l&#39;, &#39;O&#39;, 1), (&#39;##q&#39;, &#39;-N-&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
[(&#39;CLS&#39;, &#39;-N-&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;significant&#39;, &#39;O&#39;, 1), (&#39;draw&#39;, &#39;O&#39;, 1), (&#39;##back&#39;, &#39;-N-&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;for&#39;, &#39;O&#39;, 1), (&#39;either&#39;, &#39;O&#39;, 1), (&#39;approach&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;is&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;dependence&#39;, &#39;O&#39;, 1), (&#39;on&#39;, &#39;O&#39;, 1), (&#39;a&#39;, &#39;O&#39;, 1), (&#39;supply&#39;, &#39;O&#39;, 1), (&#39;of&#39;, &#39;O&#39;, 1), (&#39;en&#39;, &#39;B_M&#39;, 1), (&#39;##ant&#39;, &#39;-N-&#39;, 1), (&#39;##io&#39;, &#39;-N-&#39;, 1), (&#39;##pur&#39;, &#39;-N-&#39;, 1), (&#39;##e&#39;, &#39;-N-&#39;, 1), (&#39;re&#39;, &#39;I_M&#39;, 1), (&#39;##age&#39;, &#39;-N-&#39;, 1), (&#39;##nts&#39;, &#39;-N-&#39;, 1), (&#39;or&#39;, &#39;I_M&#39;, 1), (&#39;substrates&#39;, &#39;L_M&#39;, 1), (&#39;&#39;, &#39;O&#39;, 1), (&#39;synthesis&#39;, &#39;B_P&#39;, 1), (&#39;routes&#39;, &#39;L_P&#39;, 1), (&#39;generally&#39;, &#39;O&#39;, 1), (&#39;ut&#39;, &#39;O&#39;, 1), (&#39;##ilis&#39;, &#39;-N-&#39;, 1), (&#39;##e&#39;, &#39;-N-&#39;, 1), (&#39;chi&#39;, &#39;B_M&#39;, 1), (&#39;##ral&#39;, &#39;-N-&#39;, 1), (&#39;building&#39;, &#39;I_M&#39;, 1), (&#39;blocks&#39;, &#39;L_M&#39;, 1), (&#39;or&#39;, &#39;O&#39;, 1), (&#39;en&#39;, &#39;B_M&#39;, 1), (&#39;##ant&#39;, &#39;-N-&#39;, 1), (&#39;##ios&#39;, &#39;-N-&#39;, 1), (&#39;##ele&#39;, &#39;-N-&#39;, 1), (&#39;##ctive&#39;, &#39;-N-&#39;, 1), (&#39;catalyst&#39;, &#39;L_M&#39;, 1), (&#39;##s&#39;, &#39;-N-&#39;, 1), (&#39;[&#39;, &#39;O&#39;, 1), (&#39;7&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;-N-&#39;, 1), (&#39;8&#39;, &#39;-N-&#39;, 1), (&#39;]&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;O&#39;, 1), (&#39;while&#39;, &#39;O&#39;, 1), (&#39;en&#39;, &#39;B_P&#39;, 1), (&#39;##ant&#39;, &#39;-N-&#39;, 1), (&#39;##iom&#39;, &#39;-N-&#39;, 1), (&#39;##er&#39;, &#39;-N-&#39;, 1), (&#39;separation&#39;, &#39;I_P&#39;, 1), (&#39;techniques&#39;, &#39;L_P&#39;, 1), (&#39;typically&#39;, &#39;O&#39;, 1), (&#39;incorporate&#39;, &#39;O&#39;, 1), (&#39;chi&#39;, &#39;B_M&#39;, 1), (&#39;##ral&#39;, &#39;-N-&#39;, 1), (&#39;selector&#39;, &#39;I_M&#39;, 1), (&#39;molecules&#39;, &#39;L_M&#39;, 1), (&#39;to&#39;, &#39;O&#39;, 1), (&#39;form&#39;, &#39;O&#39;, 1), (&#39;chemical&#39;, &#39;O&#39;, 1), (&#39;##ly&#39;, &#39;-N-&#39;, 1), (&#39;distinct&#39;, &#39;O&#39;, 1), (&#39;and&#39;, &#39;O&#39;, 1), (&#39;distinguish&#39;, &#39;O&#39;, 1), (&#39;##able&#39;, &#39;-N-&#39;, 1), (&#39;dia&#39;, &#39;B_M&#39;, 1), (&#39;##ster&#39;, &#39;-N-&#39;, 1), (&#39;##eo&#39;, &#39;-N-&#39;, 1), (&#39;##meric&#39;, &#39;-N-&#39;, 1), (&#39;complexes&#39;, &#39;L_M&#39;, 1), (&#39;[&#39;, &#39;O&#39;, 1), (&#39;8&#39;, &#39;O&#39;, 1), (&#39;,&#39;, &#39;-N-&#39;, 1), (&#39;9&#39;, &#39;-N-&#39;, 1), (&#39;]&#39;, &#39;O&#39;, 1), (&#39;.&#39;, &#39;O&#39;, 1), (&#39;SEP&#39;, &#39;-N-&#39;, 1), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0), (&#39;PAD&#39;, &#39;-N-&#39;, 0)]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Map each unique label to an integer.</span>
<span class="c1"># label_map = {&#39;N&#39;:-100} # we don&#39;t keep that to be able to apply one_hot encoding for custom BERT</span>
<span class="n">label_map_B</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># For each label...</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">tag</span> <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">train_tags_tokenized_B</span> <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">L</span><span class="p">])):</span>
    
    <span class="c1"># Map it to its integer.</span>
    <span class="n">label_map_B</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">label_map_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;U_P&#39;: 0, &#39;I_P&#39;: 1, &#39;U_T&#39;: 2, &#39;U_M&#39;: 3, &#39;B_P&#39;: 4, &#39;O&#39;: 5, &#39;I_T&#39;: 6, &#39;L_T&#39;: 7, &#39;I_M&#39;: 8, &#39;B_M&#39;: 9, &#39;B_T&#39;: 10, &#39;-N-&#39;: 11, &#39;L_M&#39;: 12, &#39;L_P&#39;: 13}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_new_labels_B</span> <span class="o">=</span> <span class="p">[[</span><span class="n">label_map_B</span><span class="p">[</span><span class="n">elt</span><span class="p">]</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="n">L</span><span class="p">]</span> <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">train_tags_tokenized_B</span><span class="p">]</span>
<span class="n">val_new_labels_B</span> <span class="o">=</span> <span class="p">[[</span><span class="n">label_map_B</span><span class="p">[</span><span class="n">elt</span><span class="p">]</span> <span class="k">for</span> <span class="n">elt</span> <span class="ow">in</span> <span class="n">L</span><span class="p">]</span> <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">val_tags_tokenized_B</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataloader_B</span> <span class="o">=</span> <span class="n">get_data_loader</span><span class="p">(</span><span class="n">train_sentences_X</span><span class="p">,</span> <span class="n">train_attention_masks</span><span class="p">,</span> <span class="n">train_new_labels_B</span><span class="p">,</span> <span class="n">RandomSampler</span><span class="p">)</span>
<span class="n">validation_dataloader_B</span> <span class="o">=</span> <span class="n">get_data_loader</span><span class="p">(</span><span class="n">val_sentences_X</span><span class="p">,</span> <span class="n">val_attention_masks</span><span class="p">,</span> <span class="n">val_new_labels_B</span><span class="p">,</span> <span class="n">SequentialSampler</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model = get_BertForTokenClassification(label_map_B)</span>
<span class="c1"># model.cuda()</span>
<span class="c1"># train_model(model, train_dataloader_B, 5)</span>
<span class="n">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validation_dataloader_B</span><span class="p">,</span> <span class="n">label_map_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 26/26 [00:10&lt;00:00,  2.58it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>f1 micro: 0.811
Accuracy: 0.811
[[  44    4    0   13    4   18    1    0    0    0    3    0    0    1]
 [   3  218    0    3   15  124   41    2   14    9    1    0    2   17]
 [   4    0    0    0    1    3    0    1    0    0    0    0    0    0]
 [   9    7    0  155   14   31    5    3    6   13    3    3   10    5]
 [   2   18    0    0  201   60   15    0    2   15   17    1    0    0]
 [  27  241    0   12  122 7457  111   28   60   56   42   14   50  120]
 [   0   43    0    0   23  145  192    8    1    6   20    0    3    8]
 [   1    1    0    1    0   15    7   60    0    0    0    0    5   36]
 [   0   20    0    0    1   19    4    0  106   15    0    1    7    1]
 [   0    5    0    8   23   25    6    0   10  160    0    0    0    0]
 [   0    2    0    0   28   43    3    0    0    1   49    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    2    0   19    3    3    1    1    0    0  187   21]
 [   2    3    0    5    1   56    5   21    1    0    0    0   17  220]]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.810769644297106</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_sentences_test</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_doc_sentences</span><span class="p">(</span><span class="n">get_text_docs</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">),</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">test_sentences</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading docs...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 100/100 [00:17&lt;00:00,  5.84it/s]
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

Constructing sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 100/100 [00:00&lt;00:00, 373.35it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
   DONE.

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_sentences_X</span><span class="p">,</span> <span class="n">test_attention_masks</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_final_data</span><span class="p">(</span><span class="n">all_sentences_test</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Applying BERT tokenizer to the sentences...
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 829/829 [00:01&lt;00:00, 771.36it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>   DONE.

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">get_data_loader</span><span class="p">(</span><span class="n">test_sentences_X</span><span class="p">,</span> <span class="n">test_attention_masks</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">SequentialSampler</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Prediction on test set</span>

<span class="c1"># Put model in evaluation mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Tracking variables </span>
<span class="n">predictions_test</span> <span class="p">,</span> <span class="n">true_labels_test</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="c1"># Predict </span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
  <span class="c1"># Add batch to GPU</span>
  <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>

  <span class="c1"># Unpack the inputs from our dataloader</span>
  <span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span> <span class="o">=</span> <span class="n">batch</span>
  
  <span class="c1"># Telling the model not to compute or store gradients, saving memory and </span>
  <span class="c1"># speeding up prediction</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="c1"># Forward pass, calculate logit predictions</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">BertCustom</span><span class="p">):</span>
        <span class="n">logits</span><span class="p">,</span><span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> <span class="n">b_input_mask</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> 
                      <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                      <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span>
                      <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">logits</span>

  <span class="c1"># Move logits and labels to CPU</span>
  <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">label_ids</span> <span class="o">=</span> <span class="n">b_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  
  <span class="c1"># Store predictions and true labels</span>
  <span class="n">predictions_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
  <span class="n">true_labels_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;    DONE.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 52/52 [00:20&lt;00:00,  2.57it/s]</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>    DONE.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_predictions_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">predicted_label_ids_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">all_predictions_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">predicted_label_ids_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predicted_label_ids_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">index_map_B</span> <span class="o">=</span> <span class="p">{</span><span class="n">value</span><span class="p">:</span> <span class="n">key</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">value</span> <span class="ow">in</span> <span class="n">label_map_B</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">index_map_B</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{0: &#39;U_P&#39;,
 1: &#39;I_P&#39;,
 2: &#39;U_T&#39;,
 3: &#39;U_M&#39;,
 4: &#39;B_P&#39;,
 5: &#39;O&#39;,
 6: &#39;I_T&#39;,
 7: &#39;L_T&#39;,
 8: &#39;I_M&#39;,
 9: &#39;B_M&#39;,
 10: &#39;B_T&#39;,
 11: &#39;-N-&#39;,
 12: &#39;L_M&#39;,
 13: &#39;L_P&#39;}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_df_soumission</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DocID&#39;</span><span class="p">,</span> <span class="s1">&#39;Token&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test_df_soumission</span> <span class="o">=</span> <span class="n">test_df_soumission</span><span class="o">.</span><span class="n">astype</span><span class="p">({</span><span class="s1">&#39;Tag&#39;</span><span class="p">:</span> <span class="s1">&#39;string&#39;</span><span class="p">})</span>

<span class="n">clean_tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">clean_predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predicted_label_ids_test</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_sentences_X</span><span class="p">)):</span>
  <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">cls_token_id</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sep_token_id</span><span class="p">):</span>
    <span class="n">clean_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">index_map_B</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span> <span class="o">==</span> <span class="n">null_tag</span><span class="p">:</span>
      <span class="n">clean_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;O&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">clean_predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index_map_B</span><span class="p">[</span><span class="n">pred</span><span class="p">])</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">word_id</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_sentences_test</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ids</span><span class="p">)))):</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">test_df_soumission</span><span class="p">[</span><span class="n">test_df_soumission</span><span class="p">[</span><span class="s2">&quot;TokenID&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">word_id</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">test_df_soumission</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="s2">&quot;Tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clean_predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">i</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 21711/21711 [00:47&lt;00:00, 452.89it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_df_soumission</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TokenID</th>
      <th>Tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S0885230816301759-0</td>
      <td>O</td>
    </tr>
    <tr>
      <th>1</th>
      <td>S0885230816301759-1</td>
      <td>O</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S0885230816301759-2</td>
      <td>O</td>
    </tr>
    <tr>
      <th>3</th>
      <td>S0885230816301759-3</td>
      <td>O</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S0885230816301759-4</td>
      <td>B_P</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>21706</th>
      <td>S1877750313001269-211</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21707</th>
      <td>S1877750313001269-212</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21708</th>
      <td>S1877750313001269-213</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21709</th>
      <td>S1877750313001269-214</td>
      <td>O</td>
    </tr>
    <tr>
      <th>21710</th>
      <td>S1877750313001269-215</td>
      <td>O</td>
    </tr>
  </tbody>
</table>
<p>21711 rows  2 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_df_soumission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;submission_test_B_bert.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="7.3.Conclusion-(5%)">7.3.Conclusion (5%)<a class="anchor-link" href="#7.3.Conclusion-(5%)">&#182;</a></h1><p>Indiquez, dans une cellule, vos conclusions sur la tche : quest-ce qui fonctionne ? quest-ce qui ne fonctionne pas ? quel type de pr-traitement vous a donn les meilleurs rsultats ? quelles architectures ?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finalement, pour la tache A c'est le modle BERT qui nous donnes les meilleurs rsultats. Le modle Bilstm-CRF et CRF nous des rsultats corrected qui dpassent un simple algorithme qui prdirait que des 'O'. Pour la tache B c'est le Bilstm-CRF qui nous donne les meilleurs rsultats.</p>
<p>En ce qui concerne le CRF que ce soit pour la tache A ou B, ce modle ne prend pas en compte le dsquilibre du jeu de donne et rsulte en des f1 score mdiocres pour les autre labels.</p>
<p>En ce qui concerne de Bilstm-CRF, pour la tache A et B, le modle perfome mieux avec Glove, de plus utiliser un layer bilstm donne des meilleurs rsultats pour la tache A mais pour la tache B c'est le GRU layer qui donne de meilleurs rsultats.</p>
<p>Enfin pour le BERT, ce dernier perfome trs bien pour la tache A  mais nous n'avons pas eu d'aussi bon rsultat pour la tache B, en effet on a obtenu un score de 70% sur kaggle sur les donnes de test. Peut tre est ce qu  une erreur d'implmentation.</p>
<p>Pour Bert, nous avons d'abord utiliser l'approche classique BertForTokenClassification. Puis nous avons tent de trouver des mta-paramtres plus adapts  notre problme en variant les mthodes d'aggregation des sous couches les plus hautes pour obtenir le vecteur  passer au rseau  ajuster. Malheuresement aucune structure que nous avons test ne nous a permis d'obtenir de meilleurs rsultats que le BertForTokenClassification.<br>
Cette architecture nous a permis d'obtenir de bons rsultats sur la tache A avec plus de 82% en f1 score sur le validation set mais malheuresement de moins bon resultats sur la tache B, en effet on a obtenu un score de 70% sur kaggle sur les donnes de test. Nous aurions pu essayer d'autres approche pour palier au manque de donnes de certaines classes. Peut tre est ce qu  une erreur d'implmentation.<br>
On aurait aussi pu essayer d'utiliser ds architectures de transformers plus puissantes telles que RoBERTa</p>
<p>Finalement, avec plus de temps nous aurions voulus tester d'autres embeddings pour le bilstm-CRF comme le Elmo embedding. Nous aurions voulu tester le state of the art CNN-Bistlm-CRF qui consistait en crer un embedding des caractres  l'aide de CNN. Et enfin une autr ide tait de combiner Bert et CRF.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 

<script type="application/vnd.jupyter.widget-state+json">
{"bf16cec6e7de49dda8d258405b7eae02": {"model_module": "@jupyter-widgets/controls", "state": {"_view_name": "StyleView", "_model_name": "DescriptionStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "_model_module": "@jupyter-widgets/controls"}, "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0"}, "63c546fa1d2b48dbb3f73ef19348d80e": {"model_module": "@jupyter-widgets/base", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "width": null, "grid_row": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "overflow_x": null, "max_height": null, "align_content": null, "visibility": null, "overflow": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "overflow_y": null, "max_width": null, "display": null, "_view_module_version": "1.2.0", "align_self": null, "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "order": null, "left": null}, "model_name": "LayoutModel", "model_module_version": "1.2.0"}, "6a6da3cd54314b0a8dde1200fb2ba6a4": {"model_module": "@jupyter-widgets/base", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "width": null, "grid_row": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "overflow_x": null, "max_height": null, "align_content": null, "visibility": null, "overflow": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "overflow_y": null, "max_width": null, "display": null, "_view_module_version": "1.2.0", "align_self": null, "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "order": null, "left": null}, "model_name": "LayoutModel", "model_module_version": "1.2.0"}, "24dee2ed298e466b8b9cdc1afe66b729": {"model_module": "@jupyter-widgets/controls", "state": {"_view_name": "HBoxView", "_dom_classes": [], "_model_name": "HBoxModel", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.5.0", "box_style": "", "layout": "IPY_MODEL_dc4ba2d02a344bb29427e44a81dd3485", "_model_module": "@jupyter-widgets/controls", "children": ["IPY_MODEL_add506e0d3a94f1b9244f78fee3098b3", "IPY_MODEL_0f36735185f74b92bd5f093fdfc2fa84", "IPY_MODEL_c357de13e50a473e942884cab6393f37"]}, "model_name": "HBoxModel", "model_module_version": "1.5.0"}, "add506e0d3a94f1b9244f78fee3098b3": {"model_module": "@jupyter-widgets/controls", "state": {"_view_name": "HTMLView", "style": "IPY_MODEL_800640c0e2e945be9eb7bf64c751079c", "_dom_classes": [], "description": "", "_model_name": "HTMLModel", "_model_module": "@jupyter-widgets/controls", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": "Downloading: 100%", "_view_count": null, "_view_module_version": "1.5.0", "description_tooltip": null, "placeholder": "\u200b", "layout": "IPY_MODEL_b908e8268d194f7cba5e3ad848301fa0"}, "model_name": "HTMLModel", "model_module_version": "1.5.0"}, "dab07a1b62e84ebaae993735b5ab4516": {"model_module": "@jupyter-widgets/controls", "state": {"_view_name": "StyleView", "_model_name": "ProgressStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "bar_color": null, "_model_module": "@jupyter-widgets/controls"}, "model_name": "ProgressStyleModel", "model_module_version": "1.5.0"}, "b908e8268d194f7cba5e3ad848301fa0": {"model_module": "@jupyter-widgets/base", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "width": null, "grid_row": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "overflow_x": null, "max_height": null, "align_content": null, "visibility": null, "overflow": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "overflow_y": null, "max_width": null, "display": null, "_view_module_version": "1.2.0", "align_self": null, "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "order": null, "left": null}, "model_name": "LayoutModel", "model_module_version": "1.2.0"}, "800640c0e2e945be9eb7bf64c751079c": {"model_module": "@jupyter-widgets/controls", "state": {"_view_name": "StyleView", "_model_name": "DescriptionStyleModel", "description_width": "", "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.5.0", "_view_count": null, "_view_module_version": "1.2.0", "_model_module": "@jupyter-widgets/controls"}, "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0"}, "c357de13e50a473e942884cab6393f37": {"model_module": "@jupyter-widgets/controls", "state": {"_view_name": "HTMLView", "style": "IPY_MODEL_bf16cec6e7de49dda8d258405b7eae02", "_dom_classes": [], "description": "", "_model_name": "HTMLModel", "_model_module": "@jupyter-widgets/controls", "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": " 420M/420M [00:16&lt;00:00, 31.7MB/s]", "_view_count": null, "_view_module_version": "1.5.0", "description_tooltip": null, "placeholder": "\u200b", "layout": "IPY_MODEL_63c546fa1d2b48dbb3f73ef19348d80e"}, "model_name": "HTMLModel", "model_module_version": "1.5.0"}, "0f36735185f74b92bd5f093fdfc2fa84": {"model_module": "@jupyter-widgets/controls", "state": {"_view_name": "ProgressView", "style": "IPY_MODEL_dab07a1b62e84ebaae993735b5ab4516", "_dom_classes": [], "description": "", "_model_name": "FloatProgressModel", "bar_style": "success", "max": 440473133, "_view_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "value": 440473133, "_view_count": null, "_view_module_version": "1.5.0", "orientation": "horizontal", "min": 0, "description_tooltip": null, "_model_module": "@jupyter-widgets/controls", "layout": "IPY_MODEL_6a6da3cd54314b0a8dde1200fb2ba6a4"}, "model_name": "FloatProgressModel", "model_module_version": "1.5.0"}, "dc4ba2d02a344bb29427e44a81dd3485": {"model_module": "@jupyter-widgets/base", "state": {"_view_name": "LayoutView", "grid_template_rows": null, "right": null, "justify_content": null, "_view_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_view_count": null, "flex_flow": null, "min_width": null, "border": null, "align_items": null, "bottom": null, "_model_module": "@jupyter-widgets/base", "top": null, "grid_column": null, "width": null, "grid_row": null, "grid_auto_flow": null, "grid_area": null, "grid_template_columns": null, "flex": null, "_model_name": "LayoutModel", "justify_items": null, "overflow_x": null, "max_height": null, "align_content": null, "visibility": null, "overflow": null, "height": null, "min_height": null, "padding": null, "grid_auto_rows": null, "grid_gap": null, "overflow_y": null, "max_width": null, "display": null, "_view_module_version": "1.2.0", "align_self": null, "grid_template_areas": null, "object_position": null, "object_fit": null, "grid_auto_columns": null, "margin": null, "order": null, "left": null}, "model_name": "LayoutModel", "model_module_version": "1.2.0"}}
</script>


</html>
